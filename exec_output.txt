{'name': 'None', 'force': 'false', 'gpu': '2', 'recover': 'false', 'debug': 'false', 'detect_anomoly': 'false', 'profile': 'false', 'is_oracle': 'false', 'tiny_dataset': 'false', 'load_less': 'false', 'cntx_rep': 'false', 'cntx_agenda': 'false', 'disentangle_cntx': 'true', 'cntx_reranker': 'true', 'value_pred': 'true', 'uniquify': 'false', 'use_bce': 'false', 'tfixup': 'false', 'train_as_dev': 'false', 'amp': 'true', 'cntx_beam': 'true', 'should_rerank': 'false', 'use_treelstm': 'false', 'db_content': 'true', 'lin_after_cntx': 'false', 'optimizer': 'adam', 'rat_layers': '8', 'agenda_size': '30', 'base_dim': '32', 'num_heads': '8', 'agenda_encoder_num_layers': '1', 'tree_rep_transformer_num_layers': '1', 'dropout': '0.1', 'rat_dropout': '0.2', 'lm_lr': '3e-06', 'lr': '0.000186', 'batch_size': '7', 'grad_acum': '4', 'max_steps': '60000', 'power': '0.5', 'temperature': '1.0', 'grad_clip': '-1', 'grad_norm': '-1'}
experiment_name: hasty-aqua-dachsbracke_gpu2_batch_size7
2021-04-12 22:03:18,509 - INFO - allennlp.common.params - random_seed = 13370
2021-04-12 22:03:18,509 - INFO - allennlp.common.params - numpy_seed = 1337
2021-04-12 22:03:18,509 - INFO - allennlp.common.params - pytorch_seed = 133
2021-04-12 22:03:18,512 - INFO - allennlp.common.checks - Pytorch version: 1.7.0
2021-04-12 22:03:18,513 - INFO - allennlp.common.params - type = default
2021-04-12 22:03:18,513 - INFO - allennlp.common.params - dataset_reader.type = smbop
2021-04-12 22:03:18,513 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.type = pretrained_transformer
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.token_min_padding_length = 0
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.model_name = Salesforce/grappa_large_jnt
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.namespace = tags
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.max_length = None
2021-04-12 22:03:18,514 - INFO - allennlp.common.params - dataset_reader.question_token_indexers.tokens.tokenizer_kwargs = None
2021-04-12 22:03:28,244 - INFO - allennlp.common.params - dataset_reader.keep_if_unparsable = False
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.tables_file = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/train_processed_tables.json
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.dataset_path = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/database
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.cache_directory = cache/exp200train
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.include_table_name_in_column = True
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.fix_issue_16_primary_keys = False
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.qq_max_dist = 2
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.cc_max_dist = 2
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.tt_max_dist = 2
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.decoder_timesteps = 9
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.limit_instances = -1
2021-04-12 22:03:28,246 - INFO - allennlp.common.params - dataset_reader.value_pred = True
before load_trees
before connecting
2021-04-12 22:03:32,299 - INFO - allennlp.common.params - train_data_path = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/train_processed_queries.json
2021-04-12 22:03:32,300 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7fc96363cd60>
2021-04-12 22:03:32,300 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2021-04-12 22:03:32,300 - INFO - allennlp.common.params - validation_dataset_reader.type = smbop
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.type = pretrained_transformer
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.token_min_padding_length = 0
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.model_name = Salesforce/grappa_large_jnt
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.namespace = tags
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.max_length = None
2021-04-12 22:03:32,301 - INFO - allennlp.common.params - validation_dataset_reader.question_token_indexers.tokens.tokenizer_kwargs = None
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.keep_if_unparsable = True
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.tables_file = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/dev_processed_tables.json
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.dataset_path = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/database
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = cache/exp200val
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.include_table_name_in_column = True
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.fix_issue_16_primary_keys = False
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.qq_max_dist = 2
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.cc_max_dist = 2
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.tt_max_dist = 2
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.decoder_timesteps = 9
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.limit_instances = -1
2021-04-12 22:03:32,302 - INFO - allennlp.common.params - validation_dataset_reader.value_pred = True
before load_trees
before connecting
2021-04-12 22:03:33,702 - INFO - allennlp.common.params - validation_data_path = /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/dev_processed_queries.json
2021-04-12 22:03:33,702 - INFO - allennlp.common.params - test_data_path = None
2021-04-12 22:03:33,702 - INFO - allennlp.common.params - evaluate_on_test = False
2021-04-12 22:03:33,702 - INFO - allennlp.common.params - batch_weight_key = 
2021-04-12 22:03:33,702 - INFO - allennlp.training.util - Reading training data from /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/train_processed_queries.json
2021-04-12 22:03:33,705 - INFO - filelock - Lock 140505498459968 acquired on cache/exp200train/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_train_processed_queries.json.lock
2021-04-12 22:03:33,705 - INFO - filelock - Lock 140505498459968 released on cache/exp200train/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_train_processed_queries.json.lock
2021-04-12 22:03:33,705 - INFO - allennlp.data.dataset_readers.dataset_reader - Reading instances from cache cache/exp200train/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_train_processed_queries.json
2021-04-12 22:04:05,061 - INFO - allennlp.training.util - Reading validation data from /specific/netapp5/joberant/home/ohadr/smbop/shani/SmBopEST/wikisql_dataset/Processed/dev_processed_queries.json
2021-04-12 22:04:05,064 - INFO - filelock - Lock 140502546404688 acquired on cache/exp200val/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_dev_processed_queries.json.lock
2021-04-12 22:04:05,064 - INFO - filelock - Lock 140502546404688 released on cache/exp200val/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_dev_processed_queries.json.lock
2021-04-12 22:04:05,064 - INFO - allennlp.data.dataset_readers.dataset_reader - Reading instances from cache cache/exp200val/_SLASH_specific_SLASH_netapp5_SLASH_joberant_SLASH_home_SLASH_ohadr_SLASH_smbop_SLASH_shani_SLASH_SmBopEST_SLASH_wikisql_dataset_SLASH_Processed_SLASH_dev_processed_queries.json
2021-04-12 22:04:12,775 - INFO - allennlp.common.params - type = from_instances
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - min_count = None
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - max_vocab_size = None
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - pretrained_files = None
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - only_include_pretrained_words = False
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - tokens_to_add = None
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2021-04-12 22:04:12,776 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2021-04-12 22:04:12,776 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
building vocab: 0it [00:00, ?it/s]building vocab: 5741it [00:00, 57407.32it/s]building vocab: 11286it [00:00, 56804.16it/s]building vocab: 17183it [00:00, 57435.16it/s]building vocab: 23496it [00:00, 59030.45it/s]building vocab: 29044it [00:00, 57916.31it/s]building vocab: 35339it [00:00, 59338.35it/s]building vocab: 41626it [00:00, 60354.95it/s]building vocab: 47998it [00:00, 61324.11it/s]building vocab: 53974it [00:00, 60845.52it/s]building vocab: 59936it [00:01, 60470.30it/s]building vocab: 60361it [00:01, 59938.93it/s]2021-04-12 22:04:13,784 - INFO - allennlp.common.params - model.type = smbop_parser
2021-04-12 22:04:13,786 - INFO - allennlp.common.params - model.experiment_name = hasty-aqua-dachsbracke_gpu2_batch_size7
2021-04-12 22:04:13,786 - INFO - allennlp.common.params - model.question_embedder.type = basic
2021-04-12 22:04:13,786 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.type = pretrained_transformer
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.model_name = Salesforce/grappa_large_jnt
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.max_length = None
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.sub_module = None
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.train_parameters = True
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.last_layer_only = True
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.override_weights_file = None
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.override_weights_strip_prefix = None
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.gradient_checkpointing = True
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.tokenizer_kwargs = None
2021-04-12 22:04:13,787 - INFO - allennlp.common.params - model.question_embedder.token_embedders.tokens.transformer_kwargs = None
2021-04-12 22:04:22,021 - INFO - allennlp.common.params - model.schema_encoder.type = relation_transformer
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.num_layers = 8
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.num_heads = 8
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.hidden_size = 256
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.ff_size = 1024
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.tie_layers = False
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.dropout = 0.2
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.n_relations = 51
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.tfixup = False
2021-04-12 22:04:22,022 - INFO - allennlp.common.params - model.schema_encoder.mu = 31.8
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.type = pytorch_transformer
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.input_dim = 256
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.num_layers = 1
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.feedforward_hidden_dim = 1024
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.num_attention_heads = 8
2021-04-12 22:04:22,081 - INFO - allennlp.common.params - model.agenda_encoder.positional_encoding = None
2021-04-12 22:04:22,082 - INFO - allennlp.common.params - model.agenda_encoder.positional_embedding_size = 512
2021-04-12 22:04:22,082 - INFO - allennlp.common.params - model.agenda_encoder.dropout_prob = 0.1
2021-04-12 22:04:22,082 - INFO - allennlp.common.params - model.agenda_encoder.activation = relu
2021-04-12 22:04:22,097 - INFO - allennlp.common.params - model.tree_rep_transformer.type = pytorch_transformer
2021-04-12 22:04:22,097 - INFO - allennlp.common.params - model.tree_rep_transformer.input_dim = 256
2021-04-12 22:04:22,097 - INFO - allennlp.common.params - model.tree_rep_transformer.num_layers = 1
2021-04-12 22:04:22,097 - INFO - allennlp.common.params - model.tree_rep_transformer.feedforward_hidden_dim = 1024
2021-04-12 22:04:22,098 - INFO - allennlp.common.params - model.tree_rep_transformer.num_attention_heads = 8
2021-04-12 22:04:22,098 - INFO - allennlp.common.params - model.tree_rep_transformer.positional_encoding = embedding
2021-04-12 22:04:22,098 - INFO - allennlp.common.params - model.tree_rep_transformer.positional_embedding_size = 512
2021-04-12 22:04:22,098 - INFO - allennlp.common.params - model.tree_rep_transformer.dropout_prob = 0.1
2021-04-12 22:04:22,098 - INFO - allennlp.common.params - model.tree_rep_transformer.activation = relu
2021-04-12 22:04:22,113 - INFO - allennlp.common.params - model.utterance_augmenter.type = cross_attention
2021-04-12 22:04:22,116 - INFO - allennlp.common.params - model.agenda_summarizer.type = pytorch_transformer
2021-04-12 22:04:22,116 - INFO - allennlp.common.params - model.agenda_summarizer.input_dim = 256
2021-04-12 22:04:22,116 - INFO - allennlp.common.params - model.agenda_summarizer.num_layers = 1
2021-04-12 22:04:22,116 - INFO - allennlp.common.params - model.agenda_summarizer.feedforward_hidden_dim = 1024
2021-04-12 22:04:22,117 - INFO - allennlp.common.params - model.agenda_summarizer.num_attention_heads = 8
2021-04-12 22:04:22,117 - INFO - allennlp.common.params - model.agenda_summarizer.positional_encoding = None
2021-04-12 22:04:22,117 - INFO - allennlp.common.params - model.agenda_summarizer.positional_embedding_size = 512
2021-04-12 22:04:22,117 - INFO - allennlp.common.params - model.agenda_summarizer.dropout_prob = 0.1
2021-04-12 22:04:22,117 - INFO - allennlp.common.params - model.agenda_summarizer.activation = relu
2021-04-12 22:04:22,137 - INFO - allennlp.common.params - model.decoder_timesteps = 9
2021-04-12 22:04:22,137 - INFO - allennlp.common.params - model.agenda_size = 30
2021-04-12 22:04:22,137 - INFO - allennlp.common.params - model.d_frontier = 30
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.agenda_encoder_num_layers = 1
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.amp = True
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.base_dim = 32
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.batch_size = 7
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.cntx_agenda = False
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.cntx_beam = True
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.cntx_rep = False
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.cntx_reranker = True
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.debug = False
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.disentangle_cntx = True
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.embedding_dim = 256
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.grad_acum = 4
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.grad_clip = None
2021-04-12 22:04:22,138 - INFO - allennlp.common.params - model.misc_params.grad_norm = None
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.is_oracle = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.lin_after_cntx = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.lm_lr = 3e-06
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.load_less = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.lr = 0.000186
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.max_steps = 60000
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.num_heads = 8
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.power = 0.5
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.rat_dropout = 0.2
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.rat_layers = 8
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.should_rerank = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.temperature = 1
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.tfixup = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.tiny_dataset = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.train_as_dev = False
2021-04-12 22:04:22,139 - INFO - allennlp.common.params - model.misc_params.tree_rep_transformer_num_layers = 1
2021-04-12 22:04:22,140 - INFO - allennlp.common.params - model.misc_params.uniquify = False
2021-04-12 22:04:22,140 - INFO - allennlp.common.params - model.misc_params.use_bce = False
2021-04-12 22:04:22,140 - INFO - allennlp.common.params - model.misc_params.use_treelstm = False
2021-04-12 22:04:22,140 - INFO - allennlp.common.params - model.misc_params.value_pred = True
2021-04-12 22:04:22,140 - INFO - allennlp.common.params - model.dropout = 0.1
{'agenda_encoder_num_layers': 1, 'amp': True, 'base_dim': 32, 'batch_size': 7, 'cntx_agenda': False, 'cntx_beam': True, 'cntx_rep': False, 'cntx_reranker': True, 'debug': False, 'disentangle_cntx': True, 'embedding_dim': 256, 'grad_acum': 4, 'grad_clip': None, 'grad_norm': None, 'is_oracle': False, 'lin_after_cntx': False, 'lm_lr': 3e-06, 'load_less': False, 'lr': 0.000186, 'max_steps': 60000, 'num_heads': 8, 'power': 0.5, 'rat_dropout': 0.2, 'rat_layers': 8, 'should_rerank': False, 'temperature': 1, 'tfixup': False, 'tiny_dataset': False, 'train_as_dev': False, 'tree_rep_transformer_num_layers': 1, 'uniquify': False, 'use_bce': False, 'use_treelstm': False, 'value_pred': True}
2021-04-12 22:04:22,242 - INFO - filelock - Lock 140505659711200 acquired on experiments/hasty-aqua-dachsbracke_gpu2_batch_size7/vocabulary/.lock
2021-04-12 22:04:22,245 - INFO - filelock - Lock 140505659711200 released on experiments/hasty-aqua-dachsbracke_gpu2_batch_size7/vocabulary/.lock
2021-04-12 22:04:22,245 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-04-12 22:04:22,245 - INFO - allennlp.common.params - data_loader.batch_size = 1
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.sampler = None
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 7
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['enc', 'depth']
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-04-12 22:04:22,246 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.type = pytorch_dataloader
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.batch_size = 7
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.shuffle = True
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.sampler = None
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.batch_sampler = None
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.num_workers = 0
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.pin_memory = False
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.drop_last = False
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.timeout = 0
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.worker_init_fn = None
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.multiprocessing_context = None
2021-04-12 22:04:22,247 - INFO - allennlp.common.params - validation_data_loader.batches_per_epoch = None
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.type = gradient_descent
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.patience = 50
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.validation_metric = +spider
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.num_epochs = 240
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.cuda_device = 2
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.grad_norm = None
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.grad_clipping = None
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.distributed = False
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.world_size = 1
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 4
2021-04-12 22:04:22,248 - INFO - allennlp.common.params - trainer.use_amp = True
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.no_grad = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7fc96362a070>
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.moving_average = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.end_callbacks = None
2021-04-12 22:04:22,249 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2021-04-12 22:04:25,809 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2021-04-12 22:04:25,810 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.000186
2021-04-12 22:04:25,810 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2021-04-12 22:04:25,810 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2021-04-12 22:04:25,810 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2021-04-12 22:04:25,810 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2021-04-12 22:04:25,811 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2021-04-12 22:04:25,811 - INFO - allennlp.training.optimizers - Group 0: ['_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight', '_question_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight', '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight'], {'lr': 3e-06}
2021-04-12 22:04:25,812 - INFO - allennlp.training.optimizers - Group 1: ['_unary_frontier_embedder.4.weight', '_schema_encoder.encoder.layers.1.self_attn.linears.0.weight', 'pre_op_linear.2.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.1.weight', '_utterance_augmenter.att.query.bias', '_binary_frontier_embedder._weight_matrix', '_schema_encoder.encoder.layers.7.self_attn.linears.1.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.2.feed_forward.w_2.weight', '_schema_encoder.encoder.layers.4.sublayer.1.norm.weight', '_schema_encoder.encoder.layers.2.self_attn.linears.1.weight', '_utterance_augmenter.att.key.bias', '_schema_encoder.encoder.layers.3.relation_v_emb.weight', '_schema_encoder.encoder.layers.7.sublayer.0.norm.bias', '_schema_encoder.encoder.layers.4.relation_v_emb.weight', '_tree_rep_transformer._transformer.layers.0.norm1.bias', '_schema_encoder.encoder.layers.3.sublayer.1.norm.weight', '_unary_frontier_embedder.2.weight', '_unary_frontier_embedder.4.bias', '_schema_encoder.encoder.layers.1.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.3.sublayer.0.norm.weight', '_agenda_summarizer._transformer.layers.0.norm2.bias', '_schema_encoder.encoder.layers.6.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.4.self_attn.linears.0.bias', '_schema_encoder.encoder.layers.6.self_attn.linears.0.weight', '_agenda_summarizer._transformer.layers.0.norm1.bias', '_emb_to_action_dim.weight', '_schema_encoder.encoder.layers.4.relation_k_emb.weight', '_tree_rep_transformer._transformer.layers.0.self_attn.out_proj.bias', '_schema_encoder.encoder.layers.0.relation_v_emb.weight', '_schema_encoder.encoder.layers.3.sublayer.1.norm.bias', '_schema_encoder.encoder.layers.4.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.5.relation_v_emb.weight', '_rank_agenda.0.bias', '_schema_encoder.encoder.layers.3.self_attn.linears.3.bias', '_schema_encoder.encoder.layers.4.feed_forward.w_2.weight', '_schema_encoder.encoder.layers.1.feed_forward.w_2.bias', '_schema_encoder.encoder.layers.1.relation_v_emb.weight', '_agenda_summarizer._transformer.layers.0.linear1.bias', '_schema_encoder.encoder.layers.6.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.2.feed_forward.w_2.bias', '_agenda_encoder._transformer.layers.0.linear1.bias', '_schema_encoder.encoder.layers.0.self_attn.linears.3.bias', '_tree_rep_transformer._transformer.layers.0.linear1.weight', '_schema_encoder.encoder.layers.2.feed_forward.w_1.weight', '_schema_encoder.encoder.layers.1.sublayer.0.norm.bias', '_agenda_encoder._transformer.layers.0.self_attn.out_proj.weight', '_utterance_augmenter.output.dense.bias', '_tree_rep_transformer._transformer.layers.0.norm1.weight', '_schema_encoder.encoder.layers.7.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.7.feed_forward.w_1.weight', '_tree_rep_transformer._transformer.layers.0.linear2.weight', '_agenda_summarizer._transformer.layers.0.linear1.weight', '_schema_encoder.encoder.layers.5.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.7.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.1.self_attn.linears.1.bias', '_schema_encoder.encoder.layers.1.feed_forward.w_1.weight', '_schema_encoder.encoder.layers.2.sublayer.1.norm.weight', '_rank_schema.0.weight', '_schema_encoder.encoder.layers.1.sublayer.1.norm.bias', '_schema_encoder.encoder.layers.4.sublayer.1.norm.bias', '_schema_encoder.encoder.layers.1.self_attn.linears.0.bias', '_agenda_encoder._transformer.layers.0.self_attn.in_proj_weight', '_tree_rep_transformer._transformer.layers.0.linear2.bias', '_binary_frontier_embedder._bias', 'pre_op_linear.2.bias', '_schema_encoder.encoder.layers.3.feed_forward.w_1.weight', '_schema_encoder.encoder.layers.6.feed_forward.w_2.weight', 'after_add.0.bias', '_agenda_summarizer._transformer.layers.0.norm2.weight', '_unary_frontier_embedder.0.bias', '_schema_encoder.encoder.layers.7.relation_k_emb.weight', '_rank_schema.4.bias', '_schema_encoder.encoder.layers.1.feed_forward.w_2.weight', '_schema_encoder.encoder.layers.1.self_attn.linears.3.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.0.weight', '_schema_encoder.encoder.layers.5.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.6.self_attn.linears.0.bias', '_schema_encoder.encoder.layers.7.self_attn.linears.1.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.2.bias', '_tree_rep_transformer._transformer.layers.0.self_attn.in_proj_bias', '_span_score_func.bias', '_agenda_encoder._transformer.layers.0.norm2.bias', '_schema_encoder.encoder.layers.0.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.0.self_attn.linears.0.bias', '_utterance_augmenter.output.LayerNorm.weight', '_agenda_summarizer._transformer.layers.0.self_attn.in_proj_bias', '_agenda_encoder._transformer.layers.0.norm2.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.0.bias', '_schema_encoder.encoder.layers.5.self_attn.linears.2.bias', '_utterance_augmenter.att.value.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.6.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.2.relation_v_emb.weight', '_span_score_func.weight', '_schema_encoder.encoder.layers.1.sublayer.1.norm.weight', '_schema_encoder.encoder.layers.7.self_attn.linears.0.weight', '_rank_agenda.4.bias', '_schema_encoder.encoder.layers.1.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.3.feed_forward.w_2.weight', '_schema_encoder.encoder.norm.weight', '_schema_encoder.encoder.layers.6.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.4.feed_forward.w_2.bias', '_rank_schema.2.bias', '_agenda_summarizer._transformer.layers.0.self_attn.in_proj_weight', '_schema_encoder.encoder.layers.2.self_attn.linears.0.weight', 'right_emb.bias', '_schema_encoder.encoder.layers.7.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.2.sublayer.1.norm.bias', 'after_add.4.bias', '_schema_encoder.encoder.layers.5.self_attn.linears.1.bias', '_schema_encoder.encoder.layers.1.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.2.self_attn.linears.3.bias', '_schema_encoder.encoder.layers.1.relation_k_emb.weight', '_rank_agenda.0.weight', '_rank_agenda.2.bias', '_schema_encoder.encoder.layers.3.self_attn.linears.1.bias', '_rank_agenda.2.weight', '_utterance_augmenter.output.LayerNorm.bias', '_schema_encoder.encoder.layers.2.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.6.self_attn.linears.1.bias', '_agenda_encoder._transformer.layers.0.linear2.bias', '_schema_encoder.encoder.layers.7.feed_forward.w_2.bias', '_schema_encoder.encoder.layers.2.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.0.sublayer.1.norm.bias', '_schema_encoder.encoder.layers.2.sublayer.0.norm.bias', '_schema_encoder.encoder.layers.0.feed_forward.w_2.bias', '_schema_encoder.encoder.layers.3.relation_k_emb.weight', '_schema_encoder.encoder.layers.2.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.0.self_attn.linears.1.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.1.bias', 'type_embedding.weight', '_schema_encoder.encoder.layers.0.feed_forward.w_2.weight', '_schema_encoder.encoder.layers.5.self_attn.linears.3.bias', 'after_add.0.weight', '_schema_encoder.encoder.layers.1.sublayer.0.norm.weight', '_schema_encoder.encoder.layers.2.self_attn.linears.0.bias', '_utterance_augmenter.output.dense.weight', '_agenda_summarizer._transformer.layers.0.self_attn.out_proj.weight', '_schema_encoder.encoder.layers.3.self_attn.linears.0.weight', '_emb_to_action_dim.bias', '_schema_encoder.encoder.layers.0.sublayer.0.norm.weight', '_agenda_summarizer._transformer.layers.0.linear2.bias', '_schema_encoder.encoder.layers.5.sublayer.1.norm.weight', '_unary_frontier_embedder.2.bias', '_schema_encoder.encoder.layers.0.self_attn.linears.0.weight', '_schema_encoder.encoder.layers.0.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.1.weight', '_schema_encoder.encoder.layers.6.sublayer.0.norm.bias', '_agenda_summarizer._transformer.layers.0.self_attn.out_proj.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.3.bias', '_schema_encoder.encoder.layers.4.sublayer.0.norm.bias', '_rank_agenda.4.weight', '_schema_encoder.encoder.layers.1.self_attn.linears.1.weight', '_schema_encoder.encoder.layers.7.self_attn.linears.0.bias', 'right_emb.weight', '_schema_encoder.encoder.layers.0.self_attn.linears.1.weight', '_schema_encoder.encoder.layers.0.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.5.self_attn.linears.0.weight', '_agenda_encoder._transformer.layers.0.self_attn.in_proj_bias', '_schema_encoder.encoder.layers.5.feed_forward.w_2.weight', '_tree_rep_transformer._transformer.layers.0.self_attn.in_proj_weight', '_agenda_encoder._transformer.layers.0.norm1.bias', 'op_linear.weight', '_tree_rep_transformer._transformer.layers.0.linear1.bias', '_rank_schema.2.weight', '_utterance_augmenter.att.key.weight', '_schema_encoder.encoder.layers.3.sublayer.0.norm.bias', '_schema_encoder.encoder.layers.5.relation_k_emb.weight', '_schema_encoder.encoder.layers.1.self_attn.linears.2.weight', '_agenda_summarizer._transformer.layers.0.norm1.weight', 'op_linear.bias', '_schema_encoder.encoder.layers.6.relation_v_emb.weight', '_schema_encoder.encoder.layers.7.relation_v_emb.weight', '_schema_encoder.encoder.layers.2.self_attn.linears.3.weight', 'left_emb.bias', '_schema_encoder.encoder.layers.5.self_attn.linears.1.weight', '_schema_encoder.encoder.layers.4.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.5.self_attn.linears.0.bias', '_tree_rep_transformer._positional_embedding.weight', '_schema_encoder.encoder.layers.6.sublayer.1.norm.weight', '_agenda_encoder._transformer.layers.0.self_attn.out_proj.bias', 'after_add.4.weight', '_schema_encoder.encoder.layers.6.sublayer.1.norm.bias', '_schema_encoder.encoder.layers.0.sublayer.0.norm.bias', '_schema_encoder.encoder.layers.6.feed_forward.w_1.weight', '_unary_frontier_embedder.0.weight', '_schema_encoder.encoder.layers.5.self_attn.linears.2.weight', '_tree_rep_transformer._transformer.layers.0.norm2.bias', '_agenda_encoder._transformer.layers.0.linear2.weight', '_utterance_augmenter.att.value.bias', '_schema_encoder.encoder.layers.6.self_attn.linears.3.bias', '_schema_encoder.encoder.layers.5.feed_forward.w_1.weight', '_tree_rep_transformer._transformer.layers.0.self_attn.out_proj.weight', '_schema_encoder.encoder.layers.2.self_attn.linears.1.bias', '_schema_encoder.encoder.layers.4.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.3.feed_forward.w_1.bias', '_schema_encoder.encoder.norm.bias', '_schema_encoder.encoder.layers.3.feed_forward.w_2.bias', '_schema_encoder.encoder.layers.5.sublayer.0.norm.bias', '_utterance_augmenter.att.query.weight', '_tree_rep_transformer._transformer.layers.0.norm2.weight', '_schema_encoder.encoder.layers.2.self_attn.linears.2.bias', '_schema_encoder.encoder.layers.7.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.5.feed_forward.w_2.bias', '_rank_schema.4.weight', '_schema_encoder.encoder.layers.2.relation_k_emb.weight', 'after_add.2.bias', '_schema_encoder.encoder.layers.7.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.5.feed_forward.w_1.bias', '_schema_encoder.encoder.layers.6.relation_k_emb.weight', 'pre_op_linear.0.bias', '_schema_encoder.encoder.layers.0.feed_forward.w_1.weight', '_schema_encoder.encoder.layers.4.feed_forward.w_1.weight', '_schema_encoder.encoder.layers.6.feed_forward.w_2.bias', '_schema_encoder.encoder.layers.0.sublayer.1.norm.weight', '_schema_encoder.encoder.layers.0.relation_k_emb.weight', '_schema_encoder.encoder.layers.7.sublayer.1.norm.bias', '_agenda_encoder._transformer.layers.0.linear1.weight', '_schema_encoder.encoder.layers.6.self_attn.linears.2.weight', '_schema_encoder.encoder.layers.7.sublayer.1.norm.weight', '_agenda_summarizer._transformer.layers.0.linear2.weight', 'after_add.2.weight', '_schema_encoder.encoder.layers.7.self_attn.linears.3.bias', 'pre_op_linear.0.weight', '_schema_encoder.encoder.layers.6.self_attn.linears.1.weight', 'summrize_vec.weight', '_schema_encoder.encoder.layers.7.feed_forward.w_2.weight', 'left_emb.weight', '_agenda_encoder._transformer.layers.0.norm1.weight', '_rank_schema.0.bias', '_schema_encoder.encoder.layers.4.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.0.self_attn.linears.3.weight', '_schema_encoder.encoder.layers.5.sublayer.1.norm.bias'], {}
2021-04-12 22:04:25,812 - INFO - allennlp.training.optimizers - Number of trainable parameters: 374794535
2021-04-12 22:04:25,815 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2021-04-12 22:04:25,819 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2021-04-12 22:04:25,819 - INFO - allennlp.common.util - _utterance_augmenter.att.query.weight
2021-04-12 22:04:25,819 - INFO - allennlp.common.util - _utterance_augmenter.att.query.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.att.key.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.att.key.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.att.value.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.att.value.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.output.dense.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.output.dense.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.output.LayerNorm.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _utterance_augmenter.output.LayerNorm.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - type_embedding.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - summrize_vec.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _binary_frontier_embedder._weight_matrix
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _binary_frontier_embedder._bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - left_emb.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - left_emb.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - right_emb.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - right_emb.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.0.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.0.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.2.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.2.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.4.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - after_add.4.bias
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _unary_frontier_embedder.0.weight
2021-04-12 22:04:25,820 - INFO - allennlp.common.util - _unary_frontier_embedder.0.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _unary_frontier_embedder.2.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _unary_frontier_embedder.2.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _unary_frontier_embedder.4.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _unary_frontier_embedder.4.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - op_linear.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - op_linear.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - pre_op_linear.0.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - pre_op_linear.0.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - pre_op_linear.2.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - pre_op_linear.2.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias
2021-04-12 22:04:25,821 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight
2021-04-12 22:04:25,822 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight
2021-04-12 22:04:25,823 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight
2021-04-12 22:04:25,824 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias
2021-04-12 22:04:25,825 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias
2021-04-12 22:04:25,826 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias
2021-04-12 22:04:25,827 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias
2021-04-12 22:04:25,828 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias
2021-04-12 22:04:25,829 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias
2021-04-12 22:04:25,830 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias
2021-04-12 22:04:25,831 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias
2021-04-12 22:04:25,832 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias
2021-04-12 22:04:25,833 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias
2021-04-12 22:04:25,834 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias
2021-04-12 22:04:25,835 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias
2021-04-12 22:04:25,836 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _question_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.0.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.0.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.1.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.1.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.2.weight
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.2.bias
2021-04-12 22:04:25,837 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.3.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.self_attn.linears.3.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.feed_forward.w_1.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.feed_forward.w_1.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.feed_forward.w_2.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.feed_forward.w_2.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.sublayer.0.norm.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.sublayer.0.norm.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.sublayer.1.norm.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.sublayer.1.norm.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.relation_k_emb.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.0.relation_v_emb.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.0.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.0.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.1.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.1.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.2.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.2.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.3.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.self_attn.linears.3.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.feed_forward.w_1.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.feed_forward.w_1.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.feed_forward.w_2.weight
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.feed_forward.w_2.bias
2021-04-12 22:04:25,838 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.sublayer.0.norm.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.sublayer.0.norm.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.sublayer.1.norm.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.sublayer.1.norm.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.relation_k_emb.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.1.relation_v_emb.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.0.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.0.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.1.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.1.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.2.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.2.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.3.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.self_attn.linears.3.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.feed_forward.w_1.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.feed_forward.w_1.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.feed_forward.w_2.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.feed_forward.w_2.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.sublayer.0.norm.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.sublayer.0.norm.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.sublayer.1.norm.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.sublayer.1.norm.bias
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.relation_k_emb.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.2.relation_v_emb.weight
2021-04-12 22:04:25,839 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.0.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.0.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.1.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.1.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.2.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.2.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.3.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.self_attn.linears.3.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.feed_forward.w_1.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.feed_forward.w_1.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.feed_forward.w_2.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.feed_forward.w_2.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.sublayer.0.norm.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.sublayer.0.norm.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.sublayer.1.norm.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.sublayer.1.norm.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.relation_k_emb.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.3.relation_v_emb.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.0.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.0.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.1.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.1.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.2.weight
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.2.bias
2021-04-12 22:04:25,840 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.3.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.self_attn.linears.3.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.feed_forward.w_1.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.feed_forward.w_1.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.feed_forward.w_2.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.feed_forward.w_2.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.sublayer.0.norm.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.sublayer.0.norm.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.sublayer.1.norm.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.sublayer.1.norm.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.relation_k_emb.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.4.relation_v_emb.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.0.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.0.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.1.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.1.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.2.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.2.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.3.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.self_attn.linears.3.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.feed_forward.w_1.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.feed_forward.w_1.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.feed_forward.w_2.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.feed_forward.w_2.bias
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.sublayer.0.norm.weight
2021-04-12 22:04:25,841 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.sublayer.0.norm.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.sublayer.1.norm.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.sublayer.1.norm.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.relation_k_emb.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.5.relation_v_emb.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.0.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.0.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.1.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.1.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.2.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.2.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.3.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.self_attn.linears.3.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.feed_forward.w_1.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.feed_forward.w_1.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.feed_forward.w_2.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.feed_forward.w_2.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.sublayer.0.norm.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.sublayer.0.norm.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.sublayer.1.norm.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.sublayer.1.norm.bias
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.relation_k_emb.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.6.relation_v_emb.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.0.weight
2021-04-12 22:04:25,842 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.0.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.1.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.1.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.2.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.2.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.3.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.self_attn.linears.3.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.feed_forward.w_1.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.feed_forward.w_1.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.feed_forward.w_2.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.feed_forward.w_2.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.sublayer.0.norm.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.sublayer.0.norm.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.sublayer.1.norm.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.sublayer.1.norm.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.relation_k_emb.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.layers.7.relation_v_emb.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.norm.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _schema_encoder.encoder.norm.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.self_attn.in_proj_weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.self_attn.in_proj_bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.self_attn.out_proj.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.self_attn.out_proj.bias
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.linear1.weight
2021-04-12 22:04:25,843 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.linear1.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.linear2.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.linear2.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.norm1.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.norm1.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.norm2.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_encoder._transformer.layers.0.norm2.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.self_attn.in_proj_weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.self_attn.in_proj_bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.self_attn.out_proj.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.self_attn.out_proj.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.linear1.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.linear1.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.linear2.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.linear2.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.norm1.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.norm1.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.norm2.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _agenda_summarizer._transformer.layers.0.norm2.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.self_attn.in_proj_weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.self_attn.in_proj_bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.self_attn.out_proj.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.self_attn.out_proj.bias
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.linear1.weight
2021-04-12 22:04:25,844 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.linear1.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.linear2.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.linear2.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.norm1.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.norm1.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.norm2.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._transformer.layers.0.norm2.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _tree_rep_transformer._positional_embedding.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _span_score_func.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _span_score_func.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.0.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.0.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.2.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.2.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.4.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_schema.4.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.0.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.0.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.2.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.2.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.4.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _rank_agenda.4.bias
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _emb_to_action_dim.weight
2021-04-12 22:04:25,845 - INFO - allennlp.common.util - _emb_to_action_dim.bias
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = polynomial_decay
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.power = 0.5
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 1
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.end_learning_rate = 0.0
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None
2021-04-12 22:04:25,846 - INFO - allennlp.common.params - summary_interval = 100
2021-04-12 22:04:25,847 - INFO - allennlp.common.params - histogram_interval = None
2021-04-12 22:04:25,847 - INFO - allennlp.common.params - batch_size_interval = None
2021-04-12 22:04:25,847 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2021-04-12 22:04:25,847 - INFO - allennlp.common.params - should_log_learning_rate = False
2021-04-12 22:04:25,847 - INFO - allennlp.common.params - get_batch_num_total = None
2021-04-12 22:04:25,999 - INFO - allennlp.training.trainer - Beginning training.
2021-04-12 22:04:25,999 - INFO - allennlp.training.trainer - Epoch 0/239
2021-04-12 22:04:25,999 - INFO - allennlp.training.trainer - Worker 0 memory usage: 13G
2021-04-12 22:04:26,000 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B
2021-04-12 22:04:26,002 - INFO - allennlp.training.trainer - Training

  0%|          | 0/1875 [00:00<?, ?it/s]/home/joberant/home/ohadr/smbop/shani/SmBopEST/models/semantic_parsing/smbop.py:645: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  batch_idx,start_idx,end_idx = is_gold_span.nonzero().t()
final_beam_acc: 0.0000, batch_loss: 4.8682, loss: 4.8682 ||:   0%|          | 1/1875 [00:02<1:14:14,  2.38s/it]final_beam_acc: 0.0000, batch_loss: 3.7446, loss: 4.3064 ||:   0%|          | 2/1875 [00:03<1:06:51,  2.14s/it]final_beam_acc: 0.0000, batch_loss: 3.0051, loss: 3.8726 ||:   0%|          | 3/1875 [00:05<1:00:58,  1.95s/it]final_beam_acc: 0.0000, batch_loss: 2.7303, loss: 3.5871 ||:   0%|          | 4/1875 [00:06<56:44,  1.82s/it]  final_beam_acc: 0.0000, batch_loss: 2.3634, loss: 3.3423 ||:   0%|          | 5/1875 [00:08<54:32,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 2.1194, loss: 3.1385 ||:   0%|          | 6/1875 [00:10<52:18,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 1.8448, loss: 2.9537 ||:   0%|          | 7/1875 [00:11<50:31,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 1.7997, loss: 2.8094 ||:   0%|          | 8/1875 [00:13<53:30,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 1.6142, loss: 2.6766 ||:   0%|          | 9/1875 [00:15<51:53,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 1.5807, loss: 2.5670 ||:   1%|          | 10/1875 [00:16<50:43,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 1.3267, loss: 2.4543 ||:   1%|          | 11/1875 [00:18<50:33,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 1.5250, loss: 2.3769 ||:   1%|          | 12/1875 [00:19<51:12,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 1.2402, loss: 2.2894 ||:   1%|          | 13/1875 [00:21<49:07,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 1.3372, loss: 2.2214 ||:   1%|          | 14/1875 [00:22<48:26,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 1.3342, loss: 2.1623 ||:   1%|          | 15/1875 [00:24<47:21,  1.53s/it]final_beam_acc: 0.0000, batch_loss: 1.1836, loss: 2.1011 ||:   1%|          | 16/1875 [00:26<48:44,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 1.1627, loss: 2.0459 ||:   1%|          | 17/1875 [00:27<48:29,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 1.1545, loss: 1.9964 ||:   1%|          | 18/1875 [00:29<48:23,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 1.2271, loss: 1.9559 ||:   1%|1         | 19/1875 [00:30<48:45,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 1.0903, loss: 1.9126 ||:   1%|1         | 20/1875 [00:32<48:28,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 1.0428, loss: 1.8712 ||:   1%|1         | 21/1875 [00:33<48:43,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 1.0591, loss: 1.8343 ||:   1%|1         | 22/1875 [00:35<49:38,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 1.0202, loss: 1.7989 ||:   1%|1         | 23/1875 [00:37<48:31,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.9173, loss: 1.7621 ||:   1%|1         | 24/1875 [00:38<47:59,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 1.0557, loss: 1.7339 ||:   1%|1         | 25/1875 [00:40<47:50,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 1.1329, loss: 1.7108 ||:   1%|1         | 26/1875 [00:41<46:57,  1.52s/it]final_beam_acc: 0.0000, batch_loss: 1.1005, loss: 1.6882 ||:   1%|1         | 27/1875 [00:43<47:36,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 1.0088, loss: 1.6639 ||:   1%|1         | 28/1875 [00:44<46:58,  1.53s/it]final_beam_acc: 0.0000, batch_loss: 0.7517, loss: 1.6324 ||:   2%|1         | 29/1875 [00:46<46:48,  1.52s/it]final_beam_acc: 0.0000, batch_loss: 1.0498, loss: 1.6130 ||:   2%|1         | 30/1875 [00:47<47:36,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 1.0897, loss: 1.5961 ||:   2%|1         | 31/1875 [00:49<47:22,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.8735, loss: 1.5736 ||:   2%|1         | 32/1875 [00:50<47:24,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 1.0537, loss: 1.5578 ||:   2%|1         | 33/1875 [00:52<47:51,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.9711, loss: 1.5406 ||:   2%|1         | 34/1875 [00:54<48:29,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.7036, loss: 1.5166 ||:   2%|1         | 35/1875 [00:55<47:06,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.9414, loss: 1.5007 ||:   2%|1         | 36/1875 [00:57<47:05,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.9510, loss: 1.4858 ||:   2%|1         | 37/1875 [00:58<47:48,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.9592, loss: 1.4719 ||:   2%|2         | 38/1875 [01:00<48:32,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.8146, loss: 1.4551 ||:   2%|2         | 39/1875 [01:01<48:11,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 1.1133, loss: 1.4465 ||:   2%|2         | 40/1875 [01:03<47:23,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 1.0725, loss: 1.4374 ||:   2%|2         | 41/1875 [01:04<47:20,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.8837, loss: 1.4242 ||:   2%|2         | 42/1875 [01:06<48:46,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.8733, loss: 1.4114 ||:   2%|2         | 43/1875 [01:08<49:47,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.8965, loss: 1.3997 ||:   2%|2         | 44/1875 [01:09<48:31,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.9592, loss: 1.3899 ||:   2%|2         | 45/1875 [01:11<48:44,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.9543, loss: 1.3805 ||:   2%|2         | 46/1875 [01:13<51:01,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.9346, loss: 1.3710 ||:   3%|2         | 47/1875 [01:14<49:32,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.9310, loss: 1.3618 ||:   3%|2         | 48/1875 [01:16<50:40,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7340, loss: 1.3490 ||:   3%|2         | 49/1875 [01:18<49:49,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.9390, loss: 1.3408 ||:   3%|2         | 50/1875 [01:19<49:00,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6428, loss: 1.3271 ||:   3%|2         | 51/1875 [01:21<49:10,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.7837, loss: 1.3167 ||:   3%|2         | 52/1875 [01:22<49:08,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.8500, loss: 1.3079 ||:   3%|2         | 53/1875 [01:24<50:19,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.8947, loss: 1.3002 ||:   3%|2         | 54/1875 [01:26<50:47,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.8051, loss: 1.2912 ||:   3%|2         | 55/1875 [01:27<49:07,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.8475, loss: 1.2833 ||:   3%|2         | 56/1875 [01:29<49:16,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6799, loss: 1.2727 ||:   3%|3         | 57/1875 [01:30<47:22,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.7047, loss: 1.2629 ||:   3%|3         | 58/1875 [01:32<46:56,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.5817, loss: 1.2514 ||:   3%|3         | 59/1875 [01:34<47:50,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6486, loss: 1.2413 ||:   3%|3         | 60/1875 [01:35<48:02,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.9319, loss: 1.2362 ||:   3%|3         | 61/1875 [01:37<48:31,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.8498, loss: 1.2300 ||:   3%|3         | 62/1875 [01:38<47:32,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6373, loss: 1.2206 ||:   3%|3         | 63/1875 [01:40<47:30,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6402, loss: 1.2115 ||:   3%|3         | 64/1875 [01:42<47:54,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6170, loss: 1.2024 ||:   3%|3         | 65/1875 [01:43<47:30,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.8216, loss: 1.1966 ||:   4%|3         | 66/1875 [01:45<46:54,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.7225, loss: 1.1895 ||:   4%|3         | 67/1875 [01:46<48:14,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6486, loss: 1.1816 ||:   4%|3         | 68/1875 [01:48<47:41,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.7154, loss: 1.1748 ||:   4%|3         | 69/1875 [01:49<47:35,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6919, loss: 1.1679 ||:   4%|3         | 70/1875 [01:51<46:00,  1.53s/it]final_beam_acc: 0.0000, batch_loss: 0.7508, loss: 1.1621 ||:   4%|3         | 71/1875 [01:52<46:23,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.8095, loss: 1.1572 ||:   4%|3         | 72/1875 [01:54<48:29,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.7226, loss: 1.1512 ||:   4%|3         | 73/1875 [01:56<49:29,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6740, loss: 1.1448 ||:   4%|3         | 74/1875 [01:58<49:08,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.8076, loss: 1.1403 ||:   4%|4         | 75/1875 [01:59<50:09,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4915, loss: 1.1317 ||:   4%|4         | 76/1875 [02:01<48:51,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6955, loss: 1.1261 ||:   4%|4         | 77/1875 [02:03<49:41,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6884, loss: 1.1204 ||:   4%|4         | 78/1875 [02:04<48:22,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5919, loss: 1.1138 ||:   4%|4         | 79/1875 [02:06<47:25,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6948, loss: 1.1085 ||:   4%|4         | 80/1875 [02:07<46:49,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.9325, loss: 1.1063 ||:   4%|4         | 81/1875 [02:09<46:13,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.6634, loss: 1.1009 ||:   4%|4         | 82/1875 [02:10<46:39,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.7855, loss: 1.0971 ||:   4%|4         | 83/1875 [02:12<47:29,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.7657, loss: 1.0932 ||:   4%|4         | 84/1875 [02:13<47:12,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.8878, loss: 1.0908 ||:   5%|4         | 85/1875 [02:15<47:23,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6762, loss: 1.0860 ||:   5%|4         | 86/1875 [02:17<48:48,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7328, loss: 1.0819 ||:   5%|4         | 87/1875 [02:18<49:46,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4611, loss: 1.0748 ||:   5%|4         | 88/1875 [02:20<49:44,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.8712, loss: 1.0726 ||:   5%|4         | 89/1875 [02:22<50:31,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7206, loss: 1.0686 ||:   5%|4         | 90/1875 [02:24<50:18,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7148, loss: 1.0648 ||:   5%|4         | 91/1875 [02:25<49:43,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4670, loss: 1.0583 ||:   5%|4         | 92/1875 [02:27<50:34,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6752, loss: 1.0541 ||:   5%|4         | 93/1875 [02:29<51:09,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6992, loss: 1.0504 ||:   5%|5         | 94/1875 [02:30<51:03,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6865, loss: 1.0465 ||:   5%|5         | 95/1875 [02:32<51:03,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.7460, loss: 1.0434 ||:   5%|5         | 96/1875 [02:34<50:43,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6579, loss: 1.0394 ||:   5%|5         | 97/1875 [02:36<51:26,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.7866, loss: 1.0369 ||:   5%|5         | 98/1875 [02:37<51:29,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6230, loss: 1.0327 ||:   5%|5         | 99/1875 [02:39<50:51,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5421, loss: 1.0278 ||:   5%|5         | 100/1875 [02:41<55:12,  1.87s/it]final_beam_acc: 0.0000, batch_loss: 0.7298, loss: 1.0248 ||:   5%|5         | 101/1875 [02:43<54:24,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.7723, loss: 1.0223 ||:   5%|5         | 102/1875 [02:45<52:35,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6389, loss: 1.0186 ||:   5%|5         | 103/1875 [02:46<51:06,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5994, loss: 1.0146 ||:   6%|5         | 104/1875 [02:48<50:40,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6316, loss: 1.0109 ||:   6%|5         | 105/1875 [02:50<50:51,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6030, loss: 1.0071 ||:   6%|5         | 106/1875 [02:52<53:04,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.7999, loss: 1.0052 ||:   6%|5         | 107/1875 [02:53<52:36,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6181, loss: 1.0016 ||:   6%|5         | 108/1875 [02:55<51:50,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.7110, loss: 0.9989 ||:   6%|5         | 109/1875 [02:57<51:08,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6004, loss: 0.9953 ||:   6%|5         | 110/1875 [02:59<51:17,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.7914, loss: 0.9934 ||:   6%|5         | 111/1875 [03:00<50:00,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5721, loss: 0.9897 ||:   6%|5         | 112/1875 [03:02<48:08,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7150, loss: 0.9873 ||:   6%|6         | 113/1875 [03:03<48:48,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.9167, loss: 0.9866 ||:   6%|6         | 114/1875 [03:05<51:23,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5896, loss: 0.9832 ||:   6%|6         | 115/1875 [03:07<48:33,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5446, loss: 0.9794 ||:   6%|6         | 116/1875 [03:08<47:29,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.7121, loss: 0.9771 ||:   6%|6         | 117/1875 [03:10<46:35,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.7875, loss: 0.9755 ||:   6%|6         | 118/1875 [03:12<47:07,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6523, loss: 0.9728 ||:   6%|6         | 119/1875 [03:13<48:15,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6700, loss: 0.9703 ||:   6%|6         | 120/1875 [03:15<48:09,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6697, loss: 0.9678 ||:   6%|6         | 121/1875 [03:17<47:34,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7677, loss: 0.9661 ||:   7%|6         | 122/1875 [03:18<46:42,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6668, loss: 0.9637 ||:   7%|6         | 123/1875 [03:20<47:30,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6833, loss: 0.9614 ||:   7%|6         | 124/1875 [03:21<46:43,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5635, loss: 0.9583 ||:   7%|6         | 125/1875 [03:23<45:55,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6034, loss: 0.9554 ||:   7%|6         | 126/1875 [03:24<46:21,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5377, loss: 0.9522 ||:   7%|6         | 127/1875 [03:26<45:48,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.7141, loss: 0.9503 ||:   7%|6         | 128/1875 [03:27<45:27,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.7086, loss: 0.9484 ||:   7%|6         | 129/1875 [03:29<46:41,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5263, loss: 0.9452 ||:   7%|6         | 130/1875 [03:31<45:48,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6931, loss: 0.9433 ||:   7%|6         | 131/1875 [03:32<45:42,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5934, loss: 0.9406 ||:   7%|7         | 132/1875 [03:34<46:28,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6070, loss: 0.9381 ||:   7%|7         | 133/1875 [03:35<46:07,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.7080, loss: 0.9364 ||:   7%|7         | 134/1875 [03:37<45:33,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5485, loss: 0.9335 ||:   7%|7         | 135/1875 [03:39<44:50,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.6949, loss: 0.9318 ||:   7%|7         | 136/1875 [03:40<46:18,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.8179, loss: 0.9309 ||:   7%|7         | 137/1875 [03:42<45:44,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.8252, loss: 0.9302 ||:   7%|7         | 138/1875 [03:43<46:32,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5431, loss: 0.9274 ||:   7%|7         | 139/1875 [03:45<47:37,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5545, loss: 0.9247 ||:   7%|7         | 140/1875 [03:47<47:34,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5494, loss: 0.9220 ||:   8%|7         | 141/1875 [03:48<47:43,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5917, loss: 0.9197 ||:   8%|7         | 142/1875 [03:50<48:07,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5909, loss: 0.9174 ||:   8%|7         | 143/1875 [03:52<48:10,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4626, loss: 0.9143 ||:   8%|7         | 144/1875 [03:54<48:27,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6943, loss: 0.9127 ||:   8%|7         | 145/1875 [03:56<51:00,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.7069, loss: 0.9113 ||:   8%|7         | 146/1875 [03:57<50:30,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6845, loss: 0.9098 ||:   8%|7         | 147/1875 [03:59<48:53,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5787, loss: 0.9076 ||:   8%|7         | 148/1875 [04:00<47:40,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6322, loss: 0.9057 ||:   8%|7         | 149/1875 [04:02<46:53,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5786, loss: 0.9035 ||:   8%|8         | 150/1875 [04:04<46:44,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5753, loss: 0.9013 ||:   8%|8         | 151/1875 [04:05<47:09,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7075, loss: 0.9001 ||:   8%|8         | 152/1875 [04:07<46:10,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.7188, loss: 0.8989 ||:   8%|8         | 153/1875 [04:08<46:00,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4413, loss: 0.8959 ||:   8%|8         | 154/1875 [04:10<45:32,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.7927, loss: 0.8953 ||:   8%|8         | 155/1875 [04:11<44:24,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.6311, loss: 0.8936 ||:   8%|8         | 156/1875 [04:13<44:27,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.6265, loss: 0.8919 ||:   8%|8         | 157/1875 [04:15<45:09,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6305, loss: 0.8902 ||:   8%|8         | 158/1875 [04:16<45:23,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.7653, loss: 0.8894 ||:   8%|8         | 159/1875 [04:18<45:12,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4875, loss: 0.8869 ||:   9%|8         | 160/1875 [04:19<45:38,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6214, loss: 0.8853 ||:   9%|8         | 161/1875 [04:21<47:28,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7193, loss: 0.8842 ||:   9%|8         | 162/1875 [04:23<46:40,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5838, loss: 0.8824 ||:   9%|8         | 163/1875 [04:24<46:43,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.8752, loss: 0.8823 ||:   9%|8         | 164/1875 [04:26<46:03,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5759, loss: 0.8805 ||:   9%|8         | 165/1875 [04:28<45:52,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5933, loss: 0.8788 ||:   9%|8         | 166/1875 [04:29<44:52,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5537, loss: 0.8768 ||:   9%|8         | 167/1875 [04:31<45:22,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4930, loss: 0.8745 ||:   9%|8         | 168/1875 [04:32<45:07,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6884, loss: 0.8734 ||:   9%|9         | 169/1875 [04:34<44:42,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.7029, loss: 0.8724 ||:   9%|9         | 170/1875 [04:35<45:14,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5574, loss: 0.8706 ||:   9%|9         | 171/1875 [04:37<45:40,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5968, loss: 0.8690 ||:   9%|9         | 172/1875 [04:39<46:50,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6208, loss: 0.8676 ||:   9%|9         | 173/1875 [04:41<47:09,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6328, loss: 0.8662 ||:   9%|9         | 174/1875 [04:42<45:55,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.7925, loss: 0.8658 ||:   9%|9         | 175/1875 [04:44<45:51,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5858, loss: 0.8642 ||:   9%|9         | 176/1875 [04:45<45:42,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6611, loss: 0.8630 ||:   9%|9         | 177/1875 [04:47<44:44,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.8348, loss: 0.8629 ||:   9%|9         | 178/1875 [04:49<45:57,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6004, loss: 0.8614 ||:  10%|9         | 179/1875 [04:50<46:01,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7058, loss: 0.8606 ||:  10%|9         | 180/1875 [04:52<46:29,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6654, loss: 0.8595 ||:  10%|9         | 181/1875 [04:53<46:08,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5446, loss: 0.8577 ||:  10%|9         | 182/1875 [04:55<45:51,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7238, loss: 0.8570 ||:  10%|9         | 183/1875 [04:57<45:18,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6087, loss: 0.8557 ||:  10%|9         | 184/1875 [04:58<47:14,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5853, loss: 0.8542 ||:  10%|9         | 185/1875 [05:00<47:10,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6795, loss: 0.8533 ||:  10%|9         | 186/1875 [05:02<45:57,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6533, loss: 0.8522 ||:  10%|9         | 187/1875 [05:03<45:45,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6998, loss: 0.8514 ||:  10%|#         | 188/1875 [05:05<45:08,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.7481, loss: 0.8508 ||:  10%|#         | 189/1875 [05:07<47:10,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.7721, loss: 0.8504 ||:  10%|#         | 190/1875 [05:08<45:54,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6519, loss: 0.8494 ||:  10%|#         | 191/1875 [05:10<46:18,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6480, loss: 0.8483 ||:  10%|#         | 192/1875 [05:12<46:49,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5550, loss: 0.8468 ||:  10%|#         | 193/1875 [05:13<47:02,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6807, loss: 0.8460 ||:  10%|#         | 194/1875 [05:15<45:57,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5288, loss: 0.8443 ||:  10%|#         | 195/1875 [05:16<45:34,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5205, loss: 0.8427 ||:  10%|#         | 196/1875 [05:18<46:24,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6648, loss: 0.8418 ||:  11%|#         | 197/1875 [05:20<46:07,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6684, loss: 0.8409 ||:  11%|#         | 198/1875 [05:21<45:29,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7154, loss: 0.8403 ||:  11%|#         | 199/1875 [05:23<45:11,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6337, loss: 0.8392 ||:  11%|#         | 200/1875 [05:25<49:59,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.7457, loss: 0.8388 ||:  11%|#         | 201/1875 [05:27<48:18,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6089, loss: 0.8376 ||:  11%|#         | 202/1875 [05:28<47:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5264, loss: 0.8361 ||:  11%|#         | 203/1875 [05:30<44:59,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6302, loss: 0.8351 ||:  11%|#         | 204/1875 [05:31<44:56,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5896, loss: 0.8339 ||:  11%|#         | 205/1875 [05:33<44:15,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5576, loss: 0.8326 ||:  11%|#         | 206/1875 [05:35<45:10,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6209, loss: 0.8315 ||:  11%|#1        | 207/1875 [05:36<44:41,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5214, loss: 0.8300 ||:  11%|#1        | 208/1875 [05:38<44:55,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.8019, loss: 0.8299 ||:  11%|#1        | 209/1875 [05:40<45:51,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.8600, loss: 0.8300 ||:  11%|#1        | 210/1875 [05:41<45:11,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6777, loss: 0.8293 ||:  11%|#1        | 211/1875 [05:43<46:00,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4380, loss: 0.8275 ||:  11%|#1        | 212/1875 [05:45<45:47,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5395, loss: 0.8261 ||:  11%|#1        | 213/1875 [05:46<47:21,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5275, loss: 0.8247 ||:  11%|#1        | 214/1875 [05:48<46:36,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6943, loss: 0.8241 ||:  11%|#1        | 215/1875 [05:50<46:49,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5387, loss: 0.8228 ||:  12%|#1        | 216/1875 [05:51<46:47,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5086, loss: 0.8214 ||:  12%|#1        | 217/1875 [05:53<47:58,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4844, loss: 0.8198 ||:  12%|#1        | 218/1875 [05:55<47:38,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.7079, loss: 0.8193 ||:  12%|#1        | 219/1875 [05:57<46:54,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.3941, loss: 0.8174 ||:  12%|#1        | 220/1875 [05:58<47:24,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5795, loss: 0.8163 ||:  12%|#1        | 221/1875 [06:00<48:49,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.6121, loss: 0.8154 ||:  12%|#1        | 222/1875 [06:02<48:16,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6151, loss: 0.8145 ||:  12%|#1        | 223/1875 [06:04<48:26,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.3441, loss: 0.8124 ||:  12%|#1        | 224/1875 [06:05<47:43,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5186, loss: 0.8111 ||:  12%|#2        | 225/1875 [06:07<47:38,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5980, loss: 0.8101 ||:  12%|#2        | 226/1875 [06:09<47:05,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.7210, loss: 0.8097 ||:  12%|#2        | 227/1875 [06:11<48:23,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.6890, loss: 0.8092 ||:  12%|#2        | 228/1875 [06:12<48:33,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4889, loss: 0.8078 ||:  12%|#2        | 229/1875 [06:14<47:50,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5439, loss: 0.8067 ||:  12%|#2        | 230/1875 [06:16<48:42,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.7039, loss: 0.8062 ||:  12%|#2        | 231/1875 [06:18<49:09,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4538, loss: 0.8047 ||:  12%|#2        | 232/1875 [06:20<48:51,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6465, loss: 0.8040 ||:  12%|#2        | 233/1875 [06:21<47:50,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5530, loss: 0.8029 ||:  12%|#2        | 234/1875 [06:23<47:49,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5588, loss: 0.8019 ||:  13%|#2        | 235/1875 [06:25<48:11,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.6020, loss: 0.8011 ||:  13%|#2        | 236/1875 [06:27<48:32,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4900, loss: 0.7997 ||:  13%|#2        | 237/1875 [06:28<46:57,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6378, loss: 0.7991 ||:  13%|#2        | 238/1875 [06:30<46:29,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5861, loss: 0.7982 ||:  13%|#2        | 239/1875 [06:32<47:48,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5989, loss: 0.7973 ||:  13%|#2        | 240/1875 [06:33<47:19,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6758, loss: 0.7968 ||:  13%|#2        | 241/1875 [06:35<49:38,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5089, loss: 0.7956 ||:  13%|#2        | 242/1875 [06:37<48:28,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4374, loss: 0.7942 ||:  13%|#2        | 243/1875 [06:39<47:27,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5746, loss: 0.7933 ||:  13%|#3        | 244/1875 [06:41<47:47,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.7156, loss: 0.7930 ||:  13%|#3        | 245/1875 [06:42<49:00,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.6980, loss: 0.7926 ||:  13%|#3        | 246/1875 [06:44<49:24,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.4949, loss: 0.7914 ||:  13%|#3        | 247/1875 [06:46<47:22,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5392, loss: 0.7903 ||:  13%|#3        | 248/1875 [06:47<45:48,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6851, loss: 0.7899 ||:  13%|#3        | 249/1875 [06:49<46:01,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5183, loss: 0.7888 ||:  13%|#3        | 250/1875 [06:51<46:14,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6404, loss: 0.7882 ||:  13%|#3        | 251/1875 [06:53<45:41,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4355, loss: 0.7868 ||:  13%|#3        | 252/1875 [06:54<45:04,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.7128, loss: 0.7866 ||:  13%|#3        | 253/1875 [06:56<46:19,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6136, loss: 0.7859 ||:  14%|#3        | 254/1875 [06:58<47:35,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5473, loss: 0.7849 ||:  14%|#3        | 255/1875 [07:00<48:18,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6300, loss: 0.7843 ||:  14%|#3        | 256/1875 [07:01<47:41,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5845, loss: 0.7836 ||:  14%|#3        | 257/1875 [07:03<47:39,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.7323, loss: 0.7834 ||:  14%|#3        | 258/1875 [07:05<47:44,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4809, loss: 0.7822 ||:  14%|#3        | 259/1875 [07:07<47:48,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.8053, loss: 0.7823 ||:  14%|#3        | 260/1875 [07:09<49:10,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.4799, loss: 0.7811 ||:  14%|#3        | 261/1875 [07:10<48:04,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.7783, loss: 0.7811 ||:  14%|#3        | 262/1875 [07:12<48:31,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.6433, loss: 0.7806 ||:  14%|#4        | 263/1875 [07:14<46:40,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5762, loss: 0.7798 ||:  14%|#4        | 264/1875 [07:16<46:42,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5063, loss: 0.7788 ||:  14%|#4        | 265/1875 [07:17<46:02,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6542, loss: 0.7783 ||:  14%|#4        | 266/1875 [07:19<45:22,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5656, loss: 0.7775 ||:  14%|#4        | 267/1875 [07:21<46:16,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6624, loss: 0.7771 ||:  14%|#4        | 268/1875 [07:22<45:58,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6126, loss: 0.7765 ||:  14%|#4        | 269/1875 [07:24<46:31,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6463, loss: 0.7760 ||:  14%|#4        | 270/1875 [07:26<45:33,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4497, loss: 0.7748 ||:  14%|#4        | 271/1875 [07:27<44:13,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6030, loss: 0.7742 ||:  15%|#4        | 272/1875 [07:29<45:49,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5008, loss: 0.7732 ||:  15%|#4        | 273/1875 [07:31<45:59,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6500, loss: 0.7727 ||:  15%|#4        | 274/1875 [07:33<45:05,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7378, loss: 0.7726 ||:  15%|#4        | 275/1875 [07:34<45:02,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5570, loss: 0.7718 ||:  15%|#4        | 276/1875 [07:36<46:14,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5261, loss: 0.7709 ||:  15%|#4        | 277/1875 [07:38<45:29,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6369, loss: 0.7704 ||:  15%|#4        | 278/1875 [07:39<45:30,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5672, loss: 0.7697 ||:  15%|#4        | 279/1875 [07:41<45:45,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5100, loss: 0.7688 ||:  15%|#4        | 280/1875 [07:43<45:03,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5698, loss: 0.7681 ||:  15%|#4        | 281/1875 [07:45<44:57,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5637, loss: 0.7673 ||:  15%|#5        | 282/1875 [07:46<45:52,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.8944, loss: 0.7678 ||:  15%|#5        | 283/1875 [07:48<45:30,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5890, loss: 0.7672 ||:  15%|#5        | 284/1875 [07:50<45:27,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6442, loss: 0.7667 ||:  15%|#5        | 285/1875 [07:51<45:48,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6745, loss: 0.7664 ||:  15%|#5        | 286/1875 [07:53<45:35,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6004, loss: 0.7658 ||:  15%|#5        | 287/1875 [07:55<45:55,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5746, loss: 0.7652 ||:  15%|#5        | 288/1875 [07:57<44:55,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5354, loss: 0.7644 ||:  15%|#5        | 289/1875 [07:58<43:58,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4558, loss: 0.7633 ||:  15%|#5        | 290/1875 [08:00<44:55,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5724, loss: 0.7626 ||:  16%|#5        | 291/1875 [08:02<44:36,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4869, loss: 0.7617 ||:  16%|#5        | 292/1875 [08:03<44:36,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6723, loss: 0.7614 ||:  16%|#5        | 293/1875 [08:05<46:20,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5668, loss: 0.7607 ||:  16%|#5        | 294/1875 [08:07<46:16,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4602, loss: 0.7597 ||:  16%|#5        | 295/1875 [08:09<46:05,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5755, loss: 0.7591 ||:  16%|#5        | 296/1875 [08:10<45:07,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.7053, loss: 0.7589 ||:  16%|#5        | 297/1875 [08:12<44:36,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5856, loss: 0.7583 ||:  16%|#5        | 298/1875 [08:14<44:39,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6048, loss: 0.7578 ||:  16%|#5        | 299/1875 [08:15<44:29,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5552, loss: 0.7571 ||:  16%|#6        | 300/1875 [08:18<48:36,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5504, loss: 0.7565 ||:  16%|#6        | 301/1875 [08:19<48:03,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.6252, loss: 0.7560 ||:  16%|#6        | 302/1875 [08:21<46:40,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5894, loss: 0.7555 ||:  16%|#6        | 303/1875 [08:23<46:53,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4580, loss: 0.7545 ||:  16%|#6        | 304/1875 [08:25<45:48,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5974, loss: 0.7540 ||:  16%|#6        | 305/1875 [08:26<46:20,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5925, loss: 0.7535 ||:  16%|#6        | 306/1875 [08:28<44:37,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.7042, loss: 0.7533 ||:  16%|#6        | 307/1875 [08:30<44:55,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5973, loss: 0.7528 ||:  16%|#6        | 308/1875 [08:31<43:35,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5134, loss: 0.7520 ||:  16%|#6        | 309/1875 [08:33<43:39,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4969, loss: 0.7512 ||:  17%|#6        | 310/1875 [08:34<42:40,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7251, loss: 0.7511 ||:  17%|#6        | 311/1875 [08:36<42:02,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5187, loss: 0.7504 ||:  17%|#6        | 312/1875 [08:38<42:33,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4218, loss: 0.7493 ||:  17%|#6        | 313/1875 [08:39<42:48,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7646, loss: 0.7494 ||:  17%|#6        | 314/1875 [08:41<43:42,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5459, loss: 0.7487 ||:  17%|#6        | 315/1875 [08:43<43:12,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4468, loss: 0.7478 ||:  17%|#6        | 316/1875 [08:44<42:41,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7512, loss: 0.7478 ||:  17%|#6        | 317/1875 [08:46<43:10,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6468, loss: 0.7474 ||:  17%|#6        | 318/1875 [08:48<44:31,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4876, loss: 0.7466 ||:  17%|#7        | 319/1875 [08:50<45:50,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4675, loss: 0.7458 ||:  17%|#7        | 320/1875 [08:51<44:50,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6501, loss: 0.7455 ||:  17%|#7        | 321/1875 [08:53<45:32,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.8214, loss: 0.7457 ||:  17%|#7        | 322/1875 [08:55<45:54,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5084, loss: 0.7450 ||:  17%|#7        | 323/1875 [08:57<45:43,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5746, loss: 0.7444 ||:  17%|#7        | 324/1875 [08:58<44:46,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5492, loss: 0.7438 ||:  17%|#7        | 325/1875 [09:00<44:22,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4599, loss: 0.7430 ||:  17%|#7        | 326/1875 [09:02<43:16,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5684, loss: 0.7424 ||:  17%|#7        | 327/1875 [09:03<44:11,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5533, loss: 0.7419 ||:  17%|#7        | 328/1875 [09:05<43:49,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7172, loss: 0.7418 ||:  18%|#7        | 329/1875 [09:07<43:07,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.7239, loss: 0.7417 ||:  18%|#7        | 330/1875 [09:09<44:05,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5629, loss: 0.7412 ||:  18%|#7        | 331/1875 [09:10<44:07,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6324, loss: 0.7409 ||:  18%|#7        | 332/1875 [09:12<43:56,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6266, loss: 0.7405 ||:  18%|#7        | 333/1875 [09:14<42:36,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6273, loss: 0.7402 ||:  18%|#7        | 334/1875 [09:15<42:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5711, loss: 0.7397 ||:  18%|#7        | 335/1875 [09:17<42:59,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5803, loss: 0.7392 ||:  18%|#7        | 336/1875 [09:18<41:35,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5718, loss: 0.7387 ||:  18%|#7        | 337/1875 [09:20<41:28,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5111, loss: 0.7380 ||:  18%|#8        | 338/1875 [09:22<41:40,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6701, loss: 0.7378 ||:  18%|#8        | 339/1875 [09:23<41:46,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6098, loss: 0.7375 ||:  18%|#8        | 340/1875 [09:25<43:01,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3286, loss: 0.7363 ||:  18%|#8        | 341/1875 [09:27<44:00,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6814, loss: 0.7361 ||:  18%|#8        | 342/1875 [09:29<43:26,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5877, loss: 0.7357 ||:  18%|#8        | 343/1875 [09:30<42:17,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5166, loss: 0.7350 ||:  18%|#8        | 344/1875 [09:32<42:32,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.7138, loss: 0.7350 ||:  18%|#8        | 345/1875 [09:33<42:14,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6729, loss: 0.7348 ||:  18%|#8        | 346/1875 [09:35<42:17,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5246, loss: 0.7342 ||:  19%|#8        | 347/1875 [09:37<42:25,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6669, loss: 0.7340 ||:  19%|#8        | 348/1875 [09:38<42:33,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5817, loss: 0.7335 ||:  19%|#8        | 349/1875 [09:40<42:33,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6427, loss: 0.7333 ||:  19%|#8        | 350/1875 [09:42<41:57,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6084, loss: 0.7329 ||:  19%|#8        | 351/1875 [09:43<42:02,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6539, loss: 0.7327 ||:  19%|#8        | 352/1875 [09:45<42:13,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5528, loss: 0.7322 ||:  19%|#8        | 353/1875 [09:47<41:08,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6602, loss: 0.7320 ||:  19%|#8        | 354/1875 [09:48<41:33,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6631, loss: 0.7318 ||:  19%|#8        | 355/1875 [09:50<42:55,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4225, loss: 0.7309 ||:  19%|#8        | 356/1875 [09:52<43:01,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7931, loss: 0.7311 ||:  19%|#9        | 357/1875 [09:54<43:40,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5420, loss: 0.7306 ||:  19%|#9        | 358/1875 [09:55<43:59,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5985, loss: 0.7302 ||:  19%|#9        | 359/1875 [09:57<44:03,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5945, loss: 0.7298 ||:  19%|#9        | 360/1875 [09:59<43:21,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5034, loss: 0.7292 ||:  19%|#9        | 361/1875 [10:00<43:05,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6307, loss: 0.7289 ||:  19%|#9        | 362/1875 [10:02<43:18,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4986, loss: 0.7283 ||:  19%|#9        | 363/1875 [10:04<42:39,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5373, loss: 0.7278 ||:  19%|#9        | 364/1875 [10:06<42:27,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6057, loss: 0.7274 ||:  19%|#9        | 365/1875 [10:07<42:38,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5714, loss: 0.7270 ||:  20%|#9        | 366/1875 [10:09<42:25,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7495, loss: 0.7271 ||:  20%|#9        | 367/1875 [10:10<41:37,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5428, loss: 0.7266 ||:  20%|#9        | 368/1875 [10:12<42:20,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6598, loss: 0.7264 ||:  20%|#9        | 369/1875 [10:14<44:09,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5409, loss: 0.7259 ||:  20%|#9        | 370/1875 [10:16<43:31,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5232, loss: 0.7253 ||:  20%|#9        | 371/1875 [10:18<42:55,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5571, loss: 0.7249 ||:  20%|#9        | 372/1875 [10:19<41:26,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6520, loss: 0.7247 ||:  20%|#9        | 373/1875 [10:21<42:53,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6895, loss: 0.7246 ||:  20%|#9        | 374/1875 [10:23<43:23,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5029, loss: 0.7240 ||:  20%|##        | 375/1875 [10:24<42:20,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5203, loss: 0.7235 ||:  20%|##        | 376/1875 [10:26<42:46,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4946, loss: 0.7229 ||:  20%|##        | 377/1875 [10:28<42:20,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6418, loss: 0.7226 ||:  20%|##        | 378/1875 [10:29<42:10,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4880, loss: 0.7220 ||:  20%|##        | 379/1875 [10:31<42:43,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5362, loss: 0.7215 ||:  20%|##        | 380/1875 [10:33<42:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5114, loss: 0.7210 ||:  20%|##        | 381/1875 [10:34<41:54,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5796, loss: 0.7206 ||:  20%|##        | 382/1875 [10:36<41:45,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6070, loss: 0.7203 ||:  20%|##        | 383/1875 [10:38<41:23,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7044, loss: 0.7203 ||:  20%|##        | 384/1875 [10:39<39:57,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6866, loss: 0.7202 ||:  21%|##        | 385/1875 [10:41<41:00,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4858, loss: 0.7196 ||:  21%|##        | 386/1875 [10:42<40:00,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5129, loss: 0.7191 ||:  21%|##        | 387/1875 [10:44<39:05,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5586, loss: 0.7186 ||:  21%|##        | 388/1875 [10:46<39:56,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6184, loss: 0.7184 ||:  21%|##        | 389/1875 [10:47<39:02,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4763, loss: 0.7178 ||:  21%|##        | 390/1875 [10:49<38:39,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4738, loss: 0.7171 ||:  21%|##        | 391/1875 [10:50<38:51,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5045, loss: 0.7166 ||:  21%|##        | 392/1875 [10:52<38:08,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.7318, loss: 0.7166 ||:  21%|##        | 393/1875 [10:53<38:28,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4772, loss: 0.7160 ||:  21%|##1       | 394/1875 [10:55<41:14,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6446, loss: 0.7158 ||:  21%|##1       | 395/1875 [10:57<41:20,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5175, loss: 0.7153 ||:  21%|##1       | 396/1875 [10:59<40:47,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6157, loss: 0.7151 ||:  21%|##1       | 397/1875 [11:00<41:25,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4542, loss: 0.7144 ||:  21%|##1       | 398/1875 [11:02<40:56,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5776, loss: 0.7141 ||:  21%|##1       | 399/1875 [11:04<40:09,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5969, loss: 0.7138 ||:  21%|##1       | 400/1875 [11:06<44:43,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.6341, loss: 0.7136 ||:  21%|##1       | 401/1875 [11:07<43:44,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4446, loss: 0.7129 ||:  21%|##1       | 402/1875 [11:09<42:49,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5263, loss: 0.7125 ||:  21%|##1       | 403/1875 [11:11<41:49,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5629, loss: 0.7121 ||:  22%|##1       | 404/1875 [11:12<41:34,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4387, loss: 0.7114 ||:  22%|##1       | 405/1875 [11:14<40:35,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6247, loss: 0.7112 ||:  22%|##1       | 406/1875 [11:16<40:38,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5634, loss: 0.7108 ||:  22%|##1       | 407/1875 [11:17<40:08,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4307, loss: 0.7102 ||:  22%|##1       | 408/1875 [11:19<39:15,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4872, loss: 0.7096 ||:  22%|##1       | 409/1875 [11:20<38:36,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5391, loss: 0.7092 ||:  22%|##1       | 410/1875 [11:22<38:38,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5007, loss: 0.7087 ||:  22%|##1       | 411/1875 [11:24<39:33,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5665, loss: 0.7083 ||:  22%|##1       | 412/1875 [11:25<39:54,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5844, loss: 0.7080 ||:  22%|##2       | 413/1875 [11:27<38:38,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6236, loss: 0.7078 ||:  22%|##2       | 414/1875 [11:28<37:52,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5807, loss: 0.7075 ||:  22%|##2       | 415/1875 [11:30<37:51,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5933, loss: 0.7073 ||:  22%|##2       | 416/1875 [11:31<38:56,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5779, loss: 0.7070 ||:  22%|##2       | 417/1875 [11:33<39:27,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5787, loss: 0.7066 ||:  22%|##2       | 418/1875 [11:35<42:37,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5027, loss: 0.7062 ||:  22%|##2       | 419/1875 [11:37<41:22,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6027, loss: 0.7059 ||:  22%|##2       | 420/1875 [11:38<41:04,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5574, loss: 0.7056 ||:  22%|##2       | 421/1875 [11:40<39:55,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6259, loss: 0.7054 ||:  23%|##2       | 422/1875 [11:42<40:07,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5207, loss: 0.7049 ||:  23%|##2       | 423/1875 [11:43<39:31,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5256, loss: 0.7045 ||:  23%|##2       | 424/1875 [11:45<39:08,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5147, loss: 0.7041 ||:  23%|##2       | 425/1875 [11:46<38:43,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6272, loss: 0.7039 ||:  23%|##2       | 426/1875 [11:48<37:50,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4827, loss: 0.7034 ||:  23%|##2       | 427/1875 [11:49<37:37,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.6364, loss: 0.7032 ||:  23%|##2       | 428/1875 [11:51<37:04,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.4862, loss: 0.7027 ||:  23%|##2       | 429/1875 [11:52<36:57,  1.53s/it]final_beam_acc: 0.0000, batch_loss: 0.8932, loss: 0.7031 ||:  23%|##2       | 430/1875 [11:54<37:14,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.6313, loss: 0.7030 ||:  23%|##2       | 431/1875 [11:56<37:10,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.5914, loss: 0.7027 ||:  23%|##3       | 432/1875 [11:57<38:31,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5515, loss: 0.7024 ||:  23%|##3       | 433/1875 [11:59<38:57,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6251, loss: 0.7022 ||:  23%|##3       | 434/1875 [12:01<40:16,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5760, loss: 0.7019 ||:  23%|##3       | 435/1875 [12:02<40:23,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6571, loss: 0.7018 ||:  23%|##3       | 436/1875 [12:04<40:54,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5304, loss: 0.7014 ||:  23%|##3       | 437/1875 [12:06<40:26,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6271, loss: 0.7012 ||:  23%|##3       | 438/1875 [12:08<40:48,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5201, loss: 0.7008 ||:  23%|##3       | 439/1875 [12:09<40:22,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5899, loss: 0.7006 ||:  23%|##3       | 440/1875 [12:11<38:28,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4940, loss: 0.7001 ||:  24%|##3       | 441/1875 [12:12<38:20,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4536, loss: 0.6995 ||:  24%|##3       | 442/1875 [12:14<38:17,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.7709, loss: 0.6997 ||:  24%|##3       | 443/1875 [12:16<38:58,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7062, loss: 0.6997 ||:  24%|##3       | 444/1875 [12:17<38:31,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6279, loss: 0.6996 ||:  24%|##3       | 445/1875 [12:19<38:37,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5470, loss: 0.6992 ||:  24%|##3       | 446/1875 [12:20<37:57,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5666, loss: 0.6989 ||:  24%|##3       | 447/1875 [12:22<37:53,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4829, loss: 0.6984 ||:  24%|##3       | 448/1875 [12:24<38:04,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6154, loss: 0.6983 ||:  24%|##3       | 449/1875 [12:25<38:43,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6345, loss: 0.6981 ||:  24%|##4       | 450/1875 [12:27<38:26,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4917, loss: 0.6977 ||:  24%|##4       | 451/1875 [12:28<38:09,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5402, loss: 0.6973 ||:  24%|##4       | 452/1875 [12:30<38:10,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5120, loss: 0.6969 ||:  24%|##4       | 453/1875 [12:32<38:44,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5044, loss: 0.6965 ||:  24%|##4       | 454/1875 [12:33<39:40,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4164, loss: 0.6959 ||:  24%|##4       | 455/1875 [12:35<39:53,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6525, loss: 0.6958 ||:  24%|##4       | 456/1875 [12:37<39:20,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5754, loss: 0.6955 ||:  24%|##4       | 457/1875 [12:38<39:11,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5207, loss: 0.6951 ||:  24%|##4       | 458/1875 [12:40<39:12,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5838, loss: 0.6949 ||:  24%|##4       | 459/1875 [12:42<38:38,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5628, loss: 0.6946 ||:  25%|##4       | 460/1875 [12:43<38:29,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.8007, loss: 0.6948 ||:  25%|##4       | 461/1875 [12:45<38:42,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5448, loss: 0.6945 ||:  25%|##4       | 462/1875 [12:47<39:17,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6861, loss: 0.6945 ||:  25%|##4       | 463/1875 [12:48<40:02,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7319, loss: 0.6946 ||:  25%|##4       | 464/1875 [12:50<40:51,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5312, loss: 0.6942 ||:  25%|##4       | 465/1875 [12:52<39:52,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6507, loss: 0.6941 ||:  25%|##4       | 466/1875 [12:53<39:03,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5905, loss: 0.6939 ||:  25%|##4       | 467/1875 [12:55<39:02,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5023, loss: 0.6935 ||:  25%|##4       | 468/1875 [12:57<39:57,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7106, loss: 0.6935 ||:  25%|##5       | 469/1875 [12:59<40:34,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5113, loss: 0.6931 ||:  25%|##5       | 470/1875 [13:00<39:58,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5472, loss: 0.6928 ||:  25%|##5       | 471/1875 [13:02<38:51,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5124, loss: 0.6924 ||:  25%|##5       | 472/1875 [13:04<38:27,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5229, loss: 0.6921 ||:  25%|##5       | 473/1875 [13:05<39:38,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.7265, loss: 0.6922 ||:  25%|##5       | 474/1875 [13:07<41:01,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5816, loss: 0.6919 ||:  25%|##5       | 475/1875 [13:09<40:02,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5183, loss: 0.6916 ||:  25%|##5       | 476/1875 [13:11<40:06,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5734, loss: 0.6913 ||:  25%|##5       | 477/1875 [13:12<39:08,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4309, loss: 0.6908 ||:  25%|##5       | 478/1875 [13:14<38:23,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4452, loss: 0.6903 ||:  26%|##5       | 479/1875 [13:16<38:55,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5549, loss: 0.6900 ||:  26%|##5       | 480/1875 [13:17<38:26,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5201, loss: 0.6896 ||:  26%|##5       | 481/1875 [13:19<38:32,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4600, loss: 0.6891 ||:  26%|##5       | 482/1875 [13:20<38:44,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6228, loss: 0.6890 ||:  26%|##5       | 483/1875 [13:22<37:38,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6339, loss: 0.6889 ||:  26%|##5       | 484/1875 [13:24<38:50,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5747, loss: 0.6887 ||:  26%|##5       | 485/1875 [13:26<40:32,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4455, loss: 0.6882 ||:  26%|##5       | 486/1875 [13:27<39:56,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5415, loss: 0.6879 ||:  26%|##5       | 487/1875 [13:29<38:52,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5631, loss: 0.6876 ||:  26%|##6       | 488/1875 [13:31<38:31,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6841, loss: 0.6876 ||:  26%|##6       | 489/1875 [13:32<38:18,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7815, loss: 0.6878 ||:  26%|##6       | 490/1875 [13:34<37:15,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4577, loss: 0.6873 ||:  26%|##6       | 491/1875 [13:35<37:38,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5847, loss: 0.6871 ||:  26%|##6       | 492/1875 [13:37<37:00,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5743, loss: 0.6869 ||:  26%|##6       | 493/1875 [13:38<35:55,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5854, loss: 0.6867 ||:  26%|##6       | 494/1875 [13:40<36:06,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5451, loss: 0.6864 ||:  26%|##6       | 495/1875 [13:42<36:08,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5641, loss: 0.6861 ||:  26%|##6       | 496/1875 [13:43<35:35,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.5834, loss: 0.6859 ||:  27%|##6       | 497/1875 [13:45<36:40,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5012, loss: 0.6856 ||:  27%|##6       | 498/1875 [13:46<36:49,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.3830, loss: 0.6850 ||:  27%|##6       | 499/1875 [13:48<37:07,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4238, loss: 0.6844 ||:  27%|##6       | 500/1875 [13:50<41:20,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5131, loss: 0.6841 ||:  27%|##6       | 501/1875 [13:52<41:03,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5789, loss: 0.6839 ||:  27%|##6       | 502/1875 [13:54<39:53,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5842, loss: 0.6837 ||:  27%|##6       | 503/1875 [13:55<39:54,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6469, loss: 0.6836 ||:  27%|##6       | 504/1875 [13:57<38:43,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5540, loss: 0.6834 ||:  27%|##6       | 505/1875 [13:59<39:38,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6670, loss: 0.6833 ||:  27%|##6       | 506/1875 [14:00<38:46,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5569, loss: 0.6831 ||:  27%|##7       | 507/1875 [14:02<37:26,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7260, loss: 0.6832 ||:  27%|##7       | 508/1875 [14:04<37:43,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6102, loss: 0.6830 ||:  27%|##7       | 509/1875 [14:05<37:26,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4758, loss: 0.6826 ||:  27%|##7       | 510/1875 [14:07<36:17,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6177, loss: 0.6825 ||:  27%|##7       | 511/1875 [14:08<37:07,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6758, loss: 0.6825 ||:  27%|##7       | 512/1875 [14:10<36:56,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5090, loss: 0.6821 ||:  27%|##7       | 513/1875 [14:12<37:00,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5107, loss: 0.6818 ||:  27%|##7       | 514/1875 [14:14<37:54,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4106, loss: 0.6813 ||:  27%|##7       | 515/1875 [14:15<37:58,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5484, loss: 0.6810 ||:  28%|##7       | 516/1875 [14:17<37:49,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5781, loss: 0.6808 ||:  28%|##7       | 517/1875 [14:18<37:10,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4992, loss: 0.6805 ||:  28%|##7       | 518/1875 [14:20<37:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4987, loss: 0.6801 ||:  28%|##7       | 519/1875 [14:22<37:08,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5302, loss: 0.6798 ||:  28%|##7       | 520/1875 [14:23<37:37,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4738, loss: 0.6794 ||:  28%|##7       | 521/1875 [14:26<40:26,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6097, loss: 0.6793 ||:  28%|##7       | 522/1875 [14:27<39:11,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5950, loss: 0.6791 ||:  28%|##7       | 523/1875 [14:29<39:06,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5252, loss: 0.6788 ||:  28%|##7       | 524/1875 [14:30<37:37,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5833, loss: 0.6787 ||:  28%|##8       | 525/1875 [14:32<37:24,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6365, loss: 0.6786 ||:  28%|##8       | 526/1875 [14:34<39:15,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5762, loss: 0.6784 ||:  28%|##8       | 527/1875 [14:36<37:59,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5781, loss: 0.6782 ||:  28%|##8       | 528/1875 [14:37<37:19,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4701, loss: 0.6778 ||:  28%|##8       | 529/1875 [14:39<37:40,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5550, loss: 0.6776 ||:  28%|##8       | 530/1875 [14:40<36:55,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6357, loss: 0.6775 ||:  28%|##8       | 531/1875 [14:42<37:26,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6600, loss: 0.6775 ||:  28%|##8       | 532/1875 [14:44<36:32,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4735, loss: 0.6771 ||:  28%|##8       | 533/1875 [14:45<36:47,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.8037, loss: 0.6773 ||:  28%|##8       | 534/1875 [14:47<37:24,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4162, loss: 0.6768 ||:  29%|##8       | 535/1875 [14:49<36:34,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4059, loss: 0.6763 ||:  29%|##8       | 536/1875 [14:50<35:18,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4470, loss: 0.6759 ||:  29%|##8       | 537/1875 [14:52<36:14,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5329, loss: 0.6756 ||:  29%|##8       | 538/1875 [14:53<35:36,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4605, loss: 0.6752 ||:  29%|##8       | 539/1875 [14:55<35:42,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6544, loss: 0.6752 ||:  29%|##8       | 540/1875 [14:57<36:38,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.7431, loss: 0.6753 ||:  29%|##8       | 541/1875 [14:58<36:51,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5102, loss: 0.6750 ||:  29%|##8       | 542/1875 [15:00<35:45,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5140, loss: 0.6747 ||:  29%|##8       | 543/1875 [15:02<36:11,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7829, loss: 0.6749 ||:  29%|##9       | 544/1875 [15:03<37:08,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5716, loss: 0.6747 ||:  29%|##9       | 545/1875 [15:05<37:26,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6274, loss: 0.6746 ||:  29%|##9       | 546/1875 [15:07<37:38,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6207, loss: 0.6745 ||:  29%|##9       | 547/1875 [15:08<36:54,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4791, loss: 0.6742 ||:  29%|##9       | 548/1875 [15:10<36:59,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4364, loss: 0.6737 ||:  29%|##9       | 549/1875 [15:12<37:17,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6323, loss: 0.6737 ||:  29%|##9       | 550/1875 [15:14<37:18,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7325, loss: 0.6738 ||:  29%|##9       | 551/1875 [15:15<36:04,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4998, loss: 0.6735 ||:  29%|##9       | 552/1875 [15:17<35:50,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5274, loss: 0.6732 ||:  29%|##9       | 553/1875 [15:18<34:52,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6680, loss: 0.6732 ||:  30%|##9       | 554/1875 [15:20<36:17,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5076, loss: 0.6729 ||:  30%|##9       | 555/1875 [15:21<35:28,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6298, loss: 0.6728 ||:  30%|##9       | 556/1875 [15:23<34:59,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5016, loss: 0.6725 ||:  30%|##9       | 557/1875 [15:25<34:57,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4377, loss: 0.6721 ||:  30%|##9       | 558/1875 [15:26<34:47,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5541, loss: 0.6719 ||:  30%|##9       | 559/1875 [15:28<35:13,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5120, loss: 0.6716 ||:  30%|##9       | 560/1875 [15:29<35:47,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6588, loss: 0.6716 ||:  30%|##9       | 561/1875 [15:31<35:42,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6796, loss: 0.6716 ||:  30%|##9       | 562/1875 [15:33<35:39,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6050, loss: 0.6715 ||:  30%|###       | 563/1875 [15:35<37:24,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4618, loss: 0.6711 ||:  30%|###       | 564/1875 [15:36<35:53,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4988, loss: 0.6708 ||:  30%|###       | 565/1875 [15:38<36:07,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6835, loss: 0.6708 ||:  30%|###       | 566/1875 [15:39<35:31,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5607, loss: 0.6706 ||:  30%|###       | 567/1875 [15:41<36:09,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4941, loss: 0.6703 ||:  30%|###       | 568/1875 [15:43<35:54,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6416, loss: 0.6702 ||:  30%|###       | 569/1875 [15:44<35:27,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5101, loss: 0.6700 ||:  30%|###       | 570/1875 [15:46<34:39,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6106, loss: 0.6699 ||:  30%|###       | 571/1875 [15:48<35:08,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5937, loss: 0.6697 ||:  31%|###       | 572/1875 [15:49<34:29,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5101, loss: 0.6695 ||:  31%|###       | 573/1875 [15:51<34:57,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6067, loss: 0.6693 ||:  31%|###       | 574/1875 [15:52<35:26,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5725, loss: 0.6692 ||:  31%|###       | 575/1875 [15:54<35:55,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5203, loss: 0.6689 ||:  31%|###       | 576/1875 [15:56<37:15,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5414, loss: 0.6687 ||:  31%|###       | 577/1875 [15:58<37:49,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.3859, loss: 0.6682 ||:  31%|###       | 578/1875 [16:00<38:04,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4925, loss: 0.6679 ||:  31%|###       | 579/1875 [16:01<38:44,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4971, loss: 0.6676 ||:  31%|###       | 580/1875 [16:03<38:19,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5652, loss: 0.6674 ||:  31%|###       | 581/1875 [16:05<37:55,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5541, loss: 0.6672 ||:  31%|###1      | 582/1875 [16:07<37:36,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6029, loss: 0.6671 ||:  31%|###1      | 583/1875 [16:08<37:42,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5683, loss: 0.6670 ||:  31%|###1      | 584/1875 [16:10<36:47,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.3997, loss: 0.6665 ||:  31%|###1      | 585/1875 [16:12<35:51,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5828, loss: 0.6664 ||:  31%|###1      | 586/1875 [16:13<36:37,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4899, loss: 0.6661 ||:  31%|###1      | 587/1875 [16:15<37:36,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4264, loss: 0.6656 ||:  31%|###1      | 588/1875 [16:17<38:26,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4803, loss: 0.6653 ||:  31%|###1      | 589/1875 [16:19<37:56,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.6382, loss: 0.6653 ||:  31%|###1      | 590/1875 [16:21<38:23,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5323, loss: 0.6651 ||:  32%|###1      | 591/1875 [16:22<38:15,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5265, loss: 0.6648 ||:  32%|###1      | 592/1875 [16:24<38:18,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6727, loss: 0.6648 ||:  32%|###1      | 593/1875 [16:26<37:23,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4499, loss: 0.6645 ||:  32%|###1      | 594/1875 [16:28<38:12,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5509, loss: 0.6643 ||:  32%|###1      | 595/1875 [16:30<38:06,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5190, loss: 0.6640 ||:  32%|###1      | 596/1875 [16:31<38:30,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.6749, loss: 0.6641 ||:  32%|###1      | 597/1875 [16:33<38:04,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6146, loss: 0.6640 ||:  32%|###1      | 598/1875 [16:35<37:58,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6541, loss: 0.6640 ||:  32%|###1      | 599/1875 [16:37<38:57,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5488, loss: 0.6638 ||:  32%|###2      | 600/1875 [16:39<43:10,  2.03s/it]final_beam_acc: 0.0000, batch_loss: 0.6733, loss: 0.6638 ||:  32%|###2      | 601/1875 [16:41<41:17,  1.94s/it]final_beam_acc: 0.0000, batch_loss: 0.7348, loss: 0.6639 ||:  32%|###2      | 602/1875 [16:43<40:05,  1.89s/it]final_beam_acc: 0.0000, batch_loss: 0.5681, loss: 0.6637 ||:  32%|###2      | 603/1875 [16:45<38:41,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.6785, loss: 0.6638 ||:  32%|###2      | 604/1875 [16:46<38:26,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.5953, loss: 0.6637 ||:  32%|###2      | 605/1875 [16:48<38:43,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.4728, loss: 0.6633 ||:  32%|###2      | 606/1875 [16:50<38:19,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4855, loss: 0.6631 ||:  32%|###2      | 607/1875 [16:52<37:37,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6347, loss: 0.6630 ||:  32%|###2      | 608/1875 [16:54<38:30,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5774, loss: 0.6629 ||:  32%|###2      | 609/1875 [16:55<37:54,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.6247, loss: 0.6628 ||:  33%|###2      | 610/1875 [16:57<37:26,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5768, loss: 0.6627 ||:  33%|###2      | 611/1875 [16:59<37:26,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4487, loss: 0.6623 ||:  33%|###2      | 612/1875 [17:01<37:29,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4355, loss: 0.6619 ||:  33%|###2      | 613/1875 [17:02<36:59,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4773, loss: 0.6616 ||:  33%|###2      | 614/1875 [17:04<36:37,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4050, loss: 0.6612 ||:  33%|###2      | 615/1875 [17:06<37:38,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6159, loss: 0.6611 ||:  33%|###2      | 616/1875 [17:08<39:14,  1.87s/it]final_beam_acc: 0.0000, batch_loss: 0.5136, loss: 0.6609 ||:  33%|###2      | 617/1875 [17:10<38:52,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5121, loss: 0.6607 ||:  33%|###2      | 618/1875 [17:12<39:04,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.5039, loss: 0.6604 ||:  33%|###3      | 619/1875 [17:13<37:51,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4358, loss: 0.6601 ||:  33%|###3      | 620/1875 [17:15<37:36,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5872, loss: 0.6599 ||:  33%|###3      | 621/1875 [17:17<37:35,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4756, loss: 0.6596 ||:  33%|###3      | 622/1875 [17:19<37:28,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5075, loss: 0.6594 ||:  33%|###3      | 623/1875 [17:21<38:28,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5980, loss: 0.6593 ||:  33%|###3      | 624/1875 [17:23<38:35,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5128, loss: 0.6591 ||:  33%|###3      | 625/1875 [17:24<37:58,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5227, loss: 0.6588 ||:  33%|###3      | 626/1875 [17:26<37:24,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.3551, loss: 0.6584 ||:  33%|###3      | 627/1875 [17:28<37:14,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5663, loss: 0.6582 ||:  33%|###3      | 628/1875 [17:30<37:09,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4520, loss: 0.6579 ||:  34%|###3      | 629/1875 [17:31<36:22,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5976, loss: 0.6578 ||:  34%|###3      | 630/1875 [17:33<36:48,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4379, loss: 0.6574 ||:  34%|###3      | 631/1875 [17:35<37:11,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4494, loss: 0.6571 ||:  34%|###3      | 632/1875 [17:37<37:28,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4407, loss: 0.6568 ||:  34%|###3      | 633/1875 [17:38<36:44,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5093, loss: 0.6565 ||:  34%|###3      | 634/1875 [17:42<47:21,  2.29s/it]final_beam_acc: 0.0000, batch_loss: 0.5326, loss: 0.6563 ||:  34%|###3      | 635/1875 [17:44<44:47,  2.17s/it]final_beam_acc: 0.0000, batch_loss: 0.4100, loss: 0.6560 ||:  34%|###3      | 636/1875 [17:46<42:26,  2.06s/it]final_beam_acc: 0.0000, batch_loss: 0.5222, loss: 0.6557 ||:  34%|###3      | 637/1875 [17:48<41:13,  2.00s/it]final_beam_acc: 0.0000, batch_loss: 0.5008, loss: 0.6555 ||:  34%|###4      | 638/1875 [17:49<40:18,  1.96s/it]final_beam_acc: 0.0000, batch_loss: 0.6184, loss: 0.6554 ||:  34%|###4      | 639/1875 [17:51<39:54,  1.94s/it]final_beam_acc: 0.0000, batch_loss: 0.5235, loss: 0.6552 ||:  34%|###4      | 640/1875 [17:53<39:31,  1.92s/it]final_beam_acc: 0.0000, batch_loss: 0.5277, loss: 0.6550 ||:  34%|###4      | 641/1875 [17:55<38:09,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.7071, loss: 0.6551 ||:  34%|###4      | 642/1875 [17:57<37:19,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5180, loss: 0.6549 ||:  34%|###4      | 643/1875 [17:58<37:03,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5945, loss: 0.6548 ||:  34%|###4      | 644/1875 [18:00<36:09,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.7307, loss: 0.6549 ||:  34%|###4      | 645/1875 [18:02<37:04,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.5689, loss: 0.6548 ||:  34%|###4      | 646/1875 [18:04<37:14,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.6617, loss: 0.6548 ||:  35%|###4      | 647/1875 [18:05<36:34,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5646, loss: 0.6547 ||:  35%|###4      | 648/1875 [18:07<35:48,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4978, loss: 0.6544 ||:  35%|###4      | 649/1875 [18:09<35:03,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4560, loss: 0.6541 ||:  35%|###4      | 650/1875 [18:10<34:06,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5425, loss: 0.6540 ||:  35%|###4      | 651/1875 [18:12<34:29,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4554, loss: 0.6536 ||:  35%|###4      | 652/1875 [18:14<34:37,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4921, loss: 0.6534 ||:  35%|###4      | 653/1875 [18:16<35:04,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6054, loss: 0.6533 ||:  35%|###4      | 654/1875 [18:17<35:42,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6428, loss: 0.6533 ||:  35%|###4      | 655/1875 [18:19<36:03,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5064, loss: 0.6531 ||:  35%|###4      | 656/1875 [18:21<34:35,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5150, loss: 0.6529 ||:  35%|###5      | 657/1875 [18:22<34:32,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4948, loss: 0.6526 ||:  35%|###5      | 658/1875 [18:24<34:25,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5784, loss: 0.6525 ||:  35%|###5      | 659/1875 [18:26<35:20,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5067, loss: 0.6523 ||:  35%|###5      | 660/1875 [18:28<34:38,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6396, loss: 0.6523 ||:  35%|###5      | 661/1875 [18:29<34:26,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4969, loss: 0.6520 ||:  35%|###5      | 662/1875 [18:31<34:01,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5232, loss: 0.6519 ||:  35%|###5      | 663/1875 [18:33<34:19,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6008, loss: 0.6518 ||:  35%|###5      | 664/1875 [18:34<33:54,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6019, loss: 0.6517 ||:  35%|###5      | 665/1875 [18:36<35:34,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5693, loss: 0.6516 ||:  36%|###5      | 666/1875 [18:38<34:43,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6516, loss: 0.6516 ||:  36%|###5      | 667/1875 [18:40<34:27,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6520, loss: 0.6516 ||:  36%|###5      | 668/1875 [18:41<34:44,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5137, loss: 0.6514 ||:  36%|###5      | 669/1875 [18:43<33:53,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4670, loss: 0.6511 ||:  36%|###5      | 670/1875 [18:44<32:55,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6479, loss: 0.6511 ||:  36%|###5      | 671/1875 [18:46<33:34,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5328, loss: 0.6509 ||:  36%|###5      | 672/1875 [18:48<33:24,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5148, loss: 0.6507 ||:  36%|###5      | 673/1875 [18:50<34:16,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5802, loss: 0.6506 ||:  36%|###5      | 674/1875 [18:51<34:01,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5039, loss: 0.6504 ||:  36%|###6      | 675/1875 [18:53<33:18,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5546, loss: 0.6503 ||:  36%|###6      | 676/1875 [18:55<33:54,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5270, loss: 0.6501 ||:  36%|###6      | 677/1875 [18:56<33:41,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5018, loss: 0.6499 ||:  36%|###6      | 678/1875 [18:58<33:21,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6709, loss: 0.6499 ||:  36%|###6      | 679/1875 [19:00<33:04,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4751, loss: 0.6496 ||:  36%|###6      | 680/1875 [19:01<32:48,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6560, loss: 0.6496 ||:  36%|###6      | 681/1875 [19:03<33:33,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5056, loss: 0.6494 ||:  36%|###6      | 682/1875 [19:05<33:21,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5295, loss: 0.6492 ||:  36%|###6      | 683/1875 [19:06<32:54,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4942, loss: 0.6490 ||:  36%|###6      | 684/1875 [19:08<33:56,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6102, loss: 0.6490 ||:  37%|###6      | 685/1875 [19:10<33:42,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5137, loss: 0.6488 ||:  37%|###6      | 686/1875 [19:12<33:59,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.3971, loss: 0.6484 ||:  37%|###6      | 687/1875 [19:13<32:56,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5440, loss: 0.6482 ||:  37%|###6      | 688/1875 [19:15<33:07,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6571, loss: 0.6483 ||:  37%|###6      | 689/1875 [19:17<33:25,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6409, loss: 0.6483 ||:  37%|###6      | 690/1875 [19:18<33:06,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6000, loss: 0.6482 ||:  37%|###6      | 691/1875 [19:20<34:22,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5546, loss: 0.6480 ||:  37%|###6      | 692/1875 [19:22<34:51,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5733, loss: 0.6479 ||:  37%|###6      | 693/1875 [19:24<34:01,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4736, loss: 0.6477 ||:  37%|###7      | 694/1875 [19:25<34:14,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5411, loss: 0.6475 ||:  37%|###7      | 695/1875 [19:27<34:29,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5740, loss: 0.6474 ||:  37%|###7      | 696/1875 [19:29<34:39,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5681, loss: 0.6473 ||:  37%|###7      | 697/1875 [19:31<34:19,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4498, loss: 0.6470 ||:  37%|###7      | 698/1875 [19:32<33:45,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5048, loss: 0.6468 ||:  37%|###7      | 699/1875 [19:34<33:51,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5740, loss: 0.6467 ||:  37%|###7      | 700/1875 [19:36<36:41,  1.87s/it]final_beam_acc: 0.0000, batch_loss: 0.6351, loss: 0.6467 ||:  37%|###7      | 701/1875 [19:38<35:59,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.4988, loss: 0.6465 ||:  37%|###7      | 702/1875 [19:40<34:45,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4606, loss: 0.6462 ||:  37%|###7      | 703/1875 [19:41<33:21,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5913, loss: 0.6462 ||:  38%|###7      | 704/1875 [19:43<33:30,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4578, loss: 0.6459 ||:  38%|###7      | 705/1875 [19:44<32:39,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5142, loss: 0.6457 ||:  38%|###7      | 706/1875 [19:46<32:02,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6232, loss: 0.6457 ||:  38%|###7      | 707/1875 [19:48<32:49,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5254, loss: 0.6455 ||:  38%|###7      | 708/1875 [19:49<32:35,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5791, loss: 0.6454 ||:  38%|###7      | 709/1875 [19:51<32:59,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6141, loss: 0.6454 ||:  38%|###7      | 710/1875 [19:53<33:08,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5967, loss: 0.6453 ||:  38%|###7      | 711/1875 [19:55<33:22,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6020, loss: 0.6452 ||:  38%|###7      | 712/1875 [19:56<33:24,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5320, loss: 0.6451 ||:  38%|###8      | 713/1875 [19:58<33:54,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6339, loss: 0.6451 ||:  38%|###8      | 714/1875 [20:00<32:46,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5158, loss: 0.6449 ||:  38%|###8      | 715/1875 [20:01<32:33,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5769, loss: 0.6448 ||:  38%|###8      | 716/1875 [20:03<32:08,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4401, loss: 0.6445 ||:  38%|###8      | 717/1875 [20:05<33:08,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4518, loss: 0.6442 ||:  38%|###8      | 718/1875 [20:07<33:22,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6144, loss: 0.6442 ||:  38%|###8      | 719/1875 [20:08<32:41,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4691, loss: 0.6439 ||:  38%|###8      | 720/1875 [20:10<32:18,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4617, loss: 0.6437 ||:  38%|###8      | 721/1875 [20:12<33:21,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5253, loss: 0.6435 ||:  39%|###8      | 722/1875 [20:14<33:19,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4926, loss: 0.6433 ||:  39%|###8      | 723/1875 [20:15<33:06,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6390, loss: 0.6433 ||:  39%|###8      | 724/1875 [20:17<33:11,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5819, loss: 0.6432 ||:  39%|###8      | 725/1875 [20:19<33:33,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6234, loss: 0.6432 ||:  39%|###8      | 726/1875 [20:21<33:41,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5323, loss: 0.6430 ||:  39%|###8      | 727/1875 [20:22<32:47,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5758, loss: 0.6430 ||:  39%|###8      | 728/1875 [20:24<34:21,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5656, loss: 0.6428 ||:  39%|###8      | 729/1875 [20:26<33:50,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.6026, loss: 0.6428 ||:  39%|###8      | 730/1875 [20:28<33:04,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5292, loss: 0.6426 ||:  39%|###8      | 731/1875 [20:29<32:33,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4699, loss: 0.6424 ||:  39%|###9      | 732/1875 [20:31<32:51,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5136, loss: 0.6422 ||:  39%|###9      | 733/1875 [20:33<32:34,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5785, loss: 0.6421 ||:  39%|###9      | 734/1875 [20:34<32:28,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4869, loss: 0.6419 ||:  39%|###9      | 735/1875 [20:36<33:13,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6136, loss: 0.6419 ||:  39%|###9      | 736/1875 [20:38<32:53,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5138, loss: 0.6417 ||:  39%|###9      | 737/1875 [20:40<32:58,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6183, loss: 0.6417 ||:  39%|###9      | 738/1875 [20:41<32:22,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6706, loss: 0.6417 ||:  39%|###9      | 739/1875 [20:43<32:19,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5400, loss: 0.6416 ||:  39%|###9      | 740/1875 [20:45<32:08,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5207, loss: 0.6414 ||:  40%|###9      | 741/1875 [20:46<32:26,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4835, loss: 0.6412 ||:  40%|###9      | 742/1875 [20:48<32:00,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4901, loss: 0.6410 ||:  40%|###9      | 743/1875 [20:50<32:04,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4928, loss: 0.6408 ||:  40%|###9      | 744/1875 [20:52<32:37,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5279, loss: 0.6407 ||:  40%|###9      | 745/1875 [20:53<32:18,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5749, loss: 0.6406 ||:  40%|###9      | 746/1875 [20:55<31:27,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5185, loss: 0.6404 ||:  40%|###9      | 747/1875 [20:56<30:55,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5319, loss: 0.6403 ||:  40%|###9      | 748/1875 [20:58<31:49,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3819, loss: 0.6399 ||:  40%|###9      | 749/1875 [21:00<31:50,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5998, loss: 0.6399 ||:  40%|####      | 750/1875 [21:02<32:31,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4737, loss: 0.6396 ||:  40%|####      | 751/1875 [21:03<32:12,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6312, loss: 0.6396 ||:  40%|####      | 752/1875 [21:05<33:01,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.6531, loss: 0.6396 ||:  40%|####      | 753/1875 [21:07<33:00,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4958, loss: 0.6395 ||:  40%|####      | 754/1875 [21:09<32:05,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4184, loss: 0.6392 ||:  40%|####      | 755/1875 [21:10<31:21,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5635, loss: 0.6391 ||:  40%|####      | 756/1875 [21:12<31:36,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4934, loss: 0.6389 ||:  40%|####      | 757/1875 [21:14<31:27,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5406, loss: 0.6387 ||:  40%|####      | 758/1875 [21:15<31:36,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5474, loss: 0.6386 ||:  40%|####      | 759/1875 [21:17<31:03,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4465, loss: 0.6384 ||:  41%|####      | 760/1875 [21:19<30:57,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.7400, loss: 0.6385 ||:  41%|####      | 761/1875 [21:20<30:59,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6577, loss: 0.6385 ||:  41%|####      | 762/1875 [21:22<31:14,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5136, loss: 0.6384 ||:  41%|####      | 763/1875 [21:24<31:57,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4555, loss: 0.6381 ||:  41%|####      | 764/1875 [21:25<31:18,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4836, loss: 0.6379 ||:  41%|####      | 765/1875 [21:27<31:28,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4473, loss: 0.6377 ||:  41%|####      | 766/1875 [21:29<32:36,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5275, loss: 0.6375 ||:  41%|####      | 767/1875 [21:31<32:04,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5819, loss: 0.6375 ||:  41%|####      | 768/1875 [21:32<31:46,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6283, loss: 0.6374 ||:  41%|####1     | 769/1875 [21:34<32:40,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4511, loss: 0.6372 ||:  41%|####1     | 770/1875 [21:36<31:26,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5924, loss: 0.6371 ||:  41%|####1     | 771/1875 [21:38<31:00,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4884, loss: 0.6370 ||:  41%|####1     | 772/1875 [21:39<30:51,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5124, loss: 0.6368 ||:  41%|####1     | 773/1875 [21:41<30:47,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3912, loss: 0.6365 ||:  41%|####1     | 774/1875 [21:42<30:10,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5054, loss: 0.6363 ||:  41%|####1     | 775/1875 [21:44<30:15,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5234, loss: 0.6362 ||:  41%|####1     | 776/1875 [21:46<30:54,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5610, loss: 0.6361 ||:  41%|####1     | 777/1875 [21:48<31:35,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6655, loss: 0.6361 ||:  41%|####1     | 778/1875 [21:49<30:45,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4349, loss: 0.6358 ||:  42%|####1     | 779/1875 [21:51<30:52,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4548, loss: 0.6356 ||:  42%|####1     | 780/1875 [21:53<31:12,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4171, loss: 0.6353 ||:  42%|####1     | 781/1875 [21:54<31:04,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5040, loss: 0.6352 ||:  42%|####1     | 782/1875 [21:56<30:49,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4805, loss: 0.6350 ||:  42%|####1     | 783/1875 [21:58<30:26,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3977, loss: 0.6347 ||:  42%|####1     | 784/1875 [21:59<30:58,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5857, loss: 0.6346 ||:  42%|####1     | 785/1875 [22:01<30:23,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6051, loss: 0.6346 ||:  42%|####1     | 786/1875 [22:03<30:15,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4198, loss: 0.6343 ||:  42%|####1     | 787/1875 [22:04<30:07,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6826, loss: 0.6343 ||:  42%|####2     | 788/1875 [22:06<29:45,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4948, loss: 0.6342 ||:  42%|####2     | 789/1875 [22:08<30:32,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4963, loss: 0.6340 ||:  42%|####2     | 790/1875 [22:09<30:16,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5643, loss: 0.6339 ||:  42%|####2     | 791/1875 [22:11<30:24,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6776, loss: 0.6340 ||:  42%|####2     | 792/1875 [22:13<30:36,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5073, loss: 0.6338 ||:  42%|####2     | 793/1875 [22:15<30:27,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4723, loss: 0.6336 ||:  42%|####2     | 794/1875 [22:16<29:59,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4905, loss: 0.6334 ||:  42%|####2     | 795/1875 [22:18<29:46,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4950, loss: 0.6332 ||:  42%|####2     | 796/1875 [22:19<29:42,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5071, loss: 0.6331 ||:  43%|####2     | 797/1875 [22:21<29:58,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3739, loss: 0.6328 ||:  43%|####2     | 798/1875 [22:23<30:27,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5951, loss: 0.6327 ||:  43%|####2     | 799/1875 [22:25<30:37,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5718, loss: 0.6326 ||:  43%|####2     | 800/1875 [22:27<34:09,  1.91s/it]final_beam_acc: 0.0000, batch_loss: 0.6266, loss: 0.6326 ||:  43%|####2     | 801/1875 [22:29<33:40,  1.88s/it]final_beam_acc: 0.0000, batch_loss: 0.4959, loss: 0.6325 ||:  43%|####2     | 802/1875 [22:31<32:46,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.6576, loss: 0.6325 ||:  43%|####2     | 803/1875 [22:32<32:30,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.6223, loss: 0.6325 ||:  43%|####2     | 804/1875 [22:34<31:28,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4416, loss: 0.6322 ||:  43%|####2     | 805/1875 [22:36<30:32,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6021, loss: 0.6322 ||:  43%|####2     | 806/1875 [22:37<30:36,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5942, loss: 0.6322 ||:  43%|####3     | 807/1875 [22:39<30:56,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5316, loss: 0.6320 ||:  43%|####3     | 808/1875 [22:41<30:55,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5401, loss: 0.6319 ||:  43%|####3     | 809/1875 [22:42<30:20,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5821, loss: 0.6319 ||:  43%|####3     | 810/1875 [22:44<29:35,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5584, loss: 0.6318 ||:  43%|####3     | 811/1875 [22:46<29:59,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5641, loss: 0.6317 ||:  43%|####3     | 812/1875 [22:47<29:57,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5568, loss: 0.6316 ||:  43%|####3     | 813/1875 [22:49<30:14,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5263, loss: 0.6315 ||:  43%|####3     | 814/1875 [22:51<30:56,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4997, loss: 0.6313 ||:  43%|####3     | 815/1875 [22:53<30:39,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4643, loss: 0.6311 ||:  44%|####3     | 816/1875 [22:55<31:27,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6888, loss: 0.6312 ||:  44%|####3     | 817/1875 [22:56<31:20,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5125, loss: 0.6310 ||:  44%|####3     | 818/1875 [22:58<31:08,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4367, loss: 0.6308 ||:  44%|####3     | 819/1875 [23:00<30:24,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5658, loss: 0.6307 ||:  44%|####3     | 820/1875 [23:02<30:26,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4426, loss: 0.6305 ||:  44%|####3     | 821/1875 [23:03<29:37,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5619, loss: 0.6304 ||:  44%|####3     | 822/1875 [23:05<29:00,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5534, loss: 0.6303 ||:  44%|####3     | 823/1875 [23:06<29:21,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5492, loss: 0.6302 ||:  44%|####3     | 824/1875 [23:08<28:56,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5051, loss: 0.6301 ||:  44%|####4     | 825/1875 [23:10<28:53,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4699, loss: 0.6299 ||:  44%|####4     | 826/1875 [23:11<28:26,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5655, loss: 0.6298 ||:  44%|####4     | 827/1875 [23:13<29:12,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5327, loss: 0.6297 ||:  44%|####4     | 828/1875 [23:15<29:30,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5338, loss: 0.6295 ||:  44%|####4     | 829/1875 [23:16<29:26,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4087, loss: 0.6293 ||:  44%|####4     | 830/1875 [23:18<30:05,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4878, loss: 0.6291 ||:  44%|####4     | 831/1875 [23:20<29:56,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6228, loss: 0.6291 ||:  44%|####4     | 832/1875 [23:22<29:37,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5884, loss: 0.6291 ||:  44%|####4     | 833/1875 [23:23<29:02,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6419, loss: 0.6291 ||:  44%|####4     | 834/1875 [23:25<29:00,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4577, loss: 0.6289 ||:  45%|####4     | 835/1875 [23:26<28:31,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6197, loss: 0.6289 ||:  45%|####4     | 836/1875 [23:28<28:01,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4643, loss: 0.6287 ||:  45%|####4     | 837/1875 [23:30<28:02,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4431, loss: 0.6284 ||:  45%|####4     | 838/1875 [23:31<28:17,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6354, loss: 0.6284 ||:  45%|####4     | 839/1875 [23:33<28:26,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6328, loss: 0.6284 ||:  45%|####4     | 840/1875 [23:35<28:12,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4605, loss: 0.6282 ||:  45%|####4     | 841/1875 [23:36<27:58,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4545, loss: 0.6280 ||:  45%|####4     | 842/1875 [23:38<27:51,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4472, loss: 0.6278 ||:  45%|####4     | 843/1875 [23:39<28:05,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5939, loss: 0.6278 ||:  45%|####5     | 844/1875 [23:41<28:19,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5104, loss: 0.6276 ||:  45%|####5     | 845/1875 [23:43<28:48,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4952, loss: 0.6275 ||:  45%|####5     | 846/1875 [23:45<28:59,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5893, loss: 0.6274 ||:  45%|####5     | 847/1875 [23:46<29:11,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5470, loss: 0.6274 ||:  45%|####5     | 848/1875 [23:48<28:48,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4302, loss: 0.6271 ||:  45%|####5     | 849/1875 [23:49<27:48,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5835, loss: 0.6271 ||:  45%|####5     | 850/1875 [23:51<27:17,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5951, loss: 0.6270 ||:  45%|####5     | 851/1875 [23:53<27:54,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6014, loss: 0.6270 ||:  45%|####5     | 852/1875 [23:54<27:29,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4122, loss: 0.6267 ||:  45%|####5     | 853/1875 [23:56<26:38,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4152, loss: 0.6265 ||:  46%|####5     | 854/1875 [23:57<27:10,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6874, loss: 0.6266 ||:  46%|####5     | 855/1875 [23:59<27:07,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4995, loss: 0.6264 ||:  46%|####5     | 856/1875 [24:01<26:55,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4464, loss: 0.6262 ||:  46%|####5     | 857/1875 [24:02<27:04,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5248, loss: 0.6261 ||:  46%|####5     | 858/1875 [24:04<27:07,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4752, loss: 0.6259 ||:  46%|####5     | 859/1875 [24:05<27:25,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5919, loss: 0.6259 ||:  46%|####5     | 860/1875 [24:07<27:56,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4190, loss: 0.6256 ||:  46%|####5     | 861/1875 [24:09<27:04,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5526, loss: 0.6256 ||:  46%|####5     | 862/1875 [24:10<26:43,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4211, loss: 0.6253 ||:  46%|####6     | 863/1875 [24:12<27:26,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5485, loss: 0.6252 ||:  46%|####6     | 864/1875 [24:14<27:32,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5031, loss: 0.6251 ||:  46%|####6     | 865/1875 [24:15<27:17,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5030, loss: 0.6249 ||:  46%|####6     | 866/1875 [24:17<28:44,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4188, loss: 0.6247 ||:  46%|####6     | 867/1875 [24:19<28:13,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5806, loss: 0.6247 ||:  46%|####6     | 868/1875 [24:20<28:11,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3956, loss: 0.6244 ||:  46%|####6     | 869/1875 [24:22<27:47,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6124, loss: 0.6244 ||:  46%|####6     | 870/1875 [24:24<27:28,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6110, loss: 0.6244 ||:  46%|####6     | 871/1875 [24:25<27:32,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4765, loss: 0.6242 ||:  47%|####6     | 872/1875 [24:27<26:55,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5686, loss: 0.6241 ||:  47%|####6     | 873/1875 [24:28<26:47,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6053, loss: 0.6241 ||:  47%|####6     | 874/1875 [24:30<27:29,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5618, loss: 0.6240 ||:  47%|####6     | 875/1875 [24:32<27:09,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4589, loss: 0.6239 ||:  47%|####6     | 876/1875 [24:34<28:33,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4852, loss: 0.6237 ||:  47%|####6     | 877/1875 [24:35<28:07,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6108, loss: 0.6237 ||:  47%|####6     | 878/1875 [24:37<27:47,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4860, loss: 0.6235 ||:  47%|####6     | 879/1875 [24:38<27:04,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5996, loss: 0.6235 ||:  47%|####6     | 880/1875 [24:40<27:18,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6386, loss: 0.6235 ||:  47%|####6     | 881/1875 [24:42<26:43,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4972, loss: 0.6234 ||:  47%|####7     | 882/1875 [24:43<26:48,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6469, loss: 0.6234 ||:  47%|####7     | 883/1875 [24:45<26:48,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5457, loss: 0.6233 ||:  47%|####7     | 884/1875 [24:47<27:14,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5376, loss: 0.6232 ||:  47%|####7     | 885/1875 [24:48<27:22,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5214, loss: 0.6231 ||:  47%|####7     | 886/1875 [24:50<28:00,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4548, loss: 0.6229 ||:  47%|####7     | 887/1875 [24:52<27:50,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7430, loss: 0.6230 ||:  47%|####7     | 888/1875 [24:54<28:50,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4422, loss: 0.6228 ||:  47%|####7     | 889/1875 [24:55<28:03,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6243, loss: 0.6228 ||:  47%|####7     | 890/1875 [24:57<28:37,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5241, loss: 0.6227 ||:  48%|####7     | 891/1875 [24:59<27:24,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3680, loss: 0.6224 ||:  48%|####7     | 892/1875 [25:00<27:29,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4428, loss: 0.6222 ||:  48%|####7     | 893/1875 [25:02<27:18,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5741, loss: 0.6222 ||:  48%|####7     | 894/1875 [25:04<26:50,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4098, loss: 0.6220 ||:  48%|####7     | 895/1875 [25:05<25:58,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5679, loss: 0.6219 ||:  48%|####7     | 896/1875 [25:07<26:05,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5282, loss: 0.6218 ||:  48%|####7     | 897/1875 [25:08<26:27,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6062, loss: 0.6218 ||:  48%|####7     | 898/1875 [25:10<26:24,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4670, loss: 0.6216 ||:  48%|####7     | 899/1875 [25:12<26:24,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5029, loss: 0.6215 ||:  48%|####8     | 900/1875 [25:14<29:33,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5375, loss: 0.6214 ||:  48%|####8     | 901/1875 [25:15<28:52,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6078, loss: 0.6214 ||:  48%|####8     | 902/1875 [25:17<28:13,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5411, loss: 0.6213 ||:  48%|####8     | 903/1875 [25:19<27:22,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5264, loss: 0.6212 ||:  48%|####8     | 904/1875 [25:20<26:26,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5799, loss: 0.6211 ||:  48%|####8     | 905/1875 [25:22<25:52,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5272, loss: 0.6210 ||:  48%|####8     | 906/1875 [25:23<26:00,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4713, loss: 0.6208 ||:  48%|####8     | 907/1875 [25:25<25:49,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.7063, loss: 0.6209 ||:  48%|####8     | 908/1875 [25:27<25:43,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4566, loss: 0.6208 ||:  48%|####8     | 909/1875 [25:28<25:30,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6003, loss: 0.6207 ||:  49%|####8     | 910/1875 [25:30<26:23,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5165, loss: 0.6206 ||:  49%|####8     | 911/1875 [25:32<26:42,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4723, loss: 0.6205 ||:  49%|####8     | 912/1875 [25:33<26:08,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5371, loss: 0.6204 ||:  49%|####8     | 913/1875 [25:35<26:10,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5901, loss: 0.6203 ||:  49%|####8     | 914/1875 [25:36<25:35,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5689, loss: 0.6203 ||:  49%|####8     | 915/1875 [25:38<26:39,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5925, loss: 0.6203 ||:  49%|####8     | 916/1875 [25:40<26:37,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6662, loss: 0.6203 ||:  49%|####8     | 917/1875 [25:41<25:54,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4195, loss: 0.6201 ||:  49%|####8     | 918/1875 [25:43<25:21,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5109, loss: 0.6200 ||:  49%|####9     | 919/1875 [25:44<25:13,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5079, loss: 0.6198 ||:  49%|####9     | 920/1875 [25:46<25:58,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6003, loss: 0.6198 ||:  49%|####9     | 921/1875 [25:48<26:14,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4335, loss: 0.6196 ||:  49%|####9     | 922/1875 [25:50<26:36,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5938, loss: 0.6196 ||:  49%|####9     | 923/1875 [25:51<26:07,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4369, loss: 0.6194 ||:  49%|####9     | 924/1875 [25:53<26:27,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4817, loss: 0.6192 ||:  49%|####9     | 925/1875 [25:55<26:40,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3996, loss: 0.6190 ||:  49%|####9     | 926/1875 [25:56<26:22,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5063, loss: 0.6189 ||:  49%|####9     | 927/1875 [25:58<25:13,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5292, loss: 0.6188 ||:  49%|####9     | 928/1875 [25:59<25:07,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5069, loss: 0.6187 ||:  50%|####9     | 929/1875 [26:01<26:11,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5657, loss: 0.6186 ||:  50%|####9     | 930/1875 [26:03<25:26,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6706, loss: 0.6187 ||:  50%|####9     | 931/1875 [26:04<25:22,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5212, loss: 0.6186 ||:  50%|####9     | 932/1875 [26:06<25:24,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5812, loss: 0.6185 ||:  50%|####9     | 933/1875 [26:07<25:21,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4741, loss: 0.6184 ||:  50%|####9     | 934/1875 [26:09<25:20,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6452, loss: 0.6184 ||:  50%|####9     | 935/1875 [26:11<25:00,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6385, loss: 0.6184 ||:  50%|####9     | 936/1875 [26:12<25:10,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4032, loss: 0.6182 ||:  50%|####9     | 937/1875 [26:14<25:16,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4639, loss: 0.6180 ||:  50%|#####     | 938/1875 [26:15<25:14,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5949, loss: 0.6180 ||:  50%|#####     | 939/1875 [26:17<25:08,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4377, loss: 0.6178 ||:  50%|#####     | 940/1875 [26:19<25:22,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4026, loss: 0.6176 ||:  50%|#####     | 941/1875 [26:20<24:48,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4545, loss: 0.6174 ||:  50%|#####     | 942/1875 [26:22<24:54,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6204, loss: 0.6174 ||:  50%|#####     | 943/1875 [26:24<25:14,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5640, loss: 0.6174 ||:  50%|#####     | 944/1875 [26:25<25:50,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5027, loss: 0.6172 ||:  50%|#####     | 945/1875 [26:27<26:05,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.7053, loss: 0.6173 ||:  50%|#####     | 946/1875 [26:29<25:18,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4974, loss: 0.6172 ||:  51%|#####     | 947/1875 [26:30<26:25,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4171, loss: 0.6170 ||:  51%|#####     | 948/1875 [26:32<25:27,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5699, loss: 0.6169 ||:  51%|#####     | 949/1875 [26:33<24:58,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5516, loss: 0.6169 ||:  51%|#####     | 950/1875 [26:35<24:51,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5279, loss: 0.6168 ||:  51%|#####     | 951/1875 [26:37<24:56,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6238, loss: 0.6168 ||:  51%|#####     | 952/1875 [26:38<24:38,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6079, loss: 0.6168 ||:  51%|#####     | 953/1875 [26:40<25:08,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4496, loss: 0.6166 ||:  51%|#####     | 954/1875 [26:42<24:54,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5639, loss: 0.6165 ||:  51%|#####     | 955/1875 [26:43<25:24,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4289, loss: 0.6163 ||:  51%|#####     | 956/1875 [26:45<25:39,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5919, loss: 0.6163 ||:  51%|#####1    | 957/1875 [26:47<25:05,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5295, loss: 0.6162 ||:  51%|#####1    | 958/1875 [26:48<25:01,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5237, loss: 0.6161 ||:  51%|#####1    | 959/1875 [26:50<25:13,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3991, loss: 0.6159 ||:  51%|#####1    | 960/1875 [26:52<25:12,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5942, loss: 0.6159 ||:  51%|#####1    | 961/1875 [26:53<25:01,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.3685, loss: 0.6156 ||:  51%|#####1    | 962/1875 [26:55<24:15,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4037, loss: 0.6154 ||:  51%|#####1    | 963/1875 [26:56<24:19,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5529, loss: 0.6153 ||:  51%|#####1    | 964/1875 [26:58<24:20,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4497, loss: 0.6152 ||:  51%|#####1    | 965/1875 [26:59<24:19,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4160, loss: 0.6150 ||:  52%|#####1    | 966/1875 [27:01<25:25,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6479, loss: 0.6150 ||:  52%|#####1    | 967/1875 [27:03<24:57,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4735, loss: 0.6149 ||:  52%|#####1    | 968/1875 [27:04<24:33,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4554, loss: 0.6147 ||:  52%|#####1    | 969/1875 [27:06<25:03,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.3875, loss: 0.6145 ||:  52%|#####1    | 970/1875 [27:08<24:27,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4796, loss: 0.6143 ||:  52%|#####1    | 971/1875 [27:09<24:24,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5180, loss: 0.6142 ||:  52%|#####1    | 972/1875 [27:11<24:34,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.7447, loss: 0.6144 ||:  52%|#####1    | 973/1875 [27:13<24:17,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4534, loss: 0.6142 ||:  52%|#####1    | 974/1875 [27:15<25:27,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5051, loss: 0.6141 ||:  52%|#####2    | 975/1875 [27:16<25:04,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5737, loss: 0.6140 ||:  52%|#####2    | 976/1875 [27:18<24:35,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5665, loss: 0.6140 ||:  52%|#####2    | 977/1875 [27:19<24:53,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4114, loss: 0.6138 ||:  52%|#####2    | 978/1875 [27:21<24:31,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4443, loss: 0.6136 ||:  52%|#####2    | 979/1875 [27:23<24:04,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5040, loss: 0.6135 ||:  52%|#####2    | 980/1875 [27:24<23:32,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6240, loss: 0.6135 ||:  52%|#####2    | 981/1875 [27:26<24:04,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4415, loss: 0.6133 ||:  52%|#####2    | 982/1875 [27:27<23:18,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.8424, loss: 0.6136 ||:  52%|#####2    | 983/1875 [27:29<23:48,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4843, loss: 0.6134 ||:  52%|#####2    | 984/1875 [27:31<23:57,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4873, loss: 0.6133 ||:  53%|#####2    | 985/1875 [27:32<24:12,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4587, loss: 0.6131 ||:  53%|#####2    | 986/1875 [27:34<24:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.7475, loss: 0.6133 ||:  53%|#####2    | 987/1875 [27:35<23:46,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5014, loss: 0.6132 ||:  53%|#####2    | 988/1875 [27:37<23:20,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.3405, loss: 0.6129 ||:  53%|#####2    | 989/1875 [27:38<22:52,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.5157, loss: 0.6128 ||:  53%|#####2    | 990/1875 [27:40<23:17,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5934, loss: 0.6128 ||:  53%|#####2    | 991/1875 [27:42<23:05,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6175, loss: 0.6128 ||:  53%|#####2    | 992/1875 [27:43<23:03,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6029, loss: 0.6128 ||:  53%|#####2    | 993/1875 [27:45<22:58,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4976, loss: 0.6127 ||:  53%|#####3    | 994/1875 [27:46<22:44,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.3712, loss: 0.6124 ||:  53%|#####3    | 995/1875 [27:48<23:01,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6299, loss: 0.6124 ||:  53%|#####3    | 996/1875 [27:50<24:17,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5150, loss: 0.6123 ||:  53%|#####3    | 997/1875 [27:51<24:03,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4882, loss: 0.6122 ||:  53%|#####3    | 998/1875 [27:53<25:00,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4784, loss: 0.6121 ||:  53%|#####3    | 999/1875 [27:55<24:47,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6156, loss: 0.6121 ||:  53%|#####3    | 1000/1875 [27:57<27:29,  1.89s/it]final_beam_acc: 0.0000, batch_loss: 0.3881, loss: 0.6119 ||:  53%|#####3    | 1001/1875 [27:59<26:13,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4094, loss: 0.6116 ||:  53%|#####3    | 1002/1875 [28:01<26:08,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4689, loss: 0.6115 ||:  53%|#####3    | 1003/1875 [28:02<25:45,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4931, loss: 0.6114 ||:  54%|#####3    | 1004/1875 [28:04<24:45,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4113, loss: 0.6112 ||:  54%|#####3    | 1005/1875 [28:05<24:04,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5125, loss: 0.6111 ||:  54%|#####3    | 1006/1875 [28:07<23:24,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6422, loss: 0.6111 ||:  54%|#####3    | 1007/1875 [28:09<23:30,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4730, loss: 0.6110 ||:  54%|#####3    | 1008/1875 [28:10<23:56,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5344, loss: 0.6109 ||:  54%|#####3    | 1009/1875 [28:12<23:30,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5657, loss: 0.6109 ||:  54%|#####3    | 1010/1875 [28:14<24:43,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5528, loss: 0.6108 ||:  54%|#####3    | 1011/1875 [28:15<24:39,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5294, loss: 0.6107 ||:  54%|#####3    | 1012/1875 [28:17<24:10,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5826, loss: 0.6107 ||:  54%|#####4    | 1013/1875 [28:19<23:32,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5576, loss: 0.6106 ||:  54%|#####4    | 1014/1875 [28:20<23:44,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5580, loss: 0.6106 ||:  54%|#####4    | 1015/1875 [28:22<23:22,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5238, loss: 0.6105 ||:  54%|#####4    | 1016/1875 [28:23<22:55,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5423, loss: 0.6104 ||:  54%|#####4    | 1017/1875 [28:25<23:02,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5168, loss: 0.6104 ||:  54%|#####4    | 1018/1875 [28:27<23:18,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5543, loss: 0.6103 ||:  54%|#####4    | 1019/1875 [28:28<23:23,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5957, loss: 0.6103 ||:  54%|#####4    | 1020/1875 [28:30<23:54,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.7054, loss: 0.6104 ||:  54%|#####4    | 1021/1875 [28:32<23:10,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5540, loss: 0.6103 ||:  55%|#####4    | 1022/1875 [28:33<23:31,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4911, loss: 0.6102 ||:  55%|#####4    | 1023/1875 [28:35<23:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5453, loss: 0.6101 ||:  55%|#####4    | 1024/1875 [28:37<22:57,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5557, loss: 0.6101 ||:  55%|#####4    | 1025/1875 [28:38<22:51,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5318, loss: 0.6100 ||:  55%|#####4    | 1026/1875 [28:40<23:06,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5782, loss: 0.6100 ||:  55%|#####4    | 1027/1875 [28:42<23:38,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5267, loss: 0.6099 ||:  55%|#####4    | 1028/1875 [28:43<23:24,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4673, loss: 0.6098 ||:  55%|#####4    | 1029/1875 [28:45<23:55,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5906, loss: 0.6097 ||:  55%|#####4    | 1030/1875 [28:47<24:38,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5464, loss: 0.6097 ||:  55%|#####4    | 1031/1875 [28:48<23:57,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4662, loss: 0.6095 ||:  55%|#####5    | 1032/1875 [28:50<23:40,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6536, loss: 0.6096 ||:  55%|#####5    | 1033/1875 [28:52<23:28,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5363, loss: 0.6095 ||:  55%|#####5    | 1034/1875 [28:53<23:38,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4525, loss: 0.6094 ||:  55%|#####5    | 1035/1875 [28:55<23:01,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5671, loss: 0.6093 ||:  55%|#####5    | 1036/1875 [28:57<25:50,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5413, loss: 0.6093 ||:  55%|#####5    | 1037/1875 [28:59<25:27,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5235, loss: 0.6092 ||:  55%|#####5    | 1038/1875 [29:01<25:13,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.6451, loss: 0.6092 ||:  55%|#####5    | 1039/1875 [29:02<24:22,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4753, loss: 0.6091 ||:  55%|#####5    | 1040/1875 [29:04<24:03,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4457, loss: 0.6089 ||:  56%|#####5    | 1041/1875 [29:06<22:48,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4660, loss: 0.6088 ||:  56%|#####5    | 1042/1875 [29:07<22:44,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4987, loss: 0.6087 ||:  56%|#####5    | 1043/1875 [29:09<22:38,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4114, loss: 0.6085 ||:  56%|#####5    | 1044/1875 [29:10<22:01,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6034, loss: 0.6085 ||:  56%|#####5    | 1045/1875 [29:12<22:01,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6927, loss: 0.6086 ||:  56%|#####5    | 1046/1875 [29:13<21:48,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6964, loss: 0.6086 ||:  56%|#####5    | 1047/1875 [29:15<21:32,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4905, loss: 0.6085 ||:  56%|#####5    | 1048/1875 [29:17<23:11,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5260, loss: 0.6085 ||:  56%|#####5    | 1049/1875 [29:19<23:10,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4569, loss: 0.6083 ||:  56%|#####6    | 1050/1875 [29:20<23:13,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5434, loss: 0.6083 ||:  56%|#####6    | 1051/1875 [29:22<23:03,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3447, loss: 0.6080 ||:  56%|#####6    | 1052/1875 [29:24<22:51,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5353, loss: 0.6079 ||:  56%|#####6    | 1053/1875 [29:25<23:08,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3782, loss: 0.6077 ||:  56%|#####6    | 1054/1875 [29:27<22:40,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6318, loss: 0.6077 ||:  56%|#####6    | 1055/1875 [29:29<22:42,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4822, loss: 0.6076 ||:  56%|#####6    | 1056/1875 [29:30<22:19,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4898, loss: 0.6075 ||:  56%|#####6    | 1057/1875 [29:32<22:08,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4175, loss: 0.6073 ||:  56%|#####6    | 1058/1875 [29:33<21:51,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5135, loss: 0.6072 ||:  56%|#####6    | 1059/1875 [29:35<21:55,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6275, loss: 0.6073 ||:  57%|#####6    | 1060/1875 [29:37<22:12,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6074, loss: 0.6073 ||:  57%|#####6    | 1061/1875 [29:38<22:05,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4407, loss: 0.6071 ||:  57%|#####6    | 1062/1875 [29:40<22:18,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4908, loss: 0.6070 ||:  57%|#####6    | 1063/1875 [29:42<22:00,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5998, loss: 0.6070 ||:  57%|#####6    | 1064/1875 [29:43<22:58,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4354, loss: 0.6068 ||:  57%|#####6    | 1065/1875 [29:45<22:09,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4663, loss: 0.6067 ||:  57%|#####6    | 1066/1875 [29:47<21:44,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6242, loss: 0.6067 ||:  57%|#####6    | 1067/1875 [29:48<22:05,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5148, loss: 0.6066 ||:  57%|#####6    | 1068/1875 [29:50<22:30,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4077, loss: 0.6064 ||:  57%|#####7    | 1069/1875 [29:52<22:16,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4217, loss: 0.6063 ||:  57%|#####7    | 1070/1875 [29:53<21:32,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5436, loss: 0.6062 ||:  57%|#####7    | 1071/1875 [29:55<21:26,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4115, loss: 0.6060 ||:  57%|#####7    | 1072/1875 [29:56<21:26,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5636, loss: 0.6060 ||:  57%|#####7    | 1073/1875 [29:58<22:02,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5055, loss: 0.6059 ||:  57%|#####7    | 1074/1875 [30:00<21:29,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4302, loss: 0.6057 ||:  57%|#####7    | 1075/1875 [30:01<21:22,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.8140, loss: 0.6059 ||:  57%|#####7    | 1076/1875 [30:03<22:24,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4377, loss: 0.6058 ||:  57%|#####7    | 1077/1875 [30:05<21:43,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5417, loss: 0.6057 ||:  57%|#####7    | 1078/1875 [30:06<21:57,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4902, loss: 0.6056 ||:  58%|#####7    | 1079/1875 [30:08<21:27,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6134, loss: 0.6056 ||:  58%|#####7    | 1080/1875 [30:09<21:33,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5858, loss: 0.6056 ||:  58%|#####7    | 1081/1875 [30:11<21:09,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6717, loss: 0.6056 ||:  58%|#####7    | 1082/1875 [30:13<21:48,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6204, loss: 0.6057 ||:  58%|#####7    | 1083/1875 [30:14<21:44,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4549, loss: 0.6055 ||:  58%|#####7    | 1084/1875 [30:16<21:38,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4239, loss: 0.6054 ||:  58%|#####7    | 1085/1875 [30:18<21:20,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5184, loss: 0.6053 ||:  58%|#####7    | 1086/1875 [30:19<21:43,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4845, loss: 0.6052 ||:  58%|#####7    | 1087/1875 [30:21<21:32,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4647, loss: 0.6050 ||:  58%|#####8    | 1088/1875 [30:23<21:44,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5960, loss: 0.6050 ||:  58%|#####8    | 1089/1875 [30:24<21:35,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5089, loss: 0.6049 ||:  58%|#####8    | 1090/1875 [30:26<22:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4854, loss: 0.6048 ||:  58%|#####8    | 1091/1875 [30:28<21:53,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5350, loss: 0.6048 ||:  58%|#####8    | 1092/1875 [30:29<22:24,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4929, loss: 0.6047 ||:  58%|#####8    | 1093/1875 [30:31<22:28,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4657, loss: 0.6045 ||:  58%|#####8    | 1094/1875 [30:33<21:41,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4543, loss: 0.6044 ||:  58%|#####8    | 1095/1875 [30:34<21:58,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4448, loss: 0.6043 ||:  58%|#####8    | 1096/1875 [30:36<21:58,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3989, loss: 0.6041 ||:  59%|#####8    | 1097/1875 [30:38<21:14,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4740, loss: 0.6039 ||:  59%|#####8    | 1098/1875 [30:39<20:46,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4382, loss: 0.6038 ||:  59%|#####8    | 1099/1875 [30:41<21:23,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6855, loss: 0.6039 ||:  59%|#####8    | 1100/1875 [30:43<23:17,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5279, loss: 0.6038 ||:  59%|#####8    | 1101/1875 [30:45<22:17,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4862, loss: 0.6037 ||:  59%|#####8    | 1102/1875 [30:46<22:04,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4295, loss: 0.6035 ||:  59%|#####8    | 1103/1875 [30:48<21:37,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5613, loss: 0.6035 ||:  59%|#####8    | 1104/1875 [30:50<21:35,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5099, loss: 0.6034 ||:  59%|#####8    | 1105/1875 [30:51<21:13,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5630, loss: 0.6034 ||:  59%|#####8    | 1106/1875 [30:53<21:13,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5680, loss: 0.6033 ||:  59%|#####9    | 1107/1875 [30:54<20:59,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5313, loss: 0.6033 ||:  59%|#####9    | 1108/1875 [30:56<21:11,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6798, loss: 0.6033 ||:  59%|#####9    | 1109/1875 [30:58<22:19,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5655, loss: 0.6033 ||:  59%|#####9    | 1110/1875 [31:00<21:41,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5916, loss: 0.6033 ||:  59%|#####9    | 1111/1875 [31:01<21:12,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5037, loss: 0.6032 ||:  59%|#####9    | 1112/1875 [31:03<20:55,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5556, loss: 0.6032 ||:  59%|#####9    | 1113/1875 [31:04<20:32,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4760, loss: 0.6031 ||:  59%|#####9    | 1114/1875 [31:06<20:17,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5633, loss: 0.6030 ||:  59%|#####9    | 1115/1875 [31:08<20:16,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5303, loss: 0.6030 ||:  60%|#####9    | 1116/1875 [31:09<20:21,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6442, loss: 0.6030 ||:  60%|#####9    | 1117/1875 [31:11<21:53,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4928, loss: 0.6029 ||:  60%|#####9    | 1118/1875 [31:13<21:07,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5525, loss: 0.6028 ||:  60%|#####9    | 1119/1875 [31:14<21:00,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5153, loss: 0.6028 ||:  60%|#####9    | 1120/1875 [31:16<20:55,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5693, loss: 0.6027 ||:  60%|#####9    | 1121/1875 [31:18<20:42,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5053, loss: 0.6027 ||:  60%|#####9    | 1122/1875 [31:19<20:34,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5816, loss: 0.6026 ||:  60%|#####9    | 1123/1875 [31:21<20:52,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5462, loss: 0.6026 ||:  60%|#####9    | 1124/1875 [31:23<21:12,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4216, loss: 0.6024 ||:  60%|######    | 1125/1875 [31:25<21:02,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5010, loss: 0.6023 ||:  60%|######    | 1126/1875 [31:26<20:29,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4979, loss: 0.6022 ||:  60%|######    | 1127/1875 [31:28<20:40,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5917, loss: 0.6022 ||:  60%|######    | 1128/1875 [31:29<20:40,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6313, loss: 0.6023 ||:  60%|######    | 1129/1875 [31:31<20:36,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4600, loss: 0.6021 ||:  60%|######    | 1130/1875 [31:33<21:17,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4906, loss: 0.6020 ||:  60%|######    | 1131/1875 [31:35<21:04,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4949, loss: 0.6019 ||:  60%|######    | 1132/1875 [31:36<20:36,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4701, loss: 0.6018 ||:  60%|######    | 1133/1875 [31:38<20:13,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5543, loss: 0.6018 ||:  60%|######    | 1134/1875 [31:40<21:18,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4545, loss: 0.6017 ||:  61%|######    | 1135/1875 [31:41<20:40,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6012, loss: 0.6017 ||:  61%|######    | 1136/1875 [31:43<20:12,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6211, loss: 0.6017 ||:  61%|######    | 1137/1875 [31:44<20:10,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5044, loss: 0.6016 ||:  61%|######    | 1138/1875 [31:46<19:51,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5391, loss: 0.6015 ||:  61%|######    | 1139/1875 [31:48<19:43,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4455, loss: 0.6014 ||:  61%|######    | 1140/1875 [31:49<19:44,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4963, loss: 0.6013 ||:  61%|######    | 1141/1875 [31:51<20:06,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4760, loss: 0.6012 ||:  61%|######    | 1142/1875 [31:53<20:07,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6545, loss: 0.6012 ||:  61%|######    | 1143/1875 [31:54<20:03,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5211, loss: 0.6012 ||:  61%|######1   | 1144/1875 [31:56<21:50,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4914, loss: 0.6011 ||:  61%|######1   | 1145/1875 [31:58<21:28,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4022, loss: 0.6009 ||:  61%|######1   | 1146/1875 [32:00<21:05,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4362, loss: 0.6008 ||:  61%|######1   | 1147/1875 [32:01<20:45,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5849, loss: 0.6007 ||:  61%|######1   | 1148/1875 [32:03<20:23,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5222, loss: 0.6007 ||:  61%|######1   | 1149/1875 [32:05<20:03,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5343, loss: 0.6006 ||:  61%|######1   | 1150/1875 [32:06<20:27,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4058, loss: 0.6004 ||:  61%|######1   | 1151/1875 [32:08<19:51,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6764, loss: 0.6005 ||:  61%|######1   | 1152/1875 [32:09<19:38,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6842, loss: 0.6006 ||:  61%|######1   | 1153/1875 [32:11<19:56,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4372, loss: 0.6004 ||:  62%|######1   | 1154/1875 [32:13<19:57,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5297, loss: 0.6004 ||:  62%|######1   | 1155/1875 [32:14<19:25,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.7112, loss: 0.6005 ||:  62%|######1   | 1156/1875 [32:16<20:32,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4707, loss: 0.6004 ||:  62%|######1   | 1157/1875 [32:18<19:52,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.3935, loss: 0.6002 ||:  62%|######1   | 1158/1875 [32:20<19:44,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5175, loss: 0.6001 ||:  62%|######1   | 1159/1875 [32:21<20:32,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5287, loss: 0.6001 ||:  62%|######1   | 1160/1875 [32:23<20:05,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5862, loss: 0.6000 ||:  62%|######1   | 1161/1875 [32:25<20:00,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5417, loss: 0.6000 ||:  62%|######1   | 1162/1875 [32:26<19:35,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3862, loss: 0.5998 ||:  62%|######2   | 1163/1875 [32:28<19:41,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5065, loss: 0.5997 ||:  62%|######2   | 1164/1875 [32:29<19:12,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5835, loss: 0.5997 ||:  62%|######2   | 1165/1875 [32:31<19:30,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4923, loss: 0.5996 ||:  62%|######2   | 1166/1875 [32:33<19:19,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5697, loss: 0.5996 ||:  62%|######2   | 1167/1875 [32:34<19:07,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4655, loss: 0.5995 ||:  62%|######2   | 1168/1875 [32:36<19:04,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4480, loss: 0.5993 ||:  62%|######2   | 1169/1875 [32:38<19:16,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.3750, loss: 0.5992 ||:  62%|######2   | 1170/1875 [32:39<18:47,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4170, loss: 0.5990 ||:  62%|######2   | 1171/1875 [32:41<18:45,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4881, loss: 0.5989 ||:  63%|######2   | 1172/1875 [32:42<18:43,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4448, loss: 0.5988 ||:  63%|######2   | 1173/1875 [32:44<18:35,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4071, loss: 0.5986 ||:  63%|######2   | 1174/1875 [32:46<18:58,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6257, loss: 0.5986 ||:  63%|######2   | 1175/1875 [32:47<18:53,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4422, loss: 0.5985 ||:  63%|######2   | 1176/1875 [32:49<18:47,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5314, loss: 0.5984 ||:  63%|######2   | 1177/1875 [32:50<18:22,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4334, loss: 0.5983 ||:  63%|######2   | 1178/1875 [32:52<18:22,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5646, loss: 0.5983 ||:  63%|######2   | 1179/1875 [32:54<18:48,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4824, loss: 0.5982 ||:  63%|######2   | 1180/1875 [32:55<18:48,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4755, loss: 0.5981 ||:  63%|######2   | 1181/1875 [32:57<18:27,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5720, loss: 0.5981 ||:  63%|######3   | 1182/1875 [32:59<19:02,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3855, loss: 0.5979 ||:  63%|######3   | 1183/1875 [33:00<18:31,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5320, loss: 0.5978 ||:  63%|######3   | 1184/1875 [33:02<18:45,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5099, loss: 0.5977 ||:  63%|######3   | 1185/1875 [33:03<18:21,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4705, loss: 0.5976 ||:  63%|######3   | 1186/1875 [33:05<18:23,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4089, loss: 0.5975 ||:  63%|######3   | 1187/1875 [33:07<18:32,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5844, loss: 0.5975 ||:  63%|######3   | 1188/1875 [33:08<18:37,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4960, loss: 0.5974 ||:  63%|######3   | 1189/1875 [33:10<18:38,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5034, loss: 0.5973 ||:  63%|######3   | 1190/1875 [33:12<19:14,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4917, loss: 0.5972 ||:  64%|######3   | 1191/1875 [33:13<19:08,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3681, loss: 0.5970 ||:  64%|######3   | 1192/1875 [33:15<19:26,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6008, loss: 0.5970 ||:  64%|######3   | 1193/1875 [33:17<19:00,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4652, loss: 0.5969 ||:  64%|######3   | 1194/1875 [33:18<19:07,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4715, loss: 0.5968 ||:  64%|######3   | 1195/1875 [33:20<18:47,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6967, loss: 0.5969 ||:  64%|######3   | 1196/1875 [33:22<18:46,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5723, loss: 0.5969 ||:  64%|######3   | 1197/1875 [33:23<19:01,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5512, loss: 0.5968 ||:  64%|######3   | 1198/1875 [33:25<18:46,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5906, loss: 0.5968 ||:  64%|######3   | 1199/1875 [33:27<18:52,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3806, loss: 0.5966 ||:  64%|######4   | 1200/1875 [33:29<20:34,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5079, loss: 0.5966 ||:  64%|######4   | 1201/1875 [33:31<19:55,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4211, loss: 0.5964 ||:  64%|######4   | 1202/1875 [33:32<19:11,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5682, loss: 0.5964 ||:  64%|######4   | 1203/1875 [33:34<18:47,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6123, loss: 0.5964 ||:  64%|######4   | 1204/1875 [33:35<18:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6322, loss: 0.5964 ||:  64%|######4   | 1205/1875 [33:37<18:22,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4854, loss: 0.5964 ||:  64%|######4   | 1206/1875 [33:38<17:55,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5961, loss: 0.5964 ||:  64%|######4   | 1207/1875 [33:40<17:45,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5742, loss: 0.5963 ||:  64%|######4   | 1208/1875 [33:42<17:39,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5036, loss: 0.5963 ||:  64%|######4   | 1209/1875 [33:43<18:13,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.3480, loss: 0.5961 ||:  65%|######4   | 1210/1875 [33:45<18:30,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4690, loss: 0.5960 ||:  65%|######4   | 1211/1875 [33:47<19:34,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.3960, loss: 0.5958 ||:  65%|######4   | 1212/1875 [33:49<19:09,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4026, loss: 0.5956 ||:  65%|######4   | 1213/1875 [33:50<18:35,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4708, loss: 0.5955 ||:  65%|######4   | 1214/1875 [33:52<18:09,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4619, loss: 0.5954 ||:  65%|######4   | 1215/1875 [33:53<18:00,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4790, loss: 0.5953 ||:  65%|######4   | 1216/1875 [33:55<17:50,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6146, loss: 0.5953 ||:  65%|######4   | 1217/1875 [33:57<17:35,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4687, loss: 0.5952 ||:  65%|######4   | 1218/1875 [33:58<17:22,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.3893, loss: 0.5951 ||:  65%|######5   | 1219/1875 [34:00<17:08,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4645, loss: 0.5950 ||:  65%|######5   | 1220/1875 [34:01<17:19,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4792, loss: 0.5949 ||:  65%|######5   | 1221/1875 [34:03<17:01,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5524, loss: 0.5948 ||:  65%|######5   | 1222/1875 [34:04<16:56,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.4866, loss: 0.5947 ||:  65%|######5   | 1223/1875 [34:06<16:50,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.3559, loss: 0.5945 ||:  65%|######5   | 1224/1875 [34:07<16:55,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5054, loss: 0.5945 ||:  65%|######5   | 1225/1875 [34:09<17:17,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5321, loss: 0.5944 ||:  65%|######5   | 1226/1875 [34:11<17:23,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5782, loss: 0.5944 ||:  65%|######5   | 1227/1875 [34:12<17:31,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.3666, loss: 0.5942 ||:  65%|######5   | 1228/1875 [34:14<17:37,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.3235, loss: 0.5940 ||:  66%|######5   | 1229/1875 [34:16<17:25,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5058, loss: 0.5939 ||:  66%|######5   | 1230/1875 [34:17<17:26,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4263, loss: 0.5938 ||:  66%|######5   | 1231/1875 [34:19<17:21,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4897, loss: 0.5937 ||:  66%|######5   | 1232/1875 [34:20<17:05,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4251, loss: 0.5936 ||:  66%|######5   | 1233/1875 [34:22<17:38,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.7028, loss: 0.5937 ||:  66%|######5   | 1234/1875 [34:24<18:34,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4164, loss: 0.5935 ||:  66%|######5   | 1235/1875 [34:26<18:27,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4970, loss: 0.5934 ||:  66%|######5   | 1236/1875 [34:27<17:53,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4960, loss: 0.5934 ||:  66%|######5   | 1237/1875 [34:29<17:37,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6884, loss: 0.5934 ||:  66%|######6   | 1238/1875 [34:31<17:42,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5372, loss: 0.5934 ||:  66%|######6   | 1239/1875 [34:33<17:59,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4722, loss: 0.5933 ||:  66%|######6   | 1240/1875 [34:34<17:35,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7565, loss: 0.5934 ||:  66%|######6   | 1241/1875 [34:36<17:13,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5359, loss: 0.5934 ||:  66%|######6   | 1242/1875 [34:37<17:29,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4961, loss: 0.5933 ||:  66%|######6   | 1243/1875 [34:39<17:12,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.3779, loss: 0.5931 ||:  66%|######6   | 1244/1875 [34:41<17:04,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5196, loss: 0.5931 ||:  66%|######6   | 1245/1875 [34:42<16:47,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4513, loss: 0.5930 ||:  66%|######6   | 1246/1875 [34:44<16:36,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.6724, loss: 0.5930 ||:  67%|######6   | 1247/1875 [34:45<16:45,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5136, loss: 0.5930 ||:  67%|######6   | 1248/1875 [34:47<16:24,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4167, loss: 0.5928 ||:  67%|######6   | 1249/1875 [34:49<16:56,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5534, loss: 0.5928 ||:  67%|######6   | 1250/1875 [34:50<17:32,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6656, loss: 0.5928 ||:  67%|######6   | 1251/1875 [34:52<18:05,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6379, loss: 0.5929 ||:  67%|######6   | 1252/1875 [34:54<17:32,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4384, loss: 0.5927 ||:  67%|######6   | 1253/1875 [34:55<16:56,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5340, loss: 0.5927 ||:  67%|######6   | 1254/1875 [34:57<17:52,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5764, loss: 0.5927 ||:  67%|######6   | 1255/1875 [34:59<17:58,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4455, loss: 0.5926 ||:  67%|######6   | 1256/1875 [35:01<17:33,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5194, loss: 0.5925 ||:  67%|######7   | 1257/1875 [35:02<17:19,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4275, loss: 0.5924 ||:  67%|######7   | 1258/1875 [35:04<17:05,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4274, loss: 0.5923 ||:  67%|######7   | 1259/1875 [35:05<16:45,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5443, loss: 0.5922 ||:  67%|######7   | 1260/1875 [35:07<17:11,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5730, loss: 0.5922 ||:  67%|######7   | 1261/1875 [35:09<16:52,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6929, loss: 0.5923 ||:  67%|######7   | 1262/1875 [35:11<17:26,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4561, loss: 0.5922 ||:  67%|######7   | 1263/1875 [35:12<17:34,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.3512, loss: 0.5920 ||:  67%|######7   | 1264/1875 [35:14<17:13,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6771, loss: 0.5920 ||:  67%|######7   | 1265/1875 [35:16<17:02,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5295, loss: 0.5920 ||:  68%|######7   | 1266/1875 [35:17<16:23,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6093, loss: 0.5920 ||:  68%|######7   | 1267/1875 [35:19<16:31,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5251, loss: 0.5920 ||:  68%|######7   | 1268/1875 [35:21<17:10,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4579, loss: 0.5919 ||:  68%|######7   | 1269/1875 [35:22<16:54,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6573, loss: 0.5919 ||:  68%|######7   | 1270/1875 [35:24<17:03,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3899, loss: 0.5917 ||:  68%|######7   | 1271/1875 [35:26<16:30,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4951, loss: 0.5917 ||:  68%|######7   | 1272/1875 [35:27<16:31,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5733, loss: 0.5917 ||:  68%|######7   | 1273/1875 [35:29<16:12,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5308, loss: 0.5916 ||:  68%|######7   | 1274/1875 [35:30<16:24,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5249, loss: 0.5916 ||:  68%|######8   | 1275/1875 [35:32<16:24,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4856, loss: 0.5915 ||:  68%|######8   | 1276/1875 [35:34<16:21,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5954, loss: 0.5915 ||:  68%|######8   | 1277/1875 [35:35<16:34,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4028, loss: 0.5913 ||:  68%|######8   | 1278/1875 [35:37<16:18,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5016, loss: 0.5913 ||:  68%|######8   | 1279/1875 [35:39<16:43,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5029, loss: 0.5912 ||:  68%|######8   | 1280/1875 [35:40<16:30,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5987, loss: 0.5912 ||:  68%|######8   | 1281/1875 [35:42<16:44,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4345, loss: 0.5911 ||:  68%|######8   | 1282/1875 [35:44<16:25,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.7741, loss: 0.5912 ||:  68%|######8   | 1283/1875 [35:45<16:28,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5268, loss: 0.5912 ||:  68%|######8   | 1284/1875 [35:47<16:17,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3850, loss: 0.5910 ||:  69%|######8   | 1285/1875 [35:49<16:18,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4827, loss: 0.5909 ||:  69%|######8   | 1286/1875 [35:50<15:55,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5432, loss: 0.5909 ||:  69%|######8   | 1287/1875 [35:52<15:40,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5191, loss: 0.5908 ||:  69%|######8   | 1288/1875 [35:54<15:59,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4812, loss: 0.5907 ||:  69%|######8   | 1289/1875 [35:55<16:13,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4667, loss: 0.5906 ||:  69%|######8   | 1290/1875 [35:57<15:54,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5234, loss: 0.5906 ||:  69%|######8   | 1291/1875 [35:58<15:41,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6459, loss: 0.5906 ||:  69%|######8   | 1292/1875 [36:00<15:47,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6924, loss: 0.5907 ||:  69%|######8   | 1293/1875 [36:02<16:05,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5839, loss: 0.5907 ||:  69%|######9   | 1294/1875 [36:04<16:11,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4326, loss: 0.5906 ||:  69%|######9   | 1295/1875 [36:05<16:18,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6421, loss: 0.5906 ||:  69%|######9   | 1296/1875 [36:07<16:20,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6105, loss: 0.5906 ||:  69%|######9   | 1297/1875 [36:09<16:14,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5833, loss: 0.5906 ||:  69%|######9   | 1298/1875 [36:10<16:04,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5756, loss: 0.5906 ||:  69%|######9   | 1299/1875 [36:12<16:36,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6279, loss: 0.5907 ||:  69%|######9   | 1300/1875 [36:14<17:46,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.5494, loss: 0.5906 ||:  69%|######9   | 1301/1875 [36:16<16:56,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5104, loss: 0.5906 ||:  69%|######9   | 1302/1875 [36:18<16:42,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5087, loss: 0.5905 ||:  69%|######9   | 1303/1875 [36:19<16:34,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5348, loss: 0.5905 ||:  70%|######9   | 1304/1875 [36:21<16:14,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5836, loss: 0.5905 ||:  70%|######9   | 1305/1875 [36:23<16:11,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6491, loss: 0.5905 ||:  70%|######9   | 1306/1875 [36:24<16:11,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4722, loss: 0.5904 ||:  70%|######9   | 1307/1875 [36:26<16:07,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5200, loss: 0.5904 ||:  70%|######9   | 1308/1875 [36:28<15:39,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6346, loss: 0.5904 ||:  70%|######9   | 1309/1875 [36:29<15:22,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5680, loss: 0.5904 ||:  70%|######9   | 1310/1875 [36:31<15:17,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5250, loss: 0.5903 ||:  70%|######9   | 1311/1875 [36:33<16:23,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5236, loss: 0.5903 ||:  70%|######9   | 1312/1875 [36:34<16:13,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5234, loss: 0.5902 ||:  70%|#######   | 1313/1875 [36:36<16:07,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4643, loss: 0.5901 ||:  70%|#######   | 1314/1875 [36:38<15:46,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5255, loss: 0.5901 ||:  70%|#######   | 1315/1875 [36:39<15:38,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.3600, loss: 0.5899 ||:  70%|#######   | 1316/1875 [36:41<15:14,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5051, loss: 0.5898 ||:  70%|#######   | 1317/1875 [36:43<15:12,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4892, loss: 0.5898 ||:  70%|#######   | 1318/1875 [36:44<15:31,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4761, loss: 0.5897 ||:  70%|#######   | 1319/1875 [36:46<15:35,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5426, loss: 0.5896 ||:  70%|#######   | 1320/1875 [36:48<15:23,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5808, loss: 0.5896 ||:  70%|#######   | 1321/1875 [36:49<15:07,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5255, loss: 0.5896 ||:  71%|#######   | 1322/1875 [36:51<15:15,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5120, loss: 0.5895 ||:  71%|#######   | 1323/1875 [36:53<15:32,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5805, loss: 0.5895 ||:  71%|#######   | 1324/1875 [36:54<15:28,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6209, loss: 0.5895 ||:  71%|#######   | 1325/1875 [36:56<15:57,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4792, loss: 0.5895 ||:  71%|#######   | 1326/1875 [36:58<15:32,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4309, loss: 0.5893 ||:  71%|#######   | 1327/1875 [36:59<15:06,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3771, loss: 0.5892 ||:  71%|#######   | 1328/1875 [37:01<15:16,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3979, loss: 0.5890 ||:  71%|#######   | 1329/1875 [37:03<15:07,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4618, loss: 0.5889 ||:  71%|#######   | 1330/1875 [37:04<14:49,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6085, loss: 0.5889 ||:  71%|#######   | 1331/1875 [37:06<14:46,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5462, loss: 0.5889 ||:  71%|#######1  | 1332/1875 [37:07<14:27,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4803, loss: 0.5888 ||:  71%|#######1  | 1333/1875 [37:09<14:18,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4565, loss: 0.5887 ||:  71%|#######1  | 1334/1875 [37:11<14:10,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4451, loss: 0.5886 ||:  71%|#######1  | 1335/1875 [37:12<14:08,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4264, loss: 0.5885 ||:  71%|#######1  | 1336/1875 [37:14<14:23,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5510, loss: 0.5885 ||:  71%|#######1  | 1337/1875 [37:15<14:16,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4504, loss: 0.5884 ||:  71%|#######1  | 1338/1875 [37:17<14:24,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5215, loss: 0.5883 ||:  71%|#######1  | 1339/1875 [37:19<15:12,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6708, loss: 0.5884 ||:  71%|#######1  | 1340/1875 [37:21<15:04,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5309, loss: 0.5883 ||:  72%|#######1  | 1341/1875 [37:22<14:59,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4699, loss: 0.5883 ||:  72%|#######1  | 1342/1875 [37:24<15:04,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5021, loss: 0.5882 ||:  72%|#######1  | 1343/1875 [37:26<15:05,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5854, loss: 0.5882 ||:  72%|#######1  | 1344/1875 [37:27<14:49,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5232, loss: 0.5881 ||:  72%|#######1  | 1345/1875 [37:29<14:36,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6624, loss: 0.5882 ||:  72%|#######1  | 1346/1875 [37:31<15:03,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.7045, loss: 0.5883 ||:  72%|#######1  | 1347/1875 [37:33<15:33,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5627, loss: 0.5883 ||:  72%|#######1  | 1348/1875 [37:34<15:19,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6236, loss: 0.5883 ||:  72%|#######1  | 1349/1875 [37:36<14:59,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5771, loss: 0.5883 ||:  72%|#######2  | 1350/1875 [37:38<14:39,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5207, loss: 0.5882 ||:  72%|#######2  | 1351/1875 [37:39<14:32,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4728, loss: 0.5881 ||:  72%|#######2  | 1352/1875 [37:41<14:51,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5042, loss: 0.5881 ||:  72%|#######2  | 1353/1875 [37:43<14:38,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6642, loss: 0.5881 ||:  72%|#######2  | 1354/1875 [37:44<14:20,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5271, loss: 0.5881 ||:  72%|#######2  | 1355/1875 [37:46<14:34,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5326, loss: 0.5881 ||:  72%|#######2  | 1356/1875 [37:48<14:22,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4422, loss: 0.5879 ||:  72%|#######2  | 1357/1875 [37:49<13:50,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5209, loss: 0.5879 ||:  72%|#######2  | 1358/1875 [37:51<13:55,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5375, loss: 0.5879 ||:  72%|#######2  | 1359/1875 [37:52<13:32,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4300, loss: 0.5877 ||:  73%|#######2  | 1360/1875 [37:54<13:46,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5752, loss: 0.5877 ||:  73%|#######2  | 1361/1875 [37:56<13:51,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6264, loss: 0.5878 ||:  73%|#######2  | 1362/1875 [37:57<14:27,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5913, loss: 0.5878 ||:  73%|#######2  | 1363/1875 [37:59<14:36,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.7341, loss: 0.5879 ||:  73%|#######2  | 1364/1875 [38:01<14:38,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4169, loss: 0.5877 ||:  73%|#######2  | 1365/1875 [38:02<14:08,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4477, loss: 0.5876 ||:  73%|#######2  | 1366/1875 [38:04<13:47,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6116, loss: 0.5877 ||:  73%|#######2  | 1367/1875 [38:06<13:52,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.7127, loss: 0.5878 ||:  73%|#######2  | 1368/1875 [38:07<14:06,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4735, loss: 0.5877 ||:  73%|#######3  | 1369/1875 [38:09<14:04,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5424, loss: 0.5876 ||:  73%|#######3  | 1370/1875 [38:11<14:16,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4924, loss: 0.5876 ||:  73%|#######3  | 1371/1875 [38:13<14:17,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.6457, loss: 0.5876 ||:  73%|#######3  | 1372/1875 [38:14<14:01,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6398, loss: 0.5877 ||:  73%|#######3  | 1373/1875 [38:16<14:22,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4652, loss: 0.5876 ||:  73%|#######3  | 1374/1875 [38:18<14:31,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.3810, loss: 0.5874 ||:  73%|#######3  | 1375/1875 [38:19<14:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4555, loss: 0.5873 ||:  73%|#######3  | 1376/1875 [38:21<14:01,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5505, loss: 0.5873 ||:  73%|#######3  | 1377/1875 [38:23<13:55,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6372, loss: 0.5873 ||:  73%|#######3  | 1378/1875 [38:24<13:44,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6049, loss: 0.5873 ||:  74%|#######3  | 1379/1875 [38:26<13:41,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4785, loss: 0.5873 ||:  74%|#######3  | 1380/1875 [38:27<13:10,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4551, loss: 0.5872 ||:  74%|#######3  | 1381/1875 [38:29<13:16,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5238, loss: 0.5871 ||:  74%|#######3  | 1382/1875 [38:31<13:29,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.3644, loss: 0.5870 ||:  74%|#######3  | 1383/1875 [38:33<13:48,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4371, loss: 0.5868 ||:  74%|#######3  | 1384/1875 [38:34<13:47,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6052, loss: 0.5869 ||:  74%|#######3  | 1385/1875 [38:36<13:28,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6076, loss: 0.5869 ||:  74%|#######3  | 1386/1875 [38:37<13:38,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5826, loss: 0.5869 ||:  74%|#######3  | 1387/1875 [38:39<13:35,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4574, loss: 0.5868 ||:  74%|#######4  | 1388/1875 [38:41<13:29,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5534, loss: 0.5868 ||:  74%|#######4  | 1389/1875 [38:42<13:06,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4507, loss: 0.5867 ||:  74%|#######4  | 1390/1875 [38:44<12:51,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5073, loss: 0.5866 ||:  74%|#######4  | 1391/1875 [38:45<12:55,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5065, loss: 0.5865 ||:  74%|#######4  | 1392/1875 [38:47<12:36,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5119, loss: 0.5865 ||:  74%|#######4  | 1393/1875 [38:49<12:58,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5056, loss: 0.5864 ||:  74%|#######4  | 1394/1875 [38:50<12:50,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5799, loss: 0.5864 ||:  74%|#######4  | 1395/1875 [38:52<13:05,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4319, loss: 0.5863 ||:  74%|#######4  | 1396/1875 [38:54<12:51,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4517, loss: 0.5862 ||:  75%|#######4  | 1397/1875 [38:55<12:56,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4415, loss: 0.5861 ||:  75%|#######4  | 1398/1875 [38:57<12:59,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5468, loss: 0.5861 ||:  75%|#######4  | 1399/1875 [38:58<12:53,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5667, loss: 0.5861 ||:  75%|#######4  | 1400/1875 [39:01<14:12,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5047, loss: 0.5860 ||:  75%|#######4  | 1401/1875 [39:02<14:04,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.7279, loss: 0.5861 ||:  75%|#######4  | 1402/1875 [39:04<13:31,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4031, loss: 0.5860 ||:  75%|#######4  | 1403/1875 [39:05<13:03,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6154, loss: 0.5860 ||:  75%|#######4  | 1404/1875 [39:07<12:59,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4006, loss: 0.5859 ||:  75%|#######4  | 1405/1875 [39:09<12:30,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.3662, loss: 0.5857 ||:  75%|#######4  | 1406/1875 [39:10<12:43,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6290, loss: 0.5858 ||:  75%|#######5  | 1407/1875 [39:12<13:00,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4271, loss: 0.5856 ||:  75%|#######5  | 1408/1875 [39:14<12:44,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6605, loss: 0.5857 ||:  75%|#######5  | 1409/1875 [39:16<13:36,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5813, loss: 0.5857 ||:  75%|#######5  | 1410/1875 [39:17<13:35,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5371, loss: 0.5857 ||:  75%|#######5  | 1411/1875 [39:19<13:11,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5759, loss: 0.5856 ||:  75%|#######5  | 1412/1875 [39:21<13:03,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4632, loss: 0.5856 ||:  75%|#######5  | 1413/1875 [39:22<12:40,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4324, loss: 0.5855 ||:  75%|#######5  | 1414/1875 [39:24<12:21,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5002, loss: 0.5854 ||:  75%|#######5  | 1415/1875 [39:26<12:52,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6147, loss: 0.5854 ||:  76%|#######5  | 1416/1875 [39:27<12:44,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5307, loss: 0.5854 ||:  76%|#######5  | 1417/1875 [39:29<12:33,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5324, loss: 0.5853 ||:  76%|#######5  | 1418/1875 [39:30<12:32,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4193, loss: 0.5852 ||:  76%|#######5  | 1419/1875 [39:32<12:28,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4302, loss: 0.5851 ||:  76%|#######5  | 1420/1875 [39:34<12:33,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6594, loss: 0.5852 ||:  76%|#######5  | 1421/1875 [39:35<12:45,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4646, loss: 0.5851 ||:  76%|#######5  | 1422/1875 [39:37<12:42,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5569, loss: 0.5851 ||:  76%|#######5  | 1423/1875 [39:39<12:57,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6233, loss: 0.5851 ||:  76%|#######5  | 1424/1875 [39:41<12:28,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6273, loss: 0.5851 ||:  76%|#######6  | 1425/1875 [39:42<12:22,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5397, loss: 0.5851 ||:  76%|#######6  | 1426/1875 [39:44<12:15,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4516, loss: 0.5850 ||:  76%|#######6  | 1427/1875 [39:45<12:20,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5817, loss: 0.5850 ||:  76%|#######6  | 1428/1875 [39:47<12:34,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4255, loss: 0.5849 ||:  76%|#######6  | 1429/1875 [39:49<12:14,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4923, loss: 0.5848 ||:  76%|#######6  | 1430/1875 [39:50<11:56,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6238, loss: 0.5848 ||:  76%|#######6  | 1431/1875 [39:52<12:38,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4534, loss: 0.5847 ||:  76%|#######6  | 1432/1875 [39:54<12:19,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5075, loss: 0.5847 ||:  76%|#######6  | 1433/1875 [39:55<11:59,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5531, loss: 0.5847 ||:  76%|#######6  | 1434/1875 [39:57<12:02,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4526, loss: 0.5846 ||:  77%|#######6  | 1435/1875 [39:59<12:25,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6442, loss: 0.5846 ||:  77%|#######6  | 1436/1875 [40:00<12:15,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5274, loss: 0.5846 ||:  77%|#######6  | 1437/1875 [40:02<12:01,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6221, loss: 0.5846 ||:  77%|#######6  | 1438/1875 [40:04<11:58,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4994, loss: 0.5845 ||:  77%|#######6  | 1439/1875 [40:05<11:43,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6294, loss: 0.5846 ||:  77%|#######6  | 1440/1875 [40:07<11:50,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6173, loss: 0.5846 ||:  77%|#######6  | 1441/1875 [40:09<12:50,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4499, loss: 0.5845 ||:  77%|#######6  | 1442/1875 [40:10<12:05,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5248, loss: 0.5845 ||:  77%|#######6  | 1443/1875 [40:12<12:09,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5557, loss: 0.5844 ||:  77%|#######7  | 1444/1875 [40:14<11:52,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6773, loss: 0.5845 ||:  77%|#######7  | 1445/1875 [40:15<11:47,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5422, loss: 0.5845 ||:  77%|#######7  | 1446/1875 [40:17<11:34,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.3596, loss: 0.5843 ||:  77%|#######7  | 1447/1875 [40:19<11:42,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4590, loss: 0.5842 ||:  77%|#######7  | 1448/1875 [40:20<11:38,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4581, loss: 0.5842 ||:  77%|#######7  | 1449/1875 [40:22<11:18,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5184, loss: 0.5841 ||:  77%|#######7  | 1450/1875 [40:24<12:10,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5036, loss: 0.5841 ||:  77%|#######7  | 1451/1875 [40:25<12:09,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.3488, loss: 0.5839 ||:  77%|#######7  | 1452/1875 [40:27<11:48,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4796, loss: 0.5838 ||:  77%|#######7  | 1453/1875 [40:29<11:35,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4977, loss: 0.5838 ||:  78%|#######7  | 1454/1875 [40:30<11:33,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4864, loss: 0.5837 ||:  78%|#######7  | 1455/1875 [40:32<11:17,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5436, loss: 0.5837 ||:  78%|#######7  | 1456/1875 [40:33<11:15,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5554, loss: 0.5836 ||:  78%|#######7  | 1457/1875 [40:35<11:26,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4887, loss: 0.5836 ||:  78%|#######7  | 1458/1875 [40:37<11:15,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5389, loss: 0.5835 ||:  78%|#######7  | 1459/1875 [40:38<11:19,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4909, loss: 0.5835 ||:  78%|#######7  | 1460/1875 [40:40<11:22,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6888, loss: 0.5836 ||:  78%|#######7  | 1461/1875 [40:42<11:46,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4849, loss: 0.5835 ||:  78%|#######7  | 1462/1875 [40:44<11:38,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4680, loss: 0.5834 ||:  78%|#######8  | 1463/1875 [40:45<11:34,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.6165, loss: 0.5834 ||:  78%|#######8  | 1464/1875 [40:47<11:16,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5629, loss: 0.5834 ||:  78%|#######8  | 1465/1875 [40:48<11:05,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4152, loss: 0.5833 ||:  78%|#######8  | 1466/1875 [40:50<11:06,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4556, loss: 0.5832 ||:  78%|#######8  | 1467/1875 [40:52<11:02,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4163, loss: 0.5831 ||:  78%|#######8  | 1468/1875 [40:53<10:52,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4982, loss: 0.5830 ||:  78%|#######8  | 1469/1875 [40:55<10:44,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5199, loss: 0.5830 ||:  78%|#######8  | 1470/1875 [40:56<10:30,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5167, loss: 0.5830 ||:  78%|#######8  | 1471/1875 [40:58<10:38,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5075, loss: 0.5829 ||:  79%|#######8  | 1472/1875 [40:59<10:43,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5103, loss: 0.5829 ||:  79%|#######8  | 1473/1875 [41:01<11:08,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4031, loss: 0.5827 ||:  79%|#######8  | 1474/1875 [41:03<11:10,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3960, loss: 0.5826 ||:  79%|#######8  | 1475/1875 [41:04<10:44,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6026, loss: 0.5826 ||:  79%|#######8  | 1476/1875 [41:06<11:00,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5196, loss: 0.5826 ||:  79%|#######8  | 1477/1875 [41:08<10:56,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5389, loss: 0.5825 ||:  79%|#######8  | 1478/1875 [41:09<10:41,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6487, loss: 0.5826 ||:  79%|#######8  | 1479/1875 [41:11<10:33,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4398, loss: 0.5825 ||:  79%|#######8  | 1480/1875 [41:12<10:25,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5097, loss: 0.5824 ||:  79%|#######8  | 1481/1875 [41:14<10:39,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.3861, loss: 0.5823 ||:  79%|#######9  | 1482/1875 [41:16<10:35,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5281, loss: 0.5823 ||:  79%|#######9  | 1483/1875 [41:17<10:45,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5127, loss: 0.5822 ||:  79%|#######9  | 1484/1875 [41:19<10:37,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5391, loss: 0.5822 ||:  79%|#######9  | 1485/1875 [41:21<10:39,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5403, loss: 0.5822 ||:  79%|#######9  | 1486/1875 [41:23<10:55,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4931, loss: 0.5821 ||:  79%|#######9  | 1487/1875 [41:24<10:43,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5091, loss: 0.5821 ||:  79%|#######9  | 1488/1875 [41:26<10:29,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5025, loss: 0.5820 ||:  79%|#######9  | 1489/1875 [41:27<10:29,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5817, loss: 0.5820 ||:  79%|#######9  | 1490/1875 [41:29<10:36,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4570, loss: 0.5819 ||:  80%|#######9  | 1491/1875 [41:31<10:26,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5196, loss: 0.5819 ||:  80%|#######9  | 1492/1875 [41:32<10:15,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.6771, loss: 0.5820 ||:  80%|#######9  | 1493/1875 [41:34<10:09,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6166, loss: 0.5820 ||:  80%|#######9  | 1494/1875 [41:35<10:08,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4853, loss: 0.5819 ||:  80%|#######9  | 1495/1875 [41:37<10:10,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5329, loss: 0.5819 ||:  80%|#######9  | 1496/1875 [41:39<10:17,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5808, loss: 0.5819 ||:  80%|#######9  | 1497/1875 [41:40<10:39,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4319, loss: 0.5818 ||:  80%|#######9  | 1498/1875 [41:42<10:21,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6316, loss: 0.5818 ||:  80%|#######9  | 1499/1875 [41:44<10:15,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5141, loss: 0.5818 ||:  80%|########  | 1500/1875 [41:46<11:07,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4812, loss: 0.5817 ||:  80%|########  | 1501/1875 [41:47<10:33,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3876, loss: 0.5816 ||:  80%|########  | 1502/1875 [41:49<10:31,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5268, loss: 0.5815 ||:  80%|########  | 1503/1875 [41:50<10:13,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5218, loss: 0.5815 ||:  80%|########  | 1504/1875 [41:52<10:12,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4296, loss: 0.5814 ||:  80%|########  | 1505/1875 [41:54<09:58,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4981, loss: 0.5813 ||:  80%|########  | 1506/1875 [41:55<09:47,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4849, loss: 0.5813 ||:  80%|########  | 1507/1875 [41:57<09:35,  1.56s/it]final_beam_acc: 0.0000, batch_loss: 0.5673, loss: 0.5813 ||:  80%|########  | 1508/1875 [41:58<09:37,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5445, loss: 0.5812 ||:  80%|########  | 1509/1875 [42:00<09:42,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.6228, loss: 0.5813 ||:  81%|########  | 1510/1875 [42:01<09:26,  1.55s/it]final_beam_acc: 0.0000, batch_loss: 0.5892, loss: 0.5813 ||:  81%|########  | 1511/1875 [42:03<09:50,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.7633, loss: 0.5814 ||:  81%|########  | 1512/1875 [42:05<10:15,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4352, loss: 0.5813 ||:  81%|########  | 1513/1875 [42:07<09:53,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5064, loss: 0.5812 ||:  81%|########  | 1514/1875 [42:08<09:54,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4588, loss: 0.5812 ||:  81%|########  | 1515/1875 [42:10<09:48,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5829, loss: 0.5812 ||:  81%|########  | 1516/1875 [42:12<09:54,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6256, loss: 0.5812 ||:  81%|########  | 1517/1875 [42:13<09:50,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5422, loss: 0.5812 ||:  81%|########  | 1518/1875 [42:15<10:10,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4091, loss: 0.5811 ||:  81%|########1 | 1519/1875 [42:17<10:10,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5788, loss: 0.5811 ||:  81%|########1 | 1520/1875 [42:19<10:17,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.4850, loss: 0.5810 ||:  81%|########1 | 1521/1875 [42:20<10:04,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5023, loss: 0.5809 ||:  81%|########1 | 1522/1875 [42:22<09:41,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5157, loss: 0.5809 ||:  81%|########1 | 1523/1875 [42:23<09:33,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5341, loss: 0.5809 ||:  81%|########1 | 1524/1875 [42:25<09:35,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5517, loss: 0.5808 ||:  81%|########1 | 1525/1875 [42:27<09:33,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4601, loss: 0.5808 ||:  81%|########1 | 1526/1875 [42:28<09:19,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4209, loss: 0.5807 ||:  81%|########1 | 1527/1875 [42:30<09:21,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5077, loss: 0.5806 ||:  81%|########1 | 1528/1875 [42:31<09:12,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4979, loss: 0.5806 ||:  82%|########1 | 1529/1875 [42:33<09:24,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.3501, loss: 0.5804 ||:  82%|########1 | 1530/1875 [42:35<09:21,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5561, loss: 0.5804 ||:  82%|########1 | 1531/1875 [42:36<09:31,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4941, loss: 0.5803 ||:  82%|########1 | 1532/1875 [42:38<09:28,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4912, loss: 0.5803 ||:  82%|########1 | 1533/1875 [42:40<09:24,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5256, loss: 0.5802 ||:  82%|########1 | 1534/1875 [42:41<09:25,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.3778, loss: 0.5801 ||:  82%|########1 | 1535/1875 [42:43<09:10,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6484, loss: 0.5802 ||:  82%|########1 | 1536/1875 [42:44<09:10,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5735, loss: 0.5802 ||:  82%|########1 | 1537/1875 [42:46<09:18,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5504, loss: 0.5801 ||:  82%|########2 | 1538/1875 [42:48<09:04,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5918, loss: 0.5801 ||:  82%|########2 | 1539/1875 [42:50<09:31,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.3494, loss: 0.5800 ||:  82%|########2 | 1540/1875 [42:51<09:23,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5398, loss: 0.5800 ||:  82%|########2 | 1541/1875 [42:53<09:09,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4362, loss: 0.5799 ||:  82%|########2 | 1542/1875 [42:55<09:15,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4835, loss: 0.5798 ||:  82%|########2 | 1543/1875 [42:56<09:13,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4368, loss: 0.5797 ||:  82%|########2 | 1544/1875 [42:58<09:16,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5678, loss: 0.5797 ||:  82%|########2 | 1545/1875 [43:00<09:30,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5959, loss: 0.5797 ||:  82%|########2 | 1546/1875 [43:01<09:26,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6879, loss: 0.5798 ||:  83%|########2 | 1547/1875 [43:04<09:56,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5172, loss: 0.5797 ||:  83%|########2 | 1548/1875 [43:05<09:40,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5567, loss: 0.5797 ||:  83%|########2 | 1549/1875 [43:07<09:20,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5032, loss: 0.5797 ||:  83%|########2 | 1550/1875 [43:08<09:06,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5385, loss: 0.5797 ||:  83%|########2 | 1551/1875 [43:10<08:54,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5598, loss: 0.5796 ||:  83%|########2 | 1552/1875 [43:12<08:49,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5439, loss: 0.5796 ||:  83%|########2 | 1553/1875 [43:13<08:56,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4883, loss: 0.5796 ||:  83%|########2 | 1554/1875 [43:15<08:46,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5881, loss: 0.5796 ||:  83%|########2 | 1555/1875 [43:17<08:51,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5373, loss: 0.5795 ||:  83%|########2 | 1556/1875 [43:18<08:41,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5419, loss: 0.5795 ||:  83%|########3 | 1557/1875 [43:20<08:39,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4885, loss: 0.5795 ||:  83%|########3 | 1558/1875 [43:21<08:44,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6070, loss: 0.5795 ||:  83%|########3 | 1559/1875 [43:23<08:34,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5366, loss: 0.5794 ||:  83%|########3 | 1560/1875 [43:25<08:25,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4194, loss: 0.5793 ||:  83%|########3 | 1561/1875 [43:26<08:35,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4838, loss: 0.5793 ||:  83%|########3 | 1562/1875 [43:28<08:34,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4200, loss: 0.5792 ||:  83%|########3 | 1563/1875 [43:30<08:35,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4275, loss: 0.5791 ||:  83%|########3 | 1564/1875 [43:31<08:35,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4195, loss: 0.5790 ||:  83%|########3 | 1565/1875 [43:33<08:45,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3745, loss: 0.5789 ||:  84%|########3 | 1566/1875 [43:35<08:52,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.6003, loss: 0.5789 ||:  84%|########3 | 1567/1875 [43:37<09:01,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5160, loss: 0.5788 ||:  84%|########3 | 1568/1875 [43:38<09:01,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4558, loss: 0.5787 ||:  84%|########3 | 1569/1875 [43:40<09:05,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6456, loss: 0.5788 ||:  84%|########3 | 1570/1875 [43:42<09:08,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4599, loss: 0.5787 ||:  84%|########3 | 1571/1875 [43:44<09:10,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4794, loss: 0.5787 ||:  84%|########3 | 1572/1875 [43:46<09:15,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5792, loss: 0.5787 ||:  84%|########3 | 1573/1875 [43:48<09:11,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5184, loss: 0.5786 ||:  84%|########3 | 1574/1875 [43:50<09:09,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.4963, loss: 0.5786 ||:  84%|########4 | 1575/1875 [43:51<09:00,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.6380, loss: 0.5786 ||:  84%|########4 | 1576/1875 [43:53<09:02,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.6090, loss: 0.5786 ||:  84%|########4 | 1577/1875 [43:55<09:32,  1.92s/it]final_beam_acc: 0.0000, batch_loss: 0.6017, loss: 0.5786 ||:  84%|########4 | 1578/1875 [43:57<09:55,  2.00s/it]final_beam_acc: 0.0000, batch_loss: 0.6761, loss: 0.5787 ||:  84%|########4 | 1579/1875 [43:59<09:38,  1.95s/it]final_beam_acc: 0.0000, batch_loss: 0.4956, loss: 0.5786 ||:  84%|########4 | 1580/1875 [44:01<09:16,  1.89s/it]final_beam_acc: 0.0000, batch_loss: 0.3775, loss: 0.5785 ||:  84%|########4 | 1581/1875 [44:03<09:01,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5564, loss: 0.5785 ||:  84%|########4 | 1582/1875 [44:04<08:44,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5536, loss: 0.5785 ||:  84%|########4 | 1583/1875 [44:06<08:40,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6086, loss: 0.5785 ||:  84%|########4 | 1584/1875 [44:08<08:49,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.6704, loss: 0.5786 ||:  85%|########4 | 1585/1875 [44:10<08:40,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4642, loss: 0.5785 ||:  85%|########4 | 1586/1875 [44:12<08:34,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4187, loss: 0.5784 ||:  85%|########4 | 1587/1875 [44:13<08:16,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5606, loss: 0.5784 ||:  85%|########4 | 1588/1875 [44:15<08:30,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5055, loss: 0.5783 ||:  85%|########4 | 1589/1875 [44:17<08:24,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5002, loss: 0.5783 ||:  85%|########4 | 1590/1875 [44:19<08:24,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5929, loss: 0.5783 ||:  85%|########4 | 1591/1875 [44:21<08:47,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.4851, loss: 0.5782 ||:  85%|########4 | 1592/1875 [44:22<08:35,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5992, loss: 0.5782 ||:  85%|########4 | 1593/1875 [44:24<08:27,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.6292, loss: 0.5783 ||:  85%|########5 | 1594/1875 [44:26<08:36,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5324, loss: 0.5783 ||:  85%|########5 | 1595/1875 [44:28<08:23,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4771, loss: 0.5782 ||:  85%|########5 | 1596/1875 [44:30<08:21,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4803, loss: 0.5781 ||:  85%|########5 | 1597/1875 [44:31<08:25,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.4672, loss: 0.5781 ||:  85%|########5 | 1598/1875 [44:33<08:12,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4521, loss: 0.5780 ||:  85%|########5 | 1599/1875 [44:35<08:11,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4409, loss: 0.5779 ||:  85%|########5 | 1600/1875 [44:37<08:53,  1.94s/it]final_beam_acc: 0.0000, batch_loss: 0.5930, loss: 0.5779 ||:  85%|########5 | 1601/1875 [44:39<08:27,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.6721, loss: 0.5780 ||:  85%|########5 | 1602/1875 [44:41<08:15,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.5312, loss: 0.5779 ||:  85%|########5 | 1603/1875 [44:42<08:05,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4969, loss: 0.5779 ||:  86%|########5 | 1604/1875 [44:44<08:02,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.6008, loss: 0.5779 ||:  86%|########5 | 1605/1875 [44:46<08:02,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5542, loss: 0.5779 ||:  86%|########5 | 1606/1875 [44:48<07:58,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.4645, loss: 0.5778 ||:  86%|########5 | 1607/1875 [44:49<07:50,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4793, loss: 0.5777 ||:  86%|########5 | 1608/1875 [44:51<07:57,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.6038, loss: 0.5778 ||:  86%|########5 | 1609/1875 [44:53<07:50,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4545, loss: 0.5777 ||:  86%|########5 | 1610/1875 [44:55<07:47,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5768, loss: 0.5777 ||:  86%|########5 | 1611/1875 [44:57<07:52,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5207, loss: 0.5777 ||:  86%|########5 | 1612/1875 [44:58<07:48,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5746, loss: 0.5777 ||:  86%|########6 | 1613/1875 [45:00<07:32,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5158, loss: 0.5776 ||:  86%|########6 | 1614/1875 [45:02<07:24,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4073, loss: 0.5775 ||:  86%|########6 | 1615/1875 [45:03<07:25,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5719, loss: 0.5775 ||:  86%|########6 | 1616/1875 [45:05<07:19,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5684, loss: 0.5775 ||:  86%|########6 | 1617/1875 [45:07<07:41,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4004, loss: 0.5774 ||:  86%|########6 | 1618/1875 [45:09<07:42,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5524, loss: 0.5774 ||:  86%|########6 | 1619/1875 [45:11<07:49,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5814, loss: 0.5774 ||:  86%|########6 | 1620/1875 [45:12<07:42,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4649, loss: 0.5773 ||:  86%|########6 | 1621/1875 [45:14<07:29,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5335, loss: 0.5773 ||:  87%|########6 | 1622/1875 [45:16<07:25,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4086, loss: 0.5772 ||:  87%|########6 | 1623/1875 [45:18<07:37,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5290, loss: 0.5771 ||:  87%|########6 | 1624/1875 [45:20<07:38,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.4606, loss: 0.5771 ||:  87%|########6 | 1625/1875 [45:21<07:28,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.3862, loss: 0.5770 ||:  87%|########6 | 1626/1875 [45:23<07:15,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5586, loss: 0.5769 ||:  87%|########6 | 1627/1875 [45:25<07:16,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4707, loss: 0.5769 ||:  87%|########6 | 1628/1875 [45:27<07:20,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.7713, loss: 0.5770 ||:  87%|########6 | 1629/1875 [45:29<07:25,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4893, loss: 0.5769 ||:  87%|########6 | 1630/1875 [45:30<07:32,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.6259, loss: 0.5770 ||:  87%|########6 | 1631/1875 [45:32<07:33,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.5067, loss: 0.5769 ||:  87%|########7 | 1632/1875 [45:34<07:24,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5543, loss: 0.5769 ||:  87%|########7 | 1633/1875 [45:36<07:28,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5722, loss: 0.5769 ||:  87%|########7 | 1634/1875 [45:38<07:29,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.4984, loss: 0.5769 ||:  87%|########7 | 1635/1875 [45:40<07:21,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5284, loss: 0.5768 ||:  87%|########7 | 1636/1875 [45:41<07:11,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.6028, loss: 0.5769 ||:  87%|########7 | 1637/1875 [45:43<07:14,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5245, loss: 0.5768 ||:  87%|########7 | 1638/1875 [45:45<07:05,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.5239, loss: 0.5768 ||:  87%|########7 | 1639/1875 [45:47<06:51,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6106, loss: 0.5768 ||:  87%|########7 | 1640/1875 [45:48<06:52,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.4293, loss: 0.5767 ||:  88%|########7 | 1641/1875 [45:50<06:59,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4170, loss: 0.5766 ||:  88%|########7 | 1642/1875 [45:52<07:08,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5039, loss: 0.5766 ||:  88%|########7 | 1643/1875 [45:54<06:57,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4521, loss: 0.5765 ||:  88%|########7 | 1644/1875 [45:56<06:46,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4247, loss: 0.5764 ||:  88%|########7 | 1645/1875 [45:57<06:38,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.3726, loss: 0.5763 ||:  88%|########7 | 1646/1875 [45:59<06:32,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.5289, loss: 0.5763 ||:  88%|########7 | 1647/1875 [46:01<06:25,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5210, loss: 0.5762 ||:  88%|########7 | 1648/1875 [46:02<06:30,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5382, loss: 0.5762 ||:  88%|########7 | 1649/1875 [46:04<06:39,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4349, loss: 0.5761 ||:  88%|########8 | 1650/1875 [46:06<06:34,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5018, loss: 0.5761 ||:  88%|########8 | 1651/1875 [46:08<06:29,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.3319, loss: 0.5759 ||:  88%|########8 | 1652/1875 [46:09<06:29,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6336, loss: 0.5760 ||:  88%|########8 | 1653/1875 [46:11<06:26,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5952, loss: 0.5760 ||:  88%|########8 | 1654/1875 [46:13<06:21,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5488, loss: 0.5760 ||:  88%|########8 | 1655/1875 [46:15<06:18,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4994, loss: 0.5759 ||:  88%|########8 | 1656/1875 [46:16<06:12,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5501, loss: 0.5759 ||:  88%|########8 | 1657/1875 [46:18<06:21,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5868, loss: 0.5759 ||:  88%|########8 | 1658/1875 [46:20<06:15,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6266, loss: 0.5759 ||:  88%|########8 | 1659/1875 [46:22<06:17,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5285, loss: 0.5759 ||:  89%|########8 | 1660/1875 [46:23<06:21,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5395, loss: 0.5759 ||:  89%|########8 | 1661/1875 [46:25<06:32,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.5830, loss: 0.5759 ||:  89%|########8 | 1662/1875 [46:27<06:23,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.4618, loss: 0.5758 ||:  89%|########8 | 1663/1875 [46:29<06:20,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4701, loss: 0.5758 ||:  89%|########8 | 1664/1875 [46:31<06:29,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.5331, loss: 0.5757 ||:  89%|########8 | 1665/1875 [46:33<06:20,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4226, loss: 0.5756 ||:  89%|########8 | 1666/1875 [46:34<06:10,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4994, loss: 0.5756 ||:  89%|########8 | 1667/1875 [46:36<06:06,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.4511, loss: 0.5755 ||:  89%|########8 | 1668/1875 [46:38<06:00,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.5464, loss: 0.5755 ||:  89%|########9 | 1669/1875 [46:40<06:20,  1.85s/it]final_beam_acc: 0.0000, batch_loss: 0.4816, loss: 0.5754 ||:  89%|########9 | 1670/1875 [46:42<06:21,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.5255, loss: 0.5754 ||:  89%|########9 | 1671/1875 [46:44<06:21,  1.87s/it]final_beam_acc: 0.0000, batch_loss: 0.4619, loss: 0.5753 ||:  89%|########9 | 1672/1875 [46:45<06:08,  1.82s/it]final_beam_acc: 0.0000, batch_loss: 0.5394, loss: 0.5753 ||:  89%|########9 | 1673/1875 [46:47<06:12,  1.84s/it]final_beam_acc: 0.0000, batch_loss: 0.5193, loss: 0.5753 ||:  89%|########9 | 1674/1875 [46:49<06:01,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5565, loss: 0.5753 ||:  89%|########9 | 1675/1875 [46:51<05:52,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.5533, loss: 0.5753 ||:  89%|########9 | 1676/1875 [46:52<05:53,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.5075, loss: 0.5752 ||:  89%|########9 | 1677/1875 [46:54<05:46,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.3892, loss: 0.5751 ||:  89%|########9 | 1678/1875 [46:56<05:44,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6359, loss: 0.5751 ||:  90%|########9 | 1679/1875 [46:58<05:58,  1.83s/it]final_beam_acc: 0.0000, batch_loss: 0.6491, loss: 0.5752 ||:  90%|########9 | 1680/1875 [47:00<05:50,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5103, loss: 0.5752 ||:  90%|########9 | 1681/1875 [47:01<05:50,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.5860, loss: 0.5752 ||:  90%|########9 | 1682/1875 [47:03<05:45,  1.79s/it]final_beam_acc: 0.0000, batch_loss: 0.4083, loss: 0.5751 ||:  90%|########9 | 1683/1875 [47:05<05:39,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.3671, loss: 0.5749 ||:  90%|########9 | 1684/1875 [47:07<05:34,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6204, loss: 0.5750 ||:  90%|########9 | 1685/1875 [47:08<05:33,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.6202, loss: 0.5750 ||:  90%|########9 | 1686/1875 [47:10<05:35,  1.78s/it]final_beam_acc: 0.0000, batch_loss: 0.5470, loss: 0.5750 ||:  90%|########9 | 1687/1875 [47:12<05:30,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.9270, loss: 0.5752 ||:  90%|######### | 1688/1875 [47:14<05:29,  1.76s/it]final_beam_acc: 0.0000, batch_loss: 0.6539, loss: 0.5752 ||:  90%|######### | 1689/1875 [47:15<05:25,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5772, loss: 0.5752 ||:  90%|######### | 1690/1875 [47:17<05:32,  1.80s/it]final_beam_acc: 0.0000, batch_loss: 0.5127, loss: 0.5752 ||:  90%|######### | 1691/1875 [47:19<05:20,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.6865, loss: 0.5753 ||:  90%|######### | 1692/1875 [47:21<05:16,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5012, loss: 0.5752 ||:  90%|######### | 1693/1875 [47:22<05:10,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5745, loss: 0.5752 ||:  90%|######### | 1694/1875 [47:24<05:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3818, loss: 0.5751 ||:  90%|######### | 1695/1875 [47:26<05:10,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6024, loss: 0.5751 ||:  90%|######### | 1696/1875 [47:27<05:02,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4739, loss: 0.5751 ||:  91%|######### | 1697/1875 [47:29<04:52,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5788, loss: 0.5751 ||:  91%|######### | 1698/1875 [47:31<05:00,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5702, loss: 0.5751 ||:  91%|######### | 1699/1875 [47:32<04:52,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4584, loss: 0.5750 ||:  91%|######### | 1700/1875 [47:35<05:27,  1.87s/it]final_beam_acc: 0.0000, batch_loss: 0.4600, loss: 0.5749 ||:  91%|######### | 1701/1875 [47:37<05:29,  1.90s/it]final_beam_acc: 0.0000, batch_loss: 0.5297, loss: 0.5749 ||:  91%|######### | 1702/1875 [47:38<05:21,  1.86s/it]final_beam_acc: 0.0000, batch_loss: 0.5026, loss: 0.5749 ||:  91%|######### | 1703/1875 [47:40<05:11,  1.81s/it]final_beam_acc: 0.0000, batch_loss: 0.4031, loss: 0.5747 ||:  91%|######### | 1704/1875 [47:42<04:59,  1.75s/it]final_beam_acc: 0.0000, batch_loss: 0.5537, loss: 0.5747 ||:  91%|######### | 1705/1875 [47:43<04:47,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4967, loss: 0.5747 ||:  91%|######### | 1706/1875 [47:45<04:37,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4528, loss: 0.5746 ||:  91%|#########1| 1707/1875 [47:46<04:32,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5553, loss: 0.5746 ||:  91%|#########1| 1708/1875 [47:48<04:26,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4086, loss: 0.5745 ||:  91%|#########1| 1709/1875 [47:49<04:23,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5442, loss: 0.5745 ||:  91%|#########1| 1710/1875 [47:51<04:14,  1.54s/it]final_beam_acc: 0.0000, batch_loss: 0.6867, loss: 0.5746 ||:  91%|#########1| 1711/1875 [47:53<04:22,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.6086, loss: 0.5746 ||:  91%|#########1| 1712/1875 [47:54<04:30,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4892, loss: 0.5745 ||:  91%|#########1| 1713/1875 [47:56<04:30,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5262, loss: 0.5745 ||:  91%|#########1| 1714/1875 [47:58<04:36,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.4695, loss: 0.5744 ||:  91%|#########1| 1715/1875 [48:00<04:36,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6473, loss: 0.5745 ||:  92%|#########1| 1716/1875 [48:01<04:33,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5610, loss: 0.5745 ||:  92%|#########1| 1717/1875 [48:03<04:33,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5108, loss: 0.5744 ||:  92%|#########1| 1718/1875 [48:05<04:24,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.4057, loss: 0.5743 ||:  92%|#########1| 1719/1875 [48:06<04:23,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4158, loss: 0.5742 ||:  92%|#########1| 1720/1875 [48:08<04:14,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5238, loss: 0.5742 ||:  92%|#########1| 1721/1875 [48:09<04:10,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4372, loss: 0.5741 ||:  92%|#########1| 1722/1875 [48:11<04:11,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5299, loss: 0.5741 ||:  92%|#########1| 1723/1875 [48:13<04:11,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5210, loss: 0.5741 ||:  92%|#########1| 1724/1875 [48:14<04:07,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4116, loss: 0.5740 ||:  92%|#########2| 1725/1875 [48:16<04:09,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5845, loss: 0.5740 ||:  92%|#########2| 1726/1875 [48:18<04:01,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5854, loss: 0.5740 ||:  92%|#########2| 1727/1875 [48:19<04:02,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6085, loss: 0.5740 ||:  92%|#########2| 1728/1875 [48:21<04:00,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5283, loss: 0.5740 ||:  92%|#########2| 1729/1875 [48:23<03:57,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4375, loss: 0.5739 ||:  92%|#########2| 1730/1875 [48:24<03:56,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6046, loss: 0.5739 ||:  92%|#########2| 1731/1875 [48:26<03:53,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5269, loss: 0.5739 ||:  92%|#########2| 1732/1875 [48:28<03:58,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4951, loss: 0.5739 ||:  92%|#########2| 1733/1875 [48:29<03:50,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6238, loss: 0.5739 ||:  92%|#########2| 1734/1875 [48:31<03:47,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5612, loss: 0.5739 ||:  93%|#########2| 1735/1875 [48:32<03:47,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6593, loss: 0.5739 ||:  93%|#########2| 1736/1875 [48:34<03:48,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4297, loss: 0.5738 ||:  93%|#########2| 1737/1875 [48:36<03:41,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5193, loss: 0.5738 ||:  93%|#########2| 1738/1875 [48:37<03:35,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4042, loss: 0.5737 ||:  93%|#########2| 1739/1875 [48:39<03:36,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5821, loss: 0.5737 ||:  93%|#########2| 1740/1875 [48:40<03:38,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5008, loss: 0.5737 ||:  93%|#########2| 1741/1875 [48:42<03:39,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4736, loss: 0.5736 ||:  93%|#########2| 1742/1875 [48:44<03:37,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4930, loss: 0.5736 ||:  93%|#########2| 1743/1875 [48:45<03:32,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5025, loss: 0.5735 ||:  93%|#########3| 1744/1875 [48:47<03:32,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4406, loss: 0.5735 ||:  93%|#########3| 1745/1875 [48:48<03:27,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5225, loss: 0.5734 ||:  93%|#########3| 1746/1875 [48:50<03:22,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.6012, loss: 0.5734 ||:  93%|#########3| 1747/1875 [48:52<03:28,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5061, loss: 0.5734 ||:  93%|#########3| 1748/1875 [48:53<03:22,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5478, loss: 0.5734 ||:  93%|#########3| 1749/1875 [48:55<03:25,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5500, loss: 0.5734 ||:  93%|#########3| 1750/1875 [48:57<03:24,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6649, loss: 0.5734 ||:  93%|#########3| 1751/1875 [48:58<03:22,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4183, loss: 0.5733 ||:  93%|#########3| 1752/1875 [49:00<03:22,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6798, loss: 0.5734 ||:  93%|#########3| 1753/1875 [49:01<03:20,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5182, loss: 0.5734 ||:  94%|#########3| 1754/1875 [49:03<03:18,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6127, loss: 0.5734 ||:  94%|#########3| 1755/1875 [49:05<03:15,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4806, loss: 0.5733 ||:  94%|#########3| 1756/1875 [49:06<03:17,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5217, loss: 0.5733 ||:  94%|#########3| 1757/1875 [49:08<03:11,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4397, loss: 0.5732 ||:  94%|#########3| 1758/1875 [49:10<03:10,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5340, loss: 0.5732 ||:  94%|#########3| 1759/1875 [49:11<03:04,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.4380, loss: 0.5731 ||:  94%|#########3| 1760/1875 [49:13<03:02,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5158, loss: 0.5731 ||:  94%|#########3| 1761/1875 [49:14<03:02,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4720, loss: 0.5730 ||:  94%|#########3| 1762/1875 [49:16<02:58,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5351, loss: 0.5730 ||:  94%|#########4| 1763/1875 [49:18<03:01,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6460, loss: 0.5731 ||:  94%|#########4| 1764/1875 [49:19<02:59,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4650, loss: 0.5730 ||:  94%|#########4| 1765/1875 [49:21<02:55,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5969, loss: 0.5730 ||:  94%|#########4| 1766/1875 [49:22<02:53,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5353, loss: 0.5730 ||:  94%|#########4| 1767/1875 [49:24<02:51,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.4661, loss: 0.5729 ||:  94%|#########4| 1768/1875 [49:26<02:49,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5264, loss: 0.5729 ||:  94%|#########4| 1769/1875 [49:27<02:51,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4268, loss: 0.5728 ||:  94%|#########4| 1770/1875 [49:29<02:51,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5584, loss: 0.5728 ||:  94%|#########4| 1771/1875 [49:31<02:49,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4753, loss: 0.5728 ||:  95%|#########4| 1772/1875 [49:32<02:54,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4972, loss: 0.5727 ||:  95%|#########4| 1773/1875 [49:34<02:49,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4004, loss: 0.5726 ||:  95%|#########4| 1774/1875 [49:35<02:41,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4666, loss: 0.5726 ||:  95%|#########4| 1775/1875 [49:37<02:43,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5720, loss: 0.5726 ||:  95%|#########4| 1776/1875 [49:39<02:39,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5494, loss: 0.5726 ||:  95%|#########4| 1777/1875 [49:40<02:42,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5923, loss: 0.5726 ||:  95%|#########4| 1778/1875 [49:42<02:35,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5436, loss: 0.5725 ||:  95%|#########4| 1779/1875 [49:44<02:39,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4886, loss: 0.5725 ||:  95%|#########4| 1780/1875 [49:45<02:37,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4281, loss: 0.5724 ||:  95%|#########4| 1781/1875 [49:47<02:32,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.5180, loss: 0.5724 ||:  95%|#########5| 1782/1875 [49:49<02:31,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5024, loss: 0.5724 ||:  95%|#########5| 1783/1875 [49:50<02:36,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4876, loss: 0.5723 ||:  95%|#########5| 1784/1875 [49:52<02:31,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5181, loss: 0.5723 ||:  95%|#########5| 1785/1875 [49:54<02:30,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6347, loss: 0.5723 ||:  95%|#########5| 1786/1875 [49:55<02:26,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5992, loss: 0.5723 ||:  95%|#########5| 1787/1875 [49:57<02:28,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.7953, loss: 0.5724 ||:  95%|#########5| 1788/1875 [49:59<02:23,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.6071, loss: 0.5725 ||:  95%|#########5| 1789/1875 [50:00<02:24,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5297, loss: 0.5724 ||:  95%|#########5| 1790/1875 [50:02<02:20,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5924, loss: 0.5725 ||:  96%|#########5| 1791/1875 [50:04<02:16,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5142, loss: 0.5724 ||:  96%|#########5| 1792/1875 [50:05<02:23,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5961, loss: 0.5724 ||:  96%|#########5| 1793/1875 [50:07<02:19,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4984, loss: 0.5724 ||:  96%|#########5| 1794/1875 [50:09<02:17,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.4360, loss: 0.5723 ||:  96%|#########5| 1795/1875 [50:10<02:15,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5374, loss: 0.5723 ||:  96%|#########5| 1796/1875 [50:12<02:08,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.6131, loss: 0.5723 ||:  96%|#########5| 1797/1875 [50:14<02:06,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6502, loss: 0.5724 ||:  96%|#########5| 1798/1875 [50:15<02:06,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.6037, loss: 0.5724 ||:  96%|#########5| 1799/1875 [50:17<02:01,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4667, loss: 0.5723 ||:  96%|#########6| 1800/1875 [50:19<02:12,  1.77s/it]final_beam_acc: 0.0000, batch_loss: 0.4683, loss: 0.5723 ||:  96%|#########6| 1801/1875 [50:20<02:06,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.6153, loss: 0.5723 ||:  96%|#########6| 1802/1875 [50:22<02:06,  1.74s/it]final_beam_acc: 0.0000, batch_loss: 0.3806, loss: 0.5722 ||:  96%|#########6| 1803/1875 [50:24<02:01,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5155, loss: 0.5722 ||:  96%|#########6| 1804/1875 [50:26<01:59,  1.68s/it]final_beam_acc: 0.0000, batch_loss: 0.5034, loss: 0.5721 ||:  96%|#########6| 1805/1875 [50:27<01:56,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4812, loss: 0.5721 ||:  96%|#########6| 1806/1875 [50:29<01:53,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.5674, loss: 0.5721 ||:  96%|#########6| 1807/1875 [50:30<01:53,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4752, loss: 0.5720 ||:  96%|#########6| 1808/1875 [50:32<01:51,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4688, loss: 0.5720 ||:  96%|#########6| 1809/1875 [50:34<01:50,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5239, loss: 0.5719 ||:  97%|#########6| 1810/1875 [50:35<01:48,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5287, loss: 0.5719 ||:  97%|#########6| 1811/1875 [50:37<01:46,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4673, loss: 0.5718 ||:  97%|#########6| 1812/1875 [50:39<01:45,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3692, loss: 0.5717 ||:  97%|#########6| 1813/1875 [50:41<01:46,  1.71s/it]final_beam_acc: 0.0000, batch_loss: 0.4692, loss: 0.5717 ||:  97%|#########6| 1814/1875 [50:42<01:44,  1.72s/it]final_beam_acc: 0.0000, batch_loss: 0.5936, loss: 0.5717 ||:  97%|#########6| 1815/1875 [50:44<01:40,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.6383, loss: 0.5717 ||:  97%|#########6| 1816/1875 [50:46<01:39,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5527, loss: 0.5717 ||:  97%|#########6| 1817/1875 [50:47<01:35,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.3771, loss: 0.5716 ||:  97%|#########6| 1818/1875 [50:49<01:31,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.3339, loss: 0.5715 ||:  97%|#########7| 1819/1875 [50:50<01:28,  1.59s/it]final_beam_acc: 0.0000, batch_loss: 0.5271, loss: 0.5715 ||:  97%|#########7| 1820/1875 [50:52<01:26,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5229, loss: 0.5714 ||:  97%|#########7| 1821/1875 [50:54<01:26,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5282, loss: 0.5714 ||:  97%|#########7| 1822/1875 [50:55<01:23,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5654, loss: 0.5714 ||:  97%|#########7| 1823/1875 [50:57<01:22,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4276, loss: 0.5713 ||:  97%|#########7| 1824/1875 [50:58<01:22,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5258, loss: 0.5713 ||:  97%|#########7| 1825/1875 [51:00<01:18,  1.58s/it]final_beam_acc: 0.0000, batch_loss: 0.5460, loss: 0.5713 ||:  97%|#########7| 1826/1875 [51:02<01:21,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.4658, loss: 0.5712 ||:  97%|#########7| 1827/1875 [51:03<01:20,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4613, loss: 0.5712 ||:  97%|#########7| 1828/1875 [51:05<01:17,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5184, loss: 0.5711 ||:  98%|#########7| 1829/1875 [51:07<01:15,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4597, loss: 0.5711 ||:  98%|#########7| 1830/1875 [51:08<01:13,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.3903, loss: 0.5710 ||:  98%|#########7| 1831/1875 [51:10<01:09,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.4531, loss: 0.5709 ||:  98%|#########7| 1832/1875 [51:11<01:07,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5020, loss: 0.5709 ||:  98%|#########7| 1833/1875 [51:13<01:07,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5833, loss: 0.5709 ||:  98%|#########7| 1834/1875 [51:15<01:07,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4787, loss: 0.5708 ||:  98%|#########7| 1835/1875 [51:16<01:04,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.4142, loss: 0.5707 ||:  98%|#########7| 1836/1875 [51:18<01:05,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5790, loss: 0.5707 ||:  98%|#########7| 1837/1875 [51:20<01:05,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4030, loss: 0.5707 ||:  98%|#########8| 1838/1875 [51:22<01:04,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.5152, loss: 0.5706 ||:  98%|#########8| 1839/1875 [51:23<01:00,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.4363, loss: 0.5706 ||:  98%|#########8| 1840/1875 [51:25<00:56,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6000, loss: 0.5706 ||:  98%|#########8| 1841/1875 [51:26<00:55,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4950, loss: 0.5705 ||:  98%|#########8| 1842/1875 [51:28<00:54,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6327, loss: 0.5706 ||:  98%|#########8| 1843/1875 [51:30<00:52,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.4561, loss: 0.5705 ||:  98%|#########8| 1844/1875 [51:31<00:51,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.4961, loss: 0.5705 ||:  98%|#########8| 1845/1875 [51:33<00:48,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.5170, loss: 0.5704 ||:  98%|#########8| 1846/1875 [51:34<00:46,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4424, loss: 0.5704 ||:  99%|#########8| 1847/1875 [51:36<00:45,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4366, loss: 0.5703 ||:  99%|#########8| 1848/1875 [51:38<00:43,  1.61s/it]final_beam_acc: 0.0000, batch_loss: 0.4789, loss: 0.5702 ||:  99%|#########8| 1849/1875 [51:39<00:42,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4259, loss: 0.5702 ||:  99%|#########8| 1850/1875 [51:41<00:41,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5454, loss: 0.5701 ||:  99%|#########8| 1851/1875 [51:43<00:39,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.5272, loss: 0.5701 ||:  99%|#########8| 1852/1875 [51:44<00:37,  1.64s/it]final_beam_acc: 0.0000, batch_loss: 0.4220, loss: 0.5700 ||:  99%|#########8| 1853/1875 [51:46<00:35,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6133, loss: 0.5701 ||:  99%|#########8| 1854/1875 [51:47<00:33,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.5166, loss: 0.5700 ||:  99%|#########8| 1855/1875 [51:49<00:32,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4508, loss: 0.5700 ||:  99%|#########8| 1856/1875 [51:51<00:30,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4239, loss: 0.5699 ||:  99%|#########9| 1857/1875 [51:52<00:28,  1.60s/it]final_beam_acc: 0.0000, batch_loss: 0.4800, loss: 0.5698 ||:  99%|#########9| 1858/1875 [51:54<00:27,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4727, loss: 0.5698 ||:  99%|#########9| 1859/1875 [51:56<00:26,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.5825, loss: 0.5698 ||:  99%|#########9| 1860/1875 [51:57<00:24,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5090, loss: 0.5698 ||:  99%|#########9| 1861/1875 [51:59<00:23,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.6104, loss: 0.5698 ||:  99%|#########9| 1862/1875 [52:01<00:21,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.3697, loss: 0.5697 ||:  99%|#########9| 1863/1875 [52:02<00:19,  1.62s/it]final_beam_acc: 0.0000, batch_loss: 0.6613, loss: 0.5697 ||:  99%|#########9| 1864/1875 [52:04<00:17,  1.63s/it]final_beam_acc: 0.0000, batch_loss: 0.4876, loss: 0.5697 ||:  99%|#########9| 1865/1875 [52:06<00:17,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.6176, loss: 0.5697 ||: 100%|#########9| 1866/1875 [52:07<00:14,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5894, loss: 0.5697 ||: 100%|#########9| 1867/1875 [52:09<00:13,  1.70s/it]final_beam_acc: 0.0000, batch_loss: 0.5130, loss: 0.5697 ||: 100%|#########9| 1868/1875 [52:11<00:11,  1.67s/it]final_beam_acc: 0.0000, batch_loss: 0.5001, loss: 0.5697 ||: 100%|#########9| 1869/1875 [52:12<00:09,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.6069, loss: 0.5697 ||: 100%|#########9| 1870/1875 [52:14<00:08,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5967, loss: 0.5697 ||: 100%|#########9| 1871/1875 [52:16<00:06,  1.69s/it]final_beam_acc: 0.0000, batch_loss: 0.3993, loss: 0.5696 ||: 100%|#########9| 1872/1875 [52:18<00:05,  1.73s/it]final_beam_acc: 0.0000, batch_loss: 0.4485, loss: 0.5695 ||: 100%|#########9| 1873/1875 [52:19<00:03,  1.66s/it]final_beam_acc: 0.0000, batch_loss: 0.5089, loss: 0.5695 ||: 100%|#########9| 1874/1875 [52:21<00:01,  1.65s/it]final_beam_acc: 0.0000, batch_loss: 0.5362, loss: 0.5695 ||: 100%|##########| 1875/1875 [52:22<00:00,  1.57s/it]final_beam_acc: 0.0000, batch_loss: 0.5362, loss: 0.5695 ||: 100%|##########| 1875/1875 [52:22<00:00,  1.68s/it]2021-04-12 22:57:04,544 - INFO - allennlp.training.trainer - Validating

  0%|          | 0/1125 [00:00<?, ?it/s]is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 18],
       device='cuda:2')
2021-04-12 22:57:04,814 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 17],
       device='cuda:2')
2021-04-12 22:57:04,815 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15],
       device='cuda:2')
2021-04-12 22:57:04,816 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 16],
       device='cuda:2')
2021-04-12 22:57:04,817 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 17],
       device='cuda:2')
2021-04-12 22:57:04,817 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15],
       device='cuda:2')
2021-04-12 22:57:04,818 - INFO - root - 1
is_gold_leaf_idx: 14
top_agenda_indices_el: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 17],
       device='cuda:2')
2021-04-12 22:57:04,819 - INFO - root - 1
/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  0%|          | 0/1125 [00:00<?, ?it/s]
dataset/database
dataset/database
2021-04-12 22:57:05,422 - CRITICAL - root - Uncaught exception
Traceback (most recent call last):
  File "exec.py", line 144, in <module>
    run()
  File "exec.py", line 134, in run
    train_model(
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py", line 236, in train_model
    model = _train_worker(
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py", line 466, in _train_worker
    metrics = train_loop.run()
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/commands/train.py", line 528, in run
    return self.trainer.train()
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py", line 961, in train
    return self._try_train()
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py", line 1015, in _try_train
    val_loss, val_reg_loss, num_batches = self._validation_loss(epoch)
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py", line 898, in _validation_loss
    batch_outputs = self.batch_outputs(batch, for_training=False)
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/allennlp/training/trainer.py", line 601, in batch_outputs
    output_dict = self._pytorch_model(**batch)
  File "/specific/netapp5/joberant/home/ohadr/smbop/shani/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/joberant/home/ohadr/smbop/shani/SmBopEST/models/semantic_parsing/smbop.py", line 913, in forward
    self._compute_validation_outputs(
  File "/home/joberant/home/ohadr/smbop/shani/SmBopEST/models/semantic_parsing/smbop.py", line 1050, in _compute_validation_outputs
    self._evaluate_func(
  File "/home/joberant/home/ohadr/smbop/shani/SmBopEST/eval_final/evaluation.py", line 865, in evaluate_single
    schema = Schema(get_schema(db))
  File "/home/joberant/home/ohadr/smbop/shani/SmBopEST/eval_final/process_sql.py", line 89, in get_schema
    conn = sqlite3.connect(db)
sqlite3.OperationalError: unable to open database file
